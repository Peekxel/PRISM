{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import tempfile\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.io import mmread\n",
    "import anndata\n",
    "\n",
    "# Define constants\n",
    "ACCESSION = \"GSE255832\"\n",
    "BASE_URL = f\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE255nnn/{ACCESSION}/suppl/\"\n",
    "SAMPLE_IDS = [\"MMA198_1\", \"MMA198_2\", \"MMA200_1\", \"MMA202_1\"]\n",
    "FILE_TYPES = [\"barcodes.tsv.gz\", \"features.tsv.gz\", \"matrix.mtx.gz\", \"protospacer_calls_per_cell.csv.gz\"]\n",
    "\n",
    "def ensure_directory(directory):\n",
    "    \"\"\"Create directory if it doesn't exist.\"\"\"\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "    return directory\n",
    "\n",
    "def download_file(url, destination):\n",
    "    \"\"\"\n",
    "    Download a file from URL to destination if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        url: URL to download from\n",
    "        destination: Path to save the file to\n",
    "        \n",
    "    Returns:\n",
    "        True if the file exists or was successfully downloaded, False otherwise.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(destination):\n",
    "        print(f\"Downloading {url} to {destination}\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, destination)\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {url}: {e}\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def download_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    Download all dataset files if they don't exist.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory to save the files to.\n",
    "        \n",
    "    Returns:\n",
    "        True if all files exist or were successfully downloaded, False otherwise.\n",
    "    \"\"\"\n",
    "    ensure_directory(data_dir)\n",
    "    \n",
    "    all_files_exist = True\n",
    "    for sample_id in SAMPLE_IDS:\n",
    "        for file_type in FILE_TYPES:\n",
    "            filename = f\"{ACCESSION}_{sample_id}_{file_type}\"\n",
    "            file_path = os.path.join(data_dir, filename)\n",
    "            file_url = f\"{BASE_URL}{filename}\"\n",
    "            \n",
    "            if not download_file(file_url, file_path):\n",
    "                all_files_exist = False\n",
    "    \n",
    "    return all_files_exist\n",
    "\n",
    "def load_10x_data(matrix_file, features_file, barcodes_file):\n",
    "    \"\"\"\n",
    "    Load 10X Genomics data into an AnnData object.\n",
    "    \n",
    "    Args:\n",
    "        matrix_file: Path to the matrix.mtx.gz file.\n",
    "        features_file: Path to the features.tsv.gz file.\n",
    "        barcodes_file: Path to the barcodes.tsv.gz file.\n",
    "        \n",
    "    Returns:\n",
    "        AnnData object with the loaded data.\n",
    "    \"\"\"\n",
    "    # Create temporary directory for unzipped files\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # Unzip files to temporary directory\n",
    "        temp_matrix = os.path.join(temp_dir, 'matrix.mtx')\n",
    "        temp_features = os.path.join(temp_dir, 'features.tsv')\n",
    "        temp_barcodes = os.path.join(temp_dir, 'barcodes.tsv')\n",
    "        \n",
    "        # Unzip matrix file\n",
    "        with gzip.open(matrix_file, 'rb') as f_in:\n",
    "            with open(temp_matrix, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "        # Unzip features file\n",
    "        with gzip.open(features_file, 'rb') as f_in:\n",
    "            with open(temp_features, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "        # Unzip barcodes file\n",
    "        with gzip.open(barcodes_file, 'rb') as f_in:\n",
    "            with open(temp_barcodes, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "        # Read the mtx file\n",
    "        X = sparse.csr_matrix(mmread(temp_matrix).T)\n",
    "        \n",
    "        # Read gene information\n",
    "        gene_info = pd.read_csv(temp_features, sep='\\t', header=None)\n",
    "        \n",
    "        # Read cell barcodes\n",
    "        barcodes = pd.read_csv(temp_barcodes, sep='\\t', header=None)[0].values\n",
    "    \n",
    "    # Create observation and variable dataframes\n",
    "    obs = pd.DataFrame(index=barcodes)\n",
    "    var = pd.DataFrame(index=gene_info[0].values)  # Gene IDs as index\n",
    "    \n",
    "    # Add gene information\n",
    "    var['gene_symbols'] = gene_info[1].values      # Gene symbols\n",
    "    if gene_info.shape[1] > 2:\n",
    "        var['feature_types'] = gene_info[2].values  # Feature types\n",
    "    \n",
    "    # Create AnnData object\n",
    "    adata = anndata.AnnData(X=X, obs=obs, var=var)\n",
    "    \n",
    "    # Use gene symbols as var_names\n",
    "    adata.var_names = adata.var['gene_symbols'].values\n",
    "    adata.var_names_make_unique()\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def load_perturbation_data(perturbation_file, adata):\n",
    "    \"\"\"\n",
    "    Load perturbation information and add it to the AnnData object.\n",
    "    \n",
    "    Cells with an \"Unknown\" perturbation_name are removed.\n",
    "    Also, perturbations labeled as \"NonTargetingControlGuideForMouse\" are converted to \"Non-targeting\"\n",
    "    and assigned a perturbation type of \"Control\".\n",
    "    \n",
    "    Args:\n",
    "        perturbation_file: Path to the protospacer_calls_per_cell.csv.gz file.\n",
    "        adata: AnnData object to add the perturbation information to.\n",
    "        \n",
    "    Returns:\n",
    "        Updated AnnData object.\n",
    "    \"\"\"\n",
    "    # Create temporary file for unzipped perturbation data\n",
    "    with tempfile.NamedTemporaryFile(suffix='.csv', delete=False) as temp_file:\n",
    "        temp_pert_file = temp_file.name\n",
    "    \n",
    "    try:\n",
    "        # Unzip perturbation file\n",
    "        with gzip.open(perturbation_file, 'rb') as f_in:\n",
    "            with open(temp_pert_file, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "        # Read perturbation data\n",
    "        perturbations = pd.read_csv(temp_pert_file)\n",
    "        \n",
    "        # Convert to dictionary for faster lookup\n",
    "        pert_dict = {}\n",
    "        for _, row in perturbations.iterrows():\n",
    "            pert_dict[row['cell_barcode']] = row['feature_call']\n",
    "        \n",
    "        # Map perturbation info to each cell in adata\n",
    "        adata.obs['perturbation'] = adata.obs.index.map(lambda x: pert_dict.get(x, 'Unknown'))\n",
    "        \n",
    "        # Extract target gene from perturbation string\n",
    "        def extract_target_gene(pert_string):\n",
    "            \"\"\"\n",
    "            Extract target gene(s) from perturbation string.\n",
    "            \n",
    "            Args:\n",
    "                pert_string: Perturbation string (e.g., 'Elovl1_gRNA1').\n",
    "                \n",
    "            Returns:\n",
    "                Target gene(s) (e.g., 'Elovl1' or 'Elovl1+Tgds').\n",
    "            \"\"\"\n",
    "            if pd.isna(pert_string) or pert_string == 'Unknown':\n",
    "                return 'Unknown'\n",
    "            \n",
    "            # Handle multiple perturbations (separated by |)\n",
    "            if '|' in pert_string:\n",
    "                genes = []\n",
    "                for p in pert_string.split('|'):\n",
    "                    # Convert NonTargetingControlGuideForMouse to Non-targeting\n",
    "                    if 'NonTargetingControlGuideForMouse' in p:\n",
    "                        genes.append('Non-targeting')\n",
    "                    else:\n",
    "                        gene = p.split('_')[0] if '_' in p else p\n",
    "                        genes.append(gene)\n",
    "                return '+'.join(genes)\n",
    "            else:\n",
    "                # Single perturbation\n",
    "                if 'NonTargetingControlGuideForMouse' in pert_string:\n",
    "                    return 'Non-targeting'\n",
    "                return pert_string.split('_')[0] if '_' in pert_string else pert_string\n",
    "        \n",
    "        # Add target gene information\n",
    "        adata.obs['perturbation_name'] = adata.obs['perturbation'].apply(extract_target_gene)\n",
    "        \n",
    "        # Set perturbation type based on the extracted name:\n",
    "        # If the perturbation is \"Non-targeting\", mark as \"Control\", else \"targeting\".\n",
    "        adata.obs['perturbation_type'] = adata.obs['perturbation_name'].apply(\n",
    "            lambda x: 'Control' if x == 'Non-targeting' else 'targeting'\n",
    "        )\n",
    "        \n",
    "        # Exclude cells with an \"Unknown\" perturbation name.\n",
    "        adata = adata[adata.obs['perturbation_name'] != 'Unknown'].copy()\n",
    "    \n",
    "    finally:\n",
    "        # Clean up temporary file\n",
    "        if os.path.exists(temp_pert_file):\n",
    "            os.remove(temp_pert_file)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def harmonize_data(adata, sample_id):\n",
    "    \"\"\"\n",
    "    Harmonize the data according to specified standards.\n",
    "    \n",
    "    Args:\n",
    "        adata: AnnData object to harmonize.\n",
    "        sample_id: Sample identifier.\n",
    "        \n",
    "    Returns:\n",
    "        Harmonized AnnData object.\n",
    "    \"\"\"\n",
    "    # Add sample ID\n",
    "    adata.obs['sample_id'] = sample_id\n",
    "    \n",
    "    # Add organism information (from the study description)\n",
    "    adata.obs['organism'] = 'Mus musculus'\n",
    "    \n",
    "    # Add cell type information (from the study description)\n",
    "    adata.obs['cell_type'] = 'CD8+ T cells'\n",
    "    \n",
    "    # Add CRISPR type information (from the study description)\n",
    "    adata.obs['crispr_type'] = 'CRISPR KO'\n",
    "    \n",
    "    # Add cancer type information (from the study description)\n",
    "    adata.obs['cancer_type'] = 'Pancreatic cancer'\n",
    "    \n",
    "    # Add condition information based on sample ID.\n",
    "    if sample_id in ['MMA198_1', 'MMA200_1']:\n",
    "        adata.obs['condition'] = 'IgG control'\n",
    "    elif sample_id in ['MMA198_2', 'MMA202_1']:\n",
    "        adata.obs['condition'] = 'anti-PD-1'\n",
    "    else:\n",
    "        adata.obs['condition'] = 'Unknown'\n",
    "    \n",
    "    # Overwrite condition for non-targeting cells to \"Control\" only.\n",
    "    adata.obs.loc[adata.obs['perturbation_type'] == 'Control', 'condition'] = 'Control'\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def process_sample(data_dir, sample_id):\n",
    "    \"\"\"\n",
    "    Process a single sample from the dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the data files.\n",
    "        sample_id: Sample identifier.\n",
    "        \n",
    "    Returns:\n",
    "        Processed AnnData object.\n",
    "    \"\"\"\n",
    "    print(f\"Processing sample {sample_id}...\")\n",
    "    \n",
    "    # Define file paths\n",
    "    matrix_file = os.path.join(data_dir, f\"{ACCESSION}_{sample_id}_matrix.mtx.gz\")\n",
    "    features_file = os.path.join(data_dir, f\"{ACCESSION}_{sample_id}_features.tsv.gz\")\n",
    "    barcodes_file = os.path.join(data_dir, f\"{ACCESSION}_{sample_id}_barcodes.tsv.gz\")\n",
    "    perturbation_file = os.path.join(data_dir, f\"{ACCESSION}_{sample_id}_protospacer_calls_per_cell.csv.gz\")\n",
    "    \n",
    "    # Check if all files exist\n",
    "    for file_path in [matrix_file, features_file, barcodes_file, perturbation_file]:\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    # Load data\n",
    "    adata = load_10x_data(matrix_file, features_file, barcodes_file)\n",
    "    \n",
    "    # Add perturbation information (which filters out Unknown cells)\n",
    "    adata = load_perturbation_data(perturbation_file, adata)\n",
    "    \n",
    "    # Harmonize data (this will now update condition for non-targeting cells)\n",
    "    adata = harmonize_data(adata, sample_id)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def main_jupyter(data_dir=None):\n",
    "    \"\"\"Main function for running the pipeline in a Jupyter Notebook.\"\"\"\n",
    "    if data_dir is None:\n",
    "        data_dir = os.path.join('.', ACCESSION)\n",
    "    \n",
    "    # Download dataset if needed\n",
    "    if not download_dataset(data_dir):\n",
    "        print(\"Error downloading dataset files. Please check your internet connection.\")\n",
    "        return\n",
    "    \n",
    "    # Process each sample\n",
    "    adatas = []\n",
    "    for i, sample_id in enumerate(SAMPLE_IDS):\n",
    "        try:\n",
    "            adata = process_sample(data_dir, sample_id)\n",
    "            # Overwrite sample_id with a numeric identifier for easier reference\n",
    "            adata.obs['sample_id'] = str(i)\n",
    "            adatas.append(adata)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {sample_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not adatas:\n",
    "        print(\"No samples were successfully processed.\")\n",
    "        return\n",
    "    \n",
    "    # Combine all samples into a single AnnData object\n",
    "    print(\"Combining samples...\")\n",
    "    combined_adata = anndata.concat(adatas, join='outer', label='sample_id')\n",
    "    \n",
    "    # Ensure var_names are gene symbols\n",
    "    if 'gene_symbols' in combined_adata.var:\n",
    "        combined_adata.var_names = combined_adata.var['gene_symbols']\n",
    "        combined_adata.var_names_make_unique()\n",
    "    \n",
    "    # Make observation names unique\n",
    "    combined_adata.obs_names_make_unique()\n",
    "    \n",
    "    # Save the combined data\n",
    "    output_file = os.path.join(data_dir, f\"{ACCESSION}_harmonized.h5ad\")\n",
    "    print(f\"Saving harmonized data to {output_file}\")\n",
    "    combined_adata.write_h5ad(output_file)\n",
    "    \n",
    "    print(\"Processing complete!\")\n",
    "    print(f\"Final dataset shape: {combined_adata.shape}\")\n",
    "    print(f\"Number of genes: {combined_adata.n_vars}\")\n",
    "    print(f\"Number of cells: {combined_adata.n_obs}\")\n",
    "    print(f\"Harmonized data saved to: {output_file}\")\n",
    "\n",
    "# Run the pipeline in the Jupyter Notebook\n",
    "main_jupyter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
