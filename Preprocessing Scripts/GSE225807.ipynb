{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import shutil\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "from pathlib import Path\n",
    "from anndata import AnnData\n",
    "\n",
    "# Constants\n",
    "DATASET_ID = \"GSE225807\"\n",
    "DATASET_URL = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE225nnn/GSE225807/suppl/GSE225807_RAW.tar\"\n",
    "FILE_NAMES = {\n",
    "    \"barcodes\": \"GSM7056649_barcodes.tsv.gz\",\n",
    "    \"features\": \"GSM7056649_features.tsv.gz\",\n",
    "    \"matrix\": \"GSM7056649_matrix.mtx.gz\",\n",
    "    \"mu_matrix\": \"GSM7056649_mu_matrix.tsv.gz\",\n",
    "    \"sgrna_mapping\": \"GSM7056650_bc_to_sgrna_mapping_3_06.csv.gz\"\n",
    "}\n",
    "\n",
    "def download_dataset(output_dir):\n",
    "    \"\"\"Download the dataset if it doesn't exist.\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    tar_path = output_dir / f\"{DATASET_ID}_RAW.tar\"\n",
    "    \n",
    "    # Check if all files already exist\n",
    "    all_files_exist = all((output_dir / filename).exists() for filename in FILE_NAMES.values())\n",
    "    \n",
    "    if all_files_exist:\n",
    "        print(f\"All files already exist in {output_dir}. Skipping download.\")\n",
    "        return\n",
    "    \n",
    "    # Download the tar file if it doesn't exist\n",
    "    if not tar_path.exists():\n",
    "        print(f\"Downloading {DATASET_ID} dataset...\")\n",
    "        response = requests.get(DATASET_URL, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(tar_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"Download complete: {tar_path}\")\n",
    "    \n",
    "    # Extract the tar file\n",
    "    print(f\"Extracting files from {tar_path}...\")\n",
    "    import tarfile\n",
    "    with tarfile.open(tar_path, 'r') as tar:\n",
    "        tar.extractall(path=output_dir)\n",
    "    print(\"Extraction complete.\")\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\"Load the dataset from the specified directory.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    # Check if all required files exist\n",
    "    for file_type, file_name in FILE_NAMES.items():\n",
    "        file_path = data_dir / file_name\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"Required file not found: {file_path}\")\n",
    "    \n",
    "    print(\"Loading gene expression matrix...\")\n",
    "    # Load the count matrix in sparse format\n",
    "    mtx_path = data_dir / FILE_NAMES[\"matrix\"]\n",
    "    counts = sc.read_mtx(str(mtx_path)).X.T  # Transpose to get cells as rows\n",
    "    \n",
    "    # Load barcodes (cell IDs)\n",
    "    barcodes_path = data_dir / FILE_NAMES[\"barcodes\"]\n",
    "    with gzip.open(barcodes_path, 'rt') as f:\n",
    "        barcodes = [line.strip() for line in f]\n",
    "    \n",
    "    # Load gene features\n",
    "    features_path = data_dir / FILE_NAMES[\"features\"]\n",
    "    features_df = pd.read_csv(features_path, sep='\\t', header=None, names=['gene_id', 'gene_name', 'feature_type'], compression='gzip')\n",
    "    \n",
    "    # Load sgRNA mapping\n",
    "    sgrna_path = data_dir / FILE_NAMES[\"sgrna_mapping\"]\n",
    "    \n",
    "    # Read the file manually since it has a non-standard format\n",
    "    with gzip.open(sgrna_path, 'rt') as f:\n",
    "        content = f.readlines()\n",
    "    \n",
    "    # Print the first few lines to debug\n",
    "    print(\"First few lines of sgRNA mapping file:\")\n",
    "    for i in range(min(5, len(content))):\n",
    "        print(f\"Line {i}: {content[i].strip()}\")\n",
    "    \n",
    "    # Try to parse the file\n",
    "    try:\n",
    "        # Try reading with pandas directly\n",
    "        sgrna_df = pd.read_csv(sgrna_path, compression='gzip', sep='\\t')\n",
    "        print(f\"Successfully read sgRNA mapping file with pandas. Shape: {sgrna_df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading with pandas: {e}\")\n",
    "        \n",
    "        # Try manual parsing\n",
    "        try:\n",
    "            # Parse header\n",
    "            header_line = content[0].strip()\n",
    "            header = header_line.split('\\t')\n",
    "            header = [h.strip() for h in header]\n",
    "            \n",
    "            # Parse data\n",
    "            data = []\n",
    "            for line in content[1:]:\n",
    "                row = line.strip().split('\\t')\n",
    "                # Ensure each row has the same number of columns as the header\n",
    "                if len(row) > len(header):\n",
    "                    # If there are more columns in the data than in the header,\n",
    "                    # we need to add more column names\n",
    "                    header.extend([f'col{i}' for i in range(len(header), len(row))])\n",
    "                elif len(row) < len(header):\n",
    "                    # If there are fewer columns in the data than in the header,\n",
    "                    # we need to pad the row with empty strings\n",
    "                    row.extend([''] * (len(header) - len(row)))\n",
    "                data.append(row)\n",
    "            \n",
    "            # Create DataFrame\n",
    "            sgrna_df = pd.DataFrame(data, columns=header)\n",
    "            print(f\"Successfully parsed sgRNA mapping file manually. Shape: {sgrna_df.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error with manual parsing: {e}\")\n",
    "            raise\n",
    "    \n",
    "    print(f\"sgRNA mapping DataFrame shape: {sgrna_df.shape}\")\n",
    "    print(f\"sgRNA mapping columns: {sgrna_df.columns.tolist()}\")\n",
    "    \n",
    "    # Create AnnData object\n",
    "    adata = AnnData(X=counts, \n",
    "                   obs=pd.DataFrame(index=barcodes),\n",
    "                   var=pd.DataFrame(index=features_df['gene_name']))\n",
    "    \n",
    "    # Add gene information\n",
    "    adata.var['gene_id'] = features_df['gene_id'].values\n",
    "    adata.var['feature_type'] = features_df['feature_type'].values\n",
    "    \n",
    "    # Add sgRNA mapping information\n",
    "    # Identify the barcode, sgRNA, and RBP columns\n",
    "    barcode_col = None\n",
    "    sgrna_col = None\n",
    "    rbp_col = None\n",
    "    \n",
    "    # Look for columns with expected names\n",
    "    for col in sgrna_df.columns:\n",
    "        if 'barcode' in col.lower():\n",
    "            barcode_col = col\n",
    "        elif 'sgrna' in col.lower() or 'guide' in col.lower():\n",
    "            sgrna_col = col\n",
    "        elif 'rbp' in col.lower() or 'protein' in col.lower() or 'target' in col.lower():\n",
    "            rbp_col = col\n",
    "    \n",
    "    # If we couldn't find the columns by name, try to infer them by position\n",
    "    if barcode_col is None and len(sgrna_df.columns) >= 3:\n",
    "        # Assume the second column is the barcode (after the index)\n",
    "        barcode_col = sgrna_df.columns[1]\n",
    "    \n",
    "    if sgrna_col is None and len(sgrna_df.columns) >= 3:\n",
    "        # Assume the third column is the sgRNA\n",
    "        sgrna_col = sgrna_df.columns[2]\n",
    "    \n",
    "    if rbp_col is None and len(sgrna_df.columns) >= 4:\n",
    "        # Assume the fourth column is the RBP\n",
    "        rbp_col = sgrna_df.columns[3]\n",
    "    \n",
    "    # Final check\n",
    "    if barcode_col is None or sgrna_col is None or rbp_col is None:\n",
    "        # If we still can't find the columns, print the first few rows to help debug\n",
    "        print(\"First few rows of sgRNA mapping file:\")\n",
    "        print(sgrna_df.head())\n",
    "        raise ValueError(\"Could not identify barcode, sgRNA, or RBP columns in sgRNA mapping file.\")\n",
    "    \n",
    "    print(f\"Using columns: barcode={barcode_col}, sgRNA={sgrna_col}, RBP={rbp_col}\")\n",
    "    \n",
    "    # Convert to string\n",
    "    sgrna_df[barcode_col] = sgrna_df[barcode_col].astype(str)\n",
    "    \n",
    "    # Create a mapping from cell barcode to sgRNA and RBP\n",
    "    barcode_to_sgrna = dict(zip(sgrna_df[barcode_col], sgrna_df[sgrna_col]))\n",
    "    barcode_to_rbp = dict(zip(sgrna_df[barcode_col], sgrna_df[rbp_col]))\n",
    "    \n",
    "    # Add sgRNA and RBP information to obs\n",
    "    # Extract the barcode part from the cell index (remove the suffix if present)\n",
    "    cell_barcodes = [bc.split('-')[0] if '-' in bc else bc for bc in adata.obs.index]\n",
    "    \n",
    "    # Map cell barcodes to sgRNAs and RBPs\n",
    "    adata.obs['sgRNA'] = [barcode_to_sgrna.get(bc, 'unknown') for bc in cell_barcodes]\n",
    "    adata.obs['RBP'] = [barcode_to_rbp.get(bc, 'unknown') for bc in cell_barcodes]\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"Cells with known sgRNA: {sum(adata.obs['sgRNA'] != 'unknown')} out of {adata.n_obs}\")\n",
    "    print(f\"Cells with known RBP: {sum(adata.obs['RBP'] != 'unknown')} out of {adata.n_obs}\")\n",
    "    \n",
    "    # Load mu_matrix if available (contains latent variables)\n",
    "    mu_path = data_dir / FILE_NAMES[\"mu_matrix\"]\n",
    "    if mu_path.exists():\n",
    "        print(\"Loading latent variables from mu_matrix...\")\n",
    "        mu_df = pd.read_csv(mu_path, sep='\\t', index_col=0, compression='gzip')\n",
    "        \n",
    "        # Only include cells that are in the AnnData object\n",
    "        common_cells = list(set(mu_df.index) & set(adata.obs.index))\n",
    "        if common_cells:\n",
    "            mu_df = mu_df.loc[common_cells]\n",
    "            for col in mu_df.columns:\n",
    "                adata.obs[col] = [mu_df.loc[bc, col] if bc in mu_df.index else np.nan for bc in adata.obs.index]\n",
    "    \n",
    "    print(f\"Loaded data with {adata.n_obs} cells and {adata.n_vars} genes.\")\n",
    "    return adata\n",
    "\n",
    "def harmonize_data(adata):\n",
    "    \"\"\"Harmonize the data according to the specified standards.\"\"\"\n",
    "    print(\"Harmonizing data...\")\n",
    "    \n",
    "    # Add organism information\n",
    "    adata.obs['organism'] = 'Homo sapiens'\n",
    "    \n",
    "    # Add cell_type information (based on the paper, these are K562 cells)\n",
    "    adata.obs['cell_type'] = 'K562'\n",
    "    \n",
    "    # Add CRISPR type information\n",
    "    adata.obs['crispr_type'] = 'CRISPRi'  # Based on the paper, this is CRISPRi\n",
    "    \n",
    "    # Add cancer_type information\n",
    "    adata.obs['cancer_type'] = 'Leukemia'  # K562 is a leukemia cell line\n",
    "    \n",
    "    # Add condition information\n",
    "    # Cells with 'negative' as RBP are controls, others are test\n",
    "    adata.obs['condition'] = 'test'\n",
    "    adata.obs.loc[adata.obs['RBP'] == 'negative', 'condition'] = 'control'\n",
    "    # Also mark cells with unknown RBP as 'unknown'\n",
    "    adata.obs.loc[adata.obs['RBP'] == 'unknown', 'condition'] = 'unknown'\n",
    "    \n",
    "    # Add perturbation_name information\n",
    "    # For control cells, set to 'Non-targeting'\n",
    "    # For test cells, use the RBP name\n",
    "    adata.obs['perturbation_name'] = adata.obs['RBP']\n",
    "    adata.obs.loc[adata.obs['RBP'] == 'negative', 'perturbation_name'] = 'Non-targeting'\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Control cells: {sum(adata.obs['condition'] == 'control')}\")\n",
    "    print(f\"Test cells: {sum(adata.obs['condition'] == 'test')}\")\n",
    "    print(f\"Unknown cells: {sum(adata.obs['condition'] == 'unknown')}\")\n",
    "    \n",
    "    # Print top perturbation targets\n",
    "    perturbation_counts = adata.obs['perturbation_name'].value_counts()\n",
    "    print(\"\\nTop 10 perturbation targets:\")\n",
    "    for target, count in zip(perturbation_counts.index[:10], perturbation_counts.values[:10]):\n",
    "        print(f\"  {target}: {count}\")\n",
    "    \n",
    "    # Add additional metadata\n",
    "    adata.uns['dataset_id'] = DATASET_ID\n",
    "    adata.uns['dataset_description'] = \"Perturb-seq data from RNA-binding proteins knockdown experiment\"\n",
    "    adata.uns['paper_title'] = \"A Unified Framework for Systematic Identification of Post-Transcriptional Regulatory Modules\"\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def main(data_dir, output_file):\n",
    "    \"\"\"Main function to process and harmonize the data.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    # Download the dataset if necessary\n",
    "    download_dataset(data_dir)\n",
    "    \n",
    "    # Load the data\n",
    "    adata = load_data(data_dir)\n",
    "    \n",
    "    # Harmonize the data\n",
    "    adata = harmonize_data(adata)\n",
    "    \n",
    "    # Save the harmonized data\n",
    "    output_path = Path(output_file)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Saving harmonized data to {output_path}...\")\n",
    "    adata.write(output_path)\n",
    "    print(\"Done!\")\n",
    "\n",
    "# Instead of using command-line arguments, set the parameters directly here:\n",
    "data_dir = \"dataa\"  # directory to store or load the dataset\n",
    "output_file = \"GSE225807_harmonized.h5ad\"  # output file path\n",
    "\n",
    "# Run the main function\n",
    "main(data_dir, output_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb20ee-b888-412a-984d-07a386d33f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata = sc.read_h5ad(\"GSE225807_harmonized.h5ad\")\n",
    "\n",
    "\n",
    "\n",
    "# Update condition column\n",
    "adata.obs[\"condition\"] = \"Test\"\n",
    "adata.obs.loc[adata.obs[\"perturbation_name\"] == \"unknown\", \"condition\"] = \"Control\"\n",
    "\n",
    "# Update perturbation_name column\n",
    "adata.obs.loc[adata.obs[\"perturbation_name\"] == \"unknown\", \"perturbation_name\"] = \"Non-targeting\"\n",
    "\n",
    "# # Save back\n",
    "adata.write(\"GSE225807_updated.h5ad\")\n",
    "# print(\"[INFO] Updated file saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
