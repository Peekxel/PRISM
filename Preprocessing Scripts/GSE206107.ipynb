{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import anndata\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Constants\n",
    "GEO_ACCESSION = \"GSE206107\"\n",
    "DOWNLOAD_URL = \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE206107&format=file\"\n",
    "GUIDE_NAMES = ['sgNC1', 'sgNC2', 'sgPrmt1', 'sgRipk1', 'sgAxl']\n",
    "GENE_TARGET_MAP = {\n",
    "    'sgNC1': 'Non-Targeting',\n",
    "    'sgNC2': 'Non-Targeting',\n",
    "    'sgPrmt1': 'Prmt1',\n",
    "    'sgRipk1': 'Ripk1',\n",
    "    'sgAxl': 'Axl'\n",
    "}\n",
    "\n",
    "def download_and_extract(data_dir):\n",
    "    \"\"\"Download and extract the dataset if not already present.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    tar_path = data_dir / f\"{GEO_ACCESSION}_RAW.tar\"\n",
    "    \n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    if not tar_path.exists():\n",
    "        print(f\"Downloading {GEO_ACCESSION} dataset...\")\n",
    "        urllib.request.urlretrieve(DOWNLOAD_URL, tar_path)\n",
    "    \n",
    "    h5_files = list(data_dir.glob(\"*.h5\"))\n",
    "    if not h5_files:\n",
    "        print(f\"Extracting {GEO_ACCESSION}_RAW.tar...\")\n",
    "        with tarfile.open(tar_path, 'r') as tar:\n",
    "            tar.extractall(path=data_dir)\n",
    "        h5_files = list(data_dir.glob(\"*.h5\"))\n",
    "    \n",
    "    return h5_files\n",
    "\n",
    "def parse_filename(filename):\n",
    "    \"\"\"Parse the filename to extract metadata.\"\"\"\n",
    "    basename = os.path.basename(filename)\n",
    "    gsm_id = basename.split('_')[0]\n",
    "    \n",
    "    match = re.match(r'GSM\\d+_(\\d+)-(\\w+)-(\\w+)(?:-v(\\d+))?-(\\w+)\\.h5', basename)\n",
    "    if match:\n",
    "        version_num, seq_type, condition, version, treatment = match.groups()\n",
    "        if version is None:\n",
    "            version = \"1\"\n",
    "        return {\n",
    "            'gsm_id': gsm_id,\n",
    "            'version_num': version_num,\n",
    "            'seq_type': seq_type,\n",
    "            'condition': condition,\n",
    "            'version': f\"v{version}\",\n",
    "            'treatment': treatment\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Could not parse filename: {basename}\")\n",
    "\n",
    "def read_h5_file(file_path):\n",
    "    \"\"\"Read an h5 file and return the gene expression matrix and metadata.\"\"\"\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        if 'matrix' in f:\n",
    "            matrix_group = f['matrix']\n",
    "            data = matrix_group['data'][:]\n",
    "            indices = matrix_group['indices'][:]\n",
    "            indptr = matrix_group['indptr'][:]\n",
    "            shape = matrix_group['shape'][:]\n",
    "            \n",
    "            if 'barcodes' in matrix_group:\n",
    "                barcodes = [bc.decode('utf-8') for bc in matrix_group['barcodes'][:]]\n",
    "            else:\n",
    "                barcodes = [f\"cell_{i}\" for i in range(shape[0])]\n",
    "            \n",
    "            if len(indptr) != len(barcodes) + 1:\n",
    "                n_cells = len(barcodes)\n",
    "                new_indptr = np.zeros(n_cells + 1, dtype=np.int32)\n",
    "                new_indptr[:min(len(indptr), n_cells + 1)] = indptr[:min(len(indptr), n_cells + 1)]\n",
    "                if len(indptr) < n_cells + 1:\n",
    "                    new_indptr[len(indptr):] = indptr[-1]\n",
    "                indptr = new_indptr\n",
    "            \n",
    "            if 'features' in matrix_group:\n",
    "                features_group = matrix_group['features']\n",
    "                feature_ids = [id.decode('utf-8') for id in features_group['id'][:]]\n",
    "                feature_names = [name.decode('utf-8') for name in features_group['name'][:]]\n",
    "                \n",
    "                if 'feature_type' in features_group:\n",
    "                    feature_types = [ft.decode('utf-8') for ft in features_group['feature_type'][:]]\n",
    "                    gene_indices = [i for i, ft in enumerate(feature_types) if ft == 'Gene Expression']\n",
    "                    guide_indices = [i for i, ft in enumerate(feature_types) if ft == 'CRISPR Guide Capture']\n",
    "                    \n",
    "                    gene_ids = [feature_ids[i] for i in gene_indices]\n",
    "                    gene_names = [feature_names[i] for i in gene_indices]\n",
    "                    \n",
    "                    guide_names = [feature_names[i] for i in guide_indices] if guide_indices else None\n",
    "                    \n",
    "                    full_matrix = csr_matrix(\n",
    "                        (data, indices, indptr),\n",
    "                        shape=(len(barcodes), len(feature_names))\n",
    "                    )\n",
    "                    \n",
    "                    gene_expression = full_matrix[:, gene_indices]\n",
    "                    \n",
    "                    guide_counts = None\n",
    "                    if guide_indices:\n",
    "                        guide_counts = full_matrix[:, guide_indices].toarray()\n",
    "                else:\n",
    "                    gene_ids = feature_ids\n",
    "                    gene_names = feature_names\n",
    "                    gene_expression = csr_matrix(\n",
    "                        (data, indices, indptr),\n",
    "                        shape=(len(barcodes), len(feature_names))\n",
    "                    )\n",
    "                    guide_counts = None\n",
    "                    guide_names = None\n",
    "            else:\n",
    "                gene_ids = [f\"gene_{i}\" for i in range(shape[1])]\n",
    "                gene_names = gene_ids\n",
    "                gene_expression = csr_matrix(\n",
    "                    (data, indices, indptr),\n",
    "                    shape=(len(barcodes), len(gene_ids))\n",
    "                )\n",
    "                guide_counts = None\n",
    "                guide_names = None\n",
    "            \n",
    "            return {\n",
    "                'gene_expression': gene_expression,\n",
    "                'gene_ids': gene_ids,\n",
    "                'gene_names': gene_names,\n",
    "                'barcodes': barcodes,\n",
    "                'guide_counts': guide_counts,\n",
    "                'guide_names': guide_names\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Could not find matrix in {file_path}\")\n",
    "\n",
    "def create_anndata(data):\n",
    "    \"\"\"Create an AnnData object from the data.\"\"\"\n",
    "    gene_names = data['gene_names']\n",
    "    if len(set(gene_names)) < len(gene_names):\n",
    "        name_count = {}\n",
    "        unique_gene_names = []\n",
    "        for name in gene_names:\n",
    "            if name in name_count:\n",
    "                name_count[name] += 1\n",
    "                unique_gene_names.append(f\"{name}_{name_count[name]}\")\n",
    "            else:\n",
    "                name_count[name] = 0\n",
    "                unique_gene_names.append(name)\n",
    "        var_index = pd.Index(unique_gene_names)\n",
    "    else:\n",
    "        var_index = pd.Index(gene_names)\n",
    "    \n",
    "    adata = anndata.AnnData(\n",
    "        X=data['gene_expression'],\n",
    "        obs=pd.DataFrame(index=data['barcodes']),\n",
    "        var=pd.DataFrame(index=var_index)\n",
    "    )\n",
    "    \n",
    "    adata.var['ensembl_id'] = data['gene_ids']\n",
    "    \n",
    "    if data['guide_counts'] is not None and data['guide_names'] is not None:\n",
    "        adata.obsm['guide_counts'] = data['guide_counts']\n",
    "        adata.uns['guide_names'] = np.array(data['guide_names'])\n",
    "    \n",
    "    adata.raw = adata.copy()\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def identify_perturbations(adata):\n",
    "    \"\"\"Identify perturbations for each cell based on guide counts.\"\"\"\n",
    "    if 'guide_counts' not in adata.obsm or 'guide_names' not in adata.uns:\n",
    "        print(\"Warning: Guide counts or names not found. Cannot identify perturbations.\")\n",
    "        adata.obs['perturbation_name'] = pd.Categorical(['Unknown'] * adata.n_obs)\n",
    "        adata.obs['perturbation_type'] = pd.Categorical(['Unknown'] * adata.n_obs)\n",
    "        return adata\n",
    "    \n",
    "    guide_counts = adata.obsm['guide_counts']\n",
    "    guide_names = adata.uns['guide_names']\n",
    "    \n",
    "    perturbations = []\n",
    "    for i in range(guide_counts.shape[0]):\n",
    "        cell_guides = guide_counts[i, :]\n",
    "        if np.sum(cell_guides) == 0:\n",
    "            perturbation = \"Unknown\"\n",
    "        else:\n",
    "            threshold = 1\n",
    "            guide_indices = np.where(cell_guides > threshold)[0]\n",
    "            if len(guide_indices) == 0:\n",
    "                perturbation = \"Unknown\"\n",
    "            else:\n",
    "                targets = []\n",
    "                for idx in guide_indices:\n",
    "                    if idx < len(guide_names):\n",
    "                        guide = guide_names[idx]\n",
    "                        if guide in GENE_TARGET_MAP:\n",
    "                            targets.append(GENE_TARGET_MAP[guide])\n",
    "                        else:\n",
    "                            targets.append(guide)\n",
    "                perturbation = \" + \".join(targets)\n",
    "        perturbations.append(perturbation)\n",
    "    \n",
    "    adata.obs['perturbation_name'] = pd.Categorical(perturbations)\n",
    "    \n",
    "    perturbation_types = ['Non-Targeting' if 'Non-Targeting' in x or x == 'Unknown' else 'Targeting' \n",
    "                          for x in perturbations]\n",
    "    adata.obs['perturbation_type'] = pd.Categorical(perturbation_types)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def add_harmonized_metadata(adata, file_info):\n",
    "    \"\"\"Add harmonized metadata to the AnnData object.\"\"\"\n",
    "    adata.obs['organism'] = pd.Categorical(['Mus musculus'] * adata.n_obs)\n",
    "    adata.obs['cell_type'] = pd.Categorical(['MC38 colon cancer cells'] * adata.n_obs)\n",
    "    adata.obs['crispr_type'] = pd.Categorical(['CRISPR KO'] * adata.n_obs)\n",
    "    adata.obs['cancer_type'] = pd.Categorical(['Colon Cancer'] * adata.n_obs)\n",
    "    # The original condition is based on file_info['treatment'],\n",
    "    # but this will be overridden later based on perturbation.\n",
    "    adata.obs['condition'] = pd.Categorical([file_info['treatment']] * adata.n_obs)\n",
    "    adata.obs['seq_type'] = pd.Categorical([file_info['seq_type']] * adata.n_obs)\n",
    "    adata.obs['environment'] = pd.Categorical([file_info['condition']] * adata.n_obs)\n",
    "    adata.obs['version'] = pd.Categorical([file_info['version']] * adata.n_obs)\n",
    "    adata.obs['sample_id'] = pd.Categorical([file_info['gsm_id']] * adata.n_obs)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def process_file(file_path):\n",
    "    \"\"\"Process a single h5 file and return an AnnData object with harmonized metadata.\"\"\"\n",
    "    file_info = parse_filename(file_path)\n",
    "    data = read_h5_file(file_path)\n",
    "    adata = create_anndata(data)\n",
    "    adata = identify_perturbations(adata)\n",
    "    adata = add_harmonized_metadata(adata, file_info)\n",
    "    return adata\n",
    "\n",
    "def main(data_dir):\n",
    "    \"\"\"Process all files, combine them into one AnnData, filter and adjust metadata, then save.\"\"\"\n",
    "    h5_files = download_and_extract(data_dir)\n",
    "    print(f\"Found {len(h5_files)} h5 files to process\")\n",
    "    \n",
    "    adata_list = []\n",
    "    for file_path in h5_files:\n",
    "        print(f\"Processing {os.path.basename(file_path)}...\")\n",
    "        try:\n",
    "            adata = process_file(file_path)\n",
    "            adata_list.append(adata)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "    \n",
    "    if not adata_list:\n",
    "        print(\"No valid AnnData objects processed.\")\n",
    "        return\n",
    "    \n",
    "    # Combine all AnnData objects\n",
    "    combined_adata = anndata.concat(adata_list, join=\"outer\", merge=\"same\")\n",
    "    \n",
    "    # Exclude cells with \"Unknown\" perturbation\n",
    "    combined_adata = combined_adata[combined_adata.obs['perturbation_name'] != \"Unknown\", :].copy()\n",
    "    \n",
    "    # Update condition:\n",
    "    # If perturbation_name is \"Non-targeting\" (case insensitive), set condition to \"Control\",\n",
    "    # otherwise set to \"Test\".\n",
    "    combined_adata.obs['condition'] = combined_adata.obs['perturbation_name'].apply(\n",
    "        lambda x: \"Control\" if str(x).lower() == \"non-targeting\" else \"Test\"\n",
    "    )\n",
    "    \n",
    "    output_path = os.path.join(data_dir, \"combined_harmonized.h5ad\")\n",
    "    combined_adata.write_h5ad(output_path)\n",
    "    print(f\"Combined harmonized data saved to {output_path}\")\n",
    "\n",
    "# In Jupyter, set the data directory and call main()\n",
    "data_dir = \"/content/GSE206107\"\n",
    "main(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
