{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "# Dataset constants\n",
    "GEO_ACCESSION = \"GSE243244\"\n",
    "GEO_URL = \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE243244&format=file\"\n",
    "ORGANISM = \"Mus musculus\"\n",
    "CRISPR_TYPE = \"CRISPR KO\"\n",
    "\n",
    "def download_dataset(data_dir):\n",
    "    \"\"\"Download the dataset if not already present.\"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    tar_path = os.path.join(data_dir, f\"{GEO_ACCESSION}_RAW.tar\")\n",
    "    \n",
    "    if not os.path.exists(tar_path):\n",
    "        print(f\"Downloading {GEO_ACCESSION} dataset...\")\n",
    "        urllib.request.urlretrieve(GEO_URL, tar_path)\n",
    "        print(f\"Downloaded to {tar_path}\")\n",
    "    else:\n",
    "        print(f\"Dataset already downloaded at {tar_path}\")\n",
    "    \n",
    "    # Extract GSM files if needed\n",
    "    gsm_files = glob.glob(os.path.join(data_dir, \"GSM*.tar.gz\"))\n",
    "    if not gsm_files:\n",
    "        with tarfile.open(tar_path) as tar:\n",
    "            for member in tar.getmembers():\n",
    "                if member.name.startswith(\"GSM\") and member.name.endswith(\".tar.gz\"):\n",
    "                    tar.extract(member, path=data_dir)\n",
    "                    print(f\"Extracted {member.name}\")\n",
    "    \n",
    "    return gsm_files or glob.glob(os.path.join(data_dir, \"GSM*.tar.gz\"))\n",
    "\n",
    "def extract_tar_gz(tar_gz_path, extract_dir):\n",
    "    \"\"\"Extract a tar.gz file to a directory.\"\"\"\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall(path=extract_dir)\n",
    "    return extract_dir\n",
    "\n",
    "def read_10x_mtx(path):\n",
    "    \"\"\"Read 10X Genomics formatted matrix files.\"\"\"\n",
    "    mtx_file = os.path.join(path, \"matrix.mtx\")\n",
    "    features_file = os.path.join(path, \"features.tsv\")\n",
    "    barcodes_file = os.path.join(path, \"barcodes.tsv\")\n",
    "    \n",
    "    # Read the matrix\n",
    "    matrix = scipy.io.mmread(mtx_file).T.tocsr()\n",
    "    \n",
    "    # Read features (genes)\n",
    "    features = pd.read_csv(features_file, sep='\\t', header=None)\n",
    "    var_names = features.iloc[:, 1].values  # Use gene symbols\n",
    "    \n",
    "    # Read barcodes\n",
    "    barcodes = pd.read_csv(barcodes_file, sep='\\t', header=None).iloc[:, 0].values\n",
    "    \n",
    "    # Create AnnData object\n",
    "    adata = ad.AnnData(X=matrix, obs=pd.DataFrame(index=barcodes), var=pd.DataFrame(index=var_names))\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def process_perturbation_data(gdo_path, adata):\n",
    "    \"\"\"Process perturbation data and add to AnnData object.\"\"\"\n",
    "    # Read perturbation data\n",
    "    gdo_adata = read_10x_mtx(gdo_path)\n",
    "    \n",
    "    # Find common barcodes\n",
    "    common_barcodes = np.intersect1d(adata.obs.index, gdo_adata.obs.index)\n",
    "    \n",
    "    # Subset both AnnData objects to common barcodes\n",
    "    adata = adata[common_barcodes].copy()\n",
    "    gdo_adata = gdo_adata[common_barcodes].copy()\n",
    "    \n",
    "    # Convert perturbation matrix to dense for easier processing\n",
    "    gdo_matrix = gdo_adata.X.toarray()\n",
    "    \n",
    "    # Determine perturbation for each cell\n",
    "    perturbation_names = []\n",
    "    for i, barcode in enumerate(common_barcodes):\n",
    "        # Get indices of non-zero elements (perturbations)\n",
    "        pert_indices = np.where(gdo_matrix[i] > 0)[0]\n",
    "        \n",
    "        if len(pert_indices) == 0:\n",
    "            # No perturbation detected\n",
    "            perturbation_names.append(\"Non-targeting\")\n",
    "        else:\n",
    "            # Get perturbation names, removing guide numbers\n",
    "            pert_names = []\n",
    "            for idx in pert_indices:\n",
    "                guide_name = gdo_adata.var_names[idx]\n",
    "                # Handle different naming formats\n",
    "                if '-' in guide_name:\n",
    "                    gene_name = guide_name.split('-')[0]\n",
    "                else:\n",
    "                    gene_name = guide_name\n",
    "                \n",
    "                # Clean up gene names\n",
    "                if gene_name.startswith('Random'):\n",
    "                    gene_name = 'Random'\n",
    "                \n",
    "                pert_names.append(gene_name)\n",
    "            \n",
    "            # Remove duplicates and sort\n",
    "            pert_names = sorted(list(set(pert_names)))\n",
    "            \n",
    "            # Join multiple perturbations with +\n",
    "            perturbation_names.append(\" + \".join(pert_names))\n",
    "    \n",
    "    # Add perturbation data to original AnnData\n",
    "    adata.obs['perturbation_name'] = perturbation_names\n",
    "    adata.obs['condition'] = np.where(\n",
    "        adata.obs['perturbation_name'] == \"Non-targeting\", \n",
    "        \"Control\", \n",
    "        \"Test\"\n",
    "    )\n",
    "    \n",
    "    # Store raw perturbation matrix in .obsm\n",
    "    adata.obsm['X_perturbation'] = gdo_matrix\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def process_adt_data(adt_path, adata):\n",
    "    \"\"\"Process ADT (protein) data and add to AnnData object.\"\"\"\n",
    "    # Read ADT data\n",
    "    adt_adata = read_10x_mtx(adt_path)\n",
    "    \n",
    "    # Find common barcodes\n",
    "    common_barcodes = np.intersect1d(adata.obs.index, adt_adata.obs.index)\n",
    "    \n",
    "    # Subset both AnnData objects to common barcodes\n",
    "    adata = adata[common_barcodes].copy()\n",
    "    adt_adata = adt_adata[common_barcodes].copy()\n",
    "    \n",
    "    # Store ADT data in .obsm\n",
    "    adata.obsm['X_adt'] = adt_adata.X\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def process_hto_data(hto_path, adata):\n",
    "    \"\"\"Process HTO (cell hashing) data and add to AnnData object.\"\"\"\n",
    "    # Read HTO data\n",
    "    hto_adata = read_10x_mtx(hto_path)\n",
    "    \n",
    "    # Find common barcodes\n",
    "    common_barcodes = np.intersect1d(adata.obs.index, hto_adata.obs.index)\n",
    "    \n",
    "    # Subset both AnnData objects to common barcodes\n",
    "    adata = adata[common_barcodes].copy()\n",
    "    hto_adata = hto_adata[common_barcodes].copy()\n",
    "    \n",
    "    # Store HTO data in .obsm\n",
    "    adata.obsm['X_hto'] = hto_adata.X\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def process_experiment(data_dir, experiment_name):\n",
    "    \"\"\"Process a single experiment with all its modalities.\"\"\"\n",
    "    print(f\"Processing experiment: {experiment_name}\")\n",
    "    \n",
    "    # Find all modality files for this experiment\n",
    "    cdna_file = glob.glob(os.path.join(data_dir, f\"*{experiment_name}*cDNA*.tar.gz\"))\n",
    "    gdo_file = glob.glob(os.path.join(data_dir, f\"*{experiment_name}*GDO*.tar.gz\"))\n",
    "    adt_file = glob.glob(os.path.join(data_dir, f\"*{experiment_name}*ADT*.tar.gz\"))\n",
    "    hto_file = glob.glob(os.path.join(data_dir, f\"*{experiment_name}*HTO*.tar.gz\"))\n",
    "    \n",
    "    if not cdna_file:\n",
    "        print(f\"No cDNA file found for experiment {experiment_name}. Skipping.\")\n",
    "        return None\n",
    "    \n",
    "    # Extract and process cDNA data\n",
    "    cdna_extract_dir = os.path.join(data_dir, f\"extracted_{experiment_name}_cDNA\")\n",
    "    extract_tar_gz(cdna_file[0], cdna_extract_dir)\n",
    "    \n",
    "    # Find the matrix directory\n",
    "    matrix_dirs = glob.glob(os.path.join(cdna_extract_dir, \"**/matrix.mtx\"), recursive=True)\n",
    "    if not matrix_dirs:\n",
    "        print(f\"No matrix.mtx file found in cDNA extraction for {experiment_name}.\")\n",
    "        return None\n",
    "    cdna_matrix_dir = os.path.dirname(matrix_dirs[0])\n",
    "    \n",
    "    # Read gene expression data\n",
    "    adata = read_10x_mtx(cdna_matrix_dir)\n",
    "    print(f\"Read gene expression data: {adata.shape[0]} cells, {adata.shape[1]} genes\")\n",
    "    \n",
    "    # Process GDO data if available\n",
    "    if gdo_file:\n",
    "        gdo_extract_dir = os.path.join(data_dir, f\"extracted_{experiment_name}_GDO\")\n",
    "        extract_tar_gz(gdo_file[0], gdo_extract_dir)\n",
    "        gdo_matrix_dirs = glob.glob(os.path.join(gdo_extract_dir, \"**/matrix.mtx\"), recursive=True)\n",
    "        if gdo_matrix_dirs:\n",
    "            gdo_matrix_dir = os.path.dirname(gdo_matrix_dirs[0])\n",
    "            adata = process_perturbation_data(gdo_matrix_dir, adata)\n",
    "    else:\n",
    "        # Set default perturbation values\n",
    "        adata.obs['perturbation_name'] = \"Non-targeting\"\n",
    "        adata.obs['condition'] = \"Control\"\n",
    "    \n",
    "    # Process ADT data if available\n",
    "    if adt_file:\n",
    "        adt_extract_dir = os.path.join(data_dir, f\"extracted_{experiment_name}_ADT\")\n",
    "        extract_tar_gz(adt_file[0], adt_extract_dir)\n",
    "        adt_matrix_dirs = glob.glob(os.path.join(adt_extract_dir, \"**/matrix.mtx\"), recursive=True)\n",
    "        if adt_matrix_dirs:\n",
    "            adt_matrix_dir = os.path.dirname(adt_matrix_dirs[0])\n",
    "            adata = process_adt_data(adt_matrix_dir, adata)\n",
    "    \n",
    "    # Process HTO data if available\n",
    "    if hto_file:\n",
    "        hto_extract_dir = os.path.join(data_dir, f\"extracted_{experiment_name}_HTO\")\n",
    "        extract_tar_gz(hto_file[0], hto_extract_dir)\n",
    "        hto_matrix_dirs = glob.glob(os.path.join(hto_extract_dir, \"**/matrix.mtx\"), recursive=True)\n",
    "        if hto_matrix_dirs:\n",
    "            hto_matrix_dir = os.path.dirname(hto_matrix_dirs[0])\n",
    "            adata = process_hto_data(hto_matrix_dir, adata)\n",
    "    \n",
    "    # Add standardized metadata\n",
    "    adata.obs['organism'] = ORGANISM\n",
    "    adata.obs['crispr_type'] = CRISPR_TYPE\n",
    "    adata.obs['cancer_type'] = \"Non-Cancer\"\n",
    "    \n",
    "    # Set experiment-specific metadata\n",
    "    if experiment_name == \"TCell\":\n",
    "        adata.obs['cell_type'] = \"T Cells\"\n",
    "    elif experiment_name == \"Splenocytes\":\n",
    "        adata.obs['cell_type'] = \"Splenocytes\"\n",
    "    elif experiment_name in [\"Invivo\", \"Invivo_B16\"]:\n",
    "        adata.obs['cell_type'] = \"Bone marrow dendritic cells\"\n",
    "        adata.obs['cancer_type'] = \"Melanoma\"\n",
    "    else:\n",
    "        adata.obs['cell_type'] = \"Bone marrow dendritic cells\"\n",
    "    \n",
    "    # Add experiment type\n",
    "    adata.obs['experiment_type'] = experiment_name\n",
    "    \n",
    "    # Add a unique cell ID\n",
    "    adata.obs['cell_id'] = [f\"{experiment_name}_{i}\" for i in range(adata.n_obs)]\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def main(data_dir=None):\n",
    "    \"\"\"Main function to process and harmonize the dataset.\"\"\"\n",
    "    if data_dir is None:\n",
    "        # By default, use the current working directory\n",
    "        data_dir = os.getcwd()\n",
    "    \n",
    "    # Download and extract data\n",
    "    gsm_files = download_dataset(data_dir)\n",
    "    \n",
    "    # Identify unique experiments\n",
    "    experiments = set()\n",
    "    for gsm_file in gsm_files:\n",
    "        filename = os.path.basename(gsm_file)\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 2:\n",
    "            experiment_name = parts[1].split('.')[0]\n",
    "            if experiment_name in ['cDNA', 'GDO', 'ADT', 'HTO']:\n",
    "                # This is a modality file, extract the experiment name\n",
    "                experiment_name = parts[0].replace(\"GSM\", \"\")\n",
    "            experiments.add(experiment_name)\n",
    "    \n",
    "    print(f\"Found {len(experiments)} experiments: {experiments}\")\n",
    "    \n",
    "    # Process each experiment\n",
    "    all_adatas = []\n",
    "    for experiment in experiments:\n",
    "        adata = process_experiment(data_dir, experiment)\n",
    "        if adata is not None:\n",
    "            all_adatas.append(adata)\n",
    "    \n",
    "    # Combine all experiments\n",
    "    if len(all_adatas) > 1:\n",
    "        # Use cell_id as index to avoid duplicate index issues\n",
    "        for adata in all_adatas:\n",
    "            adata.obs_names = adata.obs['cell_id']\n",
    "        \n",
    "        combined_adata = ad.concat(all_adatas, join='outer', merge='same')\n",
    "    elif len(all_adatas) == 1:\n",
    "        combined_adata = all_adatas[0]\n",
    "        combined_adata.obs_names = combined_adata.obs['cell_id']\n",
    "    else:\n",
    "        print(\"No experiments processed. Exiting.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Combined dataset: {combined_adata.shape[0]} cells, {combined_adata.shape[1]} genes\")\n",
    "    \n",
    "    # Convert categorical columns\n",
    "    for col in ['perturbation_name', 'condition', 'organism', 'cell_type', 'crispr_type', 'cancer_type', 'experiment_type']:\n",
    "        if col in combined_adata.obs.columns:\n",
    "            combined_adata.obs[col] = combined_adata.obs[col].astype('category')\n",
    "    \n",
    "    # Save harmonized data\n",
    "    output_path = os.path.join(data_dir, f\"{GEO_ACCESSION}_harmonized.h5ad\")\n",
    "    combined_adata.write(output_path)\n",
    "    print(f\"Harmonized data saved to {output_path}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# For Jupyter Notebook, simply call main() with the desired data directory (or leave empty to use the current directory)\n",
    "data_dir = None  # Change to a specific path if needed, e.g. data_dir = \"/path/to/data\"\n",
    "output_file = main(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
