{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import tarfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from scipy import sparse, io\n",
    "\n",
    "def download_file(url, destination):\n",
    "    \"\"\"\n",
    "    Download a file from a URL to a destination path.\n",
    "    \n",
    "    Args:\n",
    "        url: URL to download from\n",
    "        destination: Path to save the file to\n",
    "    \"\"\"\n",
    "    if os.path.exists(destination):\n",
    "        print(f\"File {destination} already exists, skipping download\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Downloading {url} to {destination}\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024\n",
    "    \n",
    "    with open(destination, 'wb') as f:\n",
    "        for data in tqdm(response.iter_content(block_size), total=total_size//block_size, unit='KB'):\n",
    "            f.write(data)\n",
    "\n",
    "def download_and_extract_gse263747(data_dir):\n",
    "    \"\"\"\n",
    "    Download and extract GSE263747 dataset files if they don't exist.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory to save the files to\n",
    "    \"\"\"\n",
    "    base_url = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE263nnn/GSE263747/suppl\"\n",
    "    tar_file = os.path.join(data_dir, \"GSE263747_RAW.tar\")\n",
    "    \n",
    "    # Download the tar file if it doesn't exist\n",
    "    if not os.path.exists(tar_file):\n",
    "        download_file(f\"{base_url}/GSE263747_RAW.tar\", tar_file)\n",
    "    \n",
    "    # Extract files if they don't exist\n",
    "    if not os.path.exists(os.path.join(data_dir, \"GSM8197841_SNU_D5_GEX_matrix.mtx.gz\")):\n",
    "        print(f\"Extracting {tar_file} to {data_dir}\")\n",
    "        with tarfile.open(tar_file) as tar:\n",
    "            tar.extractall(path=data_dir)\n",
    "\n",
    "def read_10x_mtx(matrix_file, features_file, barcodes_file):\n",
    "    \"\"\"\n",
    "    Read 10x data in MTX format.\n",
    "    \n",
    "    Args:\n",
    "        matrix_file: Path to the matrix.mtx.gz file\n",
    "        features_file: Path to the features.tsv.gz file\n",
    "        barcodes_file: Path to the barcodes.tsv.gz file\n",
    "        \n",
    "    Returns:\n",
    "        X: Sparse matrix (cells x genes)\n",
    "        var_df: DataFrame with gene information\n",
    "        obs_df: DataFrame with cell information\n",
    "    \"\"\"\n",
    "    # Read the matrix\n",
    "    with gzip.open(matrix_file, 'rb') as f:\n",
    "        X = io.mmread(f).tocsr().T  # Transpose to get cells x genes\n",
    "    \n",
    "    # Read features (genes)\n",
    "    with gzip.open(features_file, 'rt') as f:\n",
    "        var_df = pd.read_csv(f, sep='\\t', header=None)\n",
    "        var_df.columns = ['gene_ids', 'gene_symbols', 'feature_types'] if var_df.shape[1] >= 3 else ['gene_ids', 'gene_symbols']\n",
    "    \n",
    "    # Read barcodes (cells)\n",
    "    with gzip.open(barcodes_file, 'rt') as f:\n",
    "        barcodes = pd.read_csv(f, sep='\\t', header=None)[0].values\n",
    "    \n",
    "    # Create observation DataFrame\n",
    "    obs_df = pd.DataFrame(index=barcodes)\n",
    "    \n",
    "    return X, var_df, obs_df\n",
    "\n",
    "def read_sgRNA_data(matrix_file, features_file, barcodes_file):\n",
    "    \"\"\"\n",
    "    Read sgRNA data in MTX format.\n",
    "    \n",
    "    Args:\n",
    "        matrix_file: Path to the matrix.mtx.gz file\n",
    "        features_file: Path to the features.tsv.gz file\n",
    "        barcodes_file: Path to the barcodes.tsv.gz file\n",
    "        \n",
    "    Returns:\n",
    "        sgRNA_df: DataFrame with sgRNA counts\n",
    "        features_df: DataFrame with sgRNA information\n",
    "    \"\"\"\n",
    "    # Read the matrix\n",
    "    with gzip.open(matrix_file, 'rb') as f:\n",
    "        X = io.mmread(f).tocsr().T  # Transpose to get cells x sgRNAs\n",
    "    \n",
    "    # Read features (sgRNAs)\n",
    "    with gzip.open(features_file, 'rt') as f:\n",
    "        features_df = pd.read_csv(f, sep='\\t', header=None)\n",
    "    \n",
    "    # Read barcodes (cells)\n",
    "    with gzip.open(barcodes_file, 'rt') as f:\n",
    "        barcodes = pd.read_csv(f, sep='\\t', header=None)[0].values\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    sgRNA_df = pd.DataFrame(\n",
    "        X.toarray(),\n",
    "        index=barcodes,\n",
    "        columns=features_df[0].values\n",
    "    )\n",
    "    \n",
    "    return sgRNA_df, features_df\n",
    "\n",
    "def parse_sgRNA_target(sgRNA_info):\n",
    "    \"\"\"\n",
    "    Parse sgRNA information to extract target gene.\n",
    "    \n",
    "    Args:\n",
    "        sgRNA_info: String with sgRNA information\n",
    "        \n",
    "    Returns:\n",
    "        Target gene name\n",
    "    \"\"\"\n",
    "    if isinstance(sgRNA_info, str):\n",
    "        if \"non-targeting\" in sgRNA_info.lower() or \"nt\" in sgRNA_info.lower():\n",
    "            return \"Non-targeting\"\n",
    "        else:\n",
    "            # Extract gene name from sgRNA info (format varies)\n",
    "            parts = sgRNA_info.split('_')\n",
    "            if len(parts) > 1:\n",
    "                return parts[0]\n",
    "            else:\n",
    "                return sgRNA_info\n",
    "    return \"unknown\"\n",
    "\n",
    "def process_gse263747(data_dir):\n",
    "    \"\"\"\n",
    "    Process GSE263747 dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the dataset files\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of AnnData objects for each timepoint\n",
    "    \"\"\"\n",
    "    # File paths\n",
    "    day5_gex_matrix = os.path.join(data_dir, \"GSM8197841_SNU_D5_GEX_matrix.mtx.gz\")\n",
    "    day5_gex_features = os.path.join(data_dir, \"GSM8197841_SNU_D5_GEX_features.tsv.gz\")\n",
    "    day5_gex_barcodes = os.path.join(data_dir, \"GSM8197841_SNU_D5_GEX_barcodes.tsv.gz\")\n",
    "    \n",
    "    day10_gex_matrix = os.path.join(data_dir, \"GSM8197842_SNU_D10_GEX_matrix.mtx.gz\")\n",
    "    day10_gex_features = os.path.join(data_dir, \"GSM8197842_SNU_D10_GEX_features.tsv.gz\")\n",
    "    day10_gex_barcodes = os.path.join(data_dir, \"GSM8197842_SNU_D10_GEX_barcodes.tsv.gz\")\n",
    "    \n",
    "    day5_sgRNA_matrix = os.path.join(data_dir, \"GSM8197843_SNU_D5_sgRNA_matrix.mtx.gz\")\n",
    "    day5_sgRNA_features = os.path.join(data_dir, \"GSM8197843_SNU_D5_sgRNA_features.tsv.gz\")\n",
    "    day5_sgRNA_barcodes = os.path.join(data_dir, \"GSM8197843_SNU_D5_sgRNA_barcodes.tsv.gz\")\n",
    "    \n",
    "    day10_sgRNA_matrix = os.path.join(data_dir, \"GSM8197844_SNU_D10_sgRNA_matrix.mtx.gz\")\n",
    "    day10_sgRNA_features = os.path.join(data_dir, \"GSM8197844_SNU_D10_sgRNA_features.tsv.gz\")\n",
    "    day10_sgRNA_barcodes = os.path.join(data_dir, \"GSM8197844_SNU_D10_sgRNA_barcodes.tsv.gz\")\n",
    "    \n",
    "    # Process day 5 data\n",
    "    print(\"Processing day5 data...\")\n",
    "    day5_X, day5_var_df, day5_obs_df = read_10x_mtx(day5_gex_matrix, day5_gex_features, day5_gex_barcodes)\n",
    "    day5_sgRNA_df, day5_sgRNA_features_df = read_sgRNA_data(day5_sgRNA_matrix, day5_sgRNA_features, day5_sgRNA_barcodes)\n",
    "    \n",
    "    # Process day 10 data\n",
    "    print(\"Processing day10 data...\")\n",
    "    day10_X, day10_var_df, day10_obs_df = read_10x_mtx(day10_gex_matrix, day10_gex_features, day10_gex_barcodes)\n",
    "    day10_sgRNA_df, day10_sgRNA_features_df = read_sgRNA_data(day10_sgRNA_matrix, day10_sgRNA_features, day10_sgRNA_barcodes)\n",
    "    \n",
    "    # Create sgRNA to target gene mapping\n",
    "    sgRNA_to_gene = {}\n",
    "    for _, row in day5_sgRNA_features_df.iterrows():\n",
    "        sgRNA_id = row[0]\n",
    "        sgRNA_info = row[1] if len(row) > 1 else \"unknown\"\n",
    "        target_gene = parse_sgRNA_target(sgRNA_info)\n",
    "        sgRNA_to_gene[sgRNA_id] = target_gene\n",
    "    \n",
    "    # For each cell, find the sgRNA with the highest count\n",
    "    day5_sgRNA_assignments = day5_sgRNA_df.idxmax(axis=1)\n",
    "    day10_sgRNA_assignments = day10_sgRNA_df.idxmax(axis=1)\n",
    "    \n",
    "    # Add sgRNA and target gene information to observation DataFrames\n",
    "    day5_obs_df['sgRNA'] = day5_sgRNA_assignments\n",
    "    day5_obs_df['perturbation_name'] = day5_sgRNA_assignments.map(sgRNA_to_gene)\n",
    "    day5_obs_df['timepoint'] = 'day5'\n",
    "    \n",
    "    day10_obs_df['sgRNA'] = day10_sgRNA_assignments\n",
    "    day10_obs_df['perturbation_name'] = day10_sgRNA_assignments.map(sgRNA_to_gene)\n",
    "    day10_obs_df['timepoint'] = 'day10'\n",
    "    \n",
    "    # Create AnnData objects\n",
    "    day5_adata = ad.AnnData(X=day5_X, obs=day5_obs_df, var=pd.DataFrame(index=day5_var_df['gene_symbols'].values))\n",
    "    day5_adata.var['gene_ids'] = day5_var_df['gene_ids'].values\n",
    "    if 'feature_types' in day5_var_df.columns:\n",
    "        day5_adata.var['feature_types'] = day5_var_df['feature_types'].values\n",
    "    \n",
    "    day10_adata = ad.AnnData(X=day10_X, obs=day10_obs_df, var=pd.DataFrame(index=day10_var_df['gene_symbols'].values))\n",
    "    day10_adata.var['gene_ids'] = day10_var_df['gene_ids'].values\n",
    "    if 'feature_types' in day10_var_df.columns:\n",
    "        day10_adata.var['feature_types'] = day10_var_df['feature_types'].values\n",
    "    \n",
    "    return {'day5': day5_adata, 'day10': day10_adata}\n",
    "\n",
    "def harmonize_gse263747(data_dir):\n",
    "    \"\"\"\n",
    "    Harmonize GSE263747 dataset into h5ad format.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the dataset files\n",
    "    \"\"\"\n",
    "    # Download and extract data if needed\n",
    "    download_and_extract_gse263747(data_dir)\n",
    "    \n",
    "    # Process data\n",
    "    adatas = process_gse263747(data_dir)\n",
    "    \n",
    "    # Harmonize metadata and save individual timepoint datasets\n",
    "    for timepoint, adata in adatas.items():\n",
    "        # Add standardized metadata\n",
    "        adata.obs['organism'] = 'Homo sapiens'\n",
    "        adata.obs['cell_type'] = 'SNU-761 liver cancer cells'\n",
    "        adata.obs['crispr_type'] = 'CRISPR KO'\n",
    "        adata.obs['cancer_type'] = 'Liver Cancer'\n",
    "        \n",
    "        # For each cell, set condition to \"Control\" if perturbation_name is exactly \"Non-targeting\",\n",
    "        # otherwise keep the timepoint.\n",
    "        adata.obs['condition'] = adata.obs.apply(\n",
    "            lambda row: \"Control\" if row['perturbation_name'] == \"Non-targeting\" else timepoint, axis=1\n",
    "        )\n",
    "        \n",
    "        # Save harmonized data for this timepoint\n",
    "        output_file = os.path.join(data_dir, f\"GSE263747_{timepoint}_harmonized.h5ad\")\n",
    "        print(f\"Saving harmonized data to {output_file}\")\n",
    "        adata.write(output_file)\n",
    "    \n",
    "    # Create a combined dataset\n",
    "    combined_adata = ad.concat(\n",
    "        adatas.values(),\n",
    "        label=\"timepoint\",\n",
    "        keys=list(adatas.keys()),\n",
    "        index_unique='-'\n",
    "    )\n",
    "    \n",
    "    # Save combined dataset\n",
    "    output_file = os.path.join(data_dir, \"GSE263747_combined_harmonized.h5ad\")\n",
    "    print(f\"Saving combined harmonized data to {output_file}\")\n",
    "    combined_adata.write(output_file)\n",
    "    \n",
    "    print(\"\\nHarmonization complete!\")\n",
    "    print(f\"Dataset summary:\")\n",
    "    print(f\"  - Number of cells: {combined_adata.n_obs}\")\n",
    "    print(f\"  - Number of genes: {combined_adata.n_vars}\")\n",
    "    print(f\"  - Organism: Homo sapiens\")\n",
    "    print(f\"  - Cell type: SNU-761 liver cancer cells\")\n",
    "    print(f\"  - CRISPR type: CRISPR KO\")\n",
    "    print(f\"  - Cancer type: Liver Cancer\")\n",
    "    print(f\"  - Timepoints: day5, day10\")\n",
    "    print(f\"  - Number of perturbations: {combined_adata.obs['perturbation_name'].nunique()}\")\n",
    "\n",
    "\n",
    "# Define the data directory. You can change this to a desired path.\n",
    "data_dir = os.getcwd()  # or set to another directory, e.g., \"/path/to/data\"\n",
    "\n",
    "# Run the harmonization process\n",
    "harmonize_gse263747(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b38bd-1bdb-4f0a-801c-082ce9d71f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
