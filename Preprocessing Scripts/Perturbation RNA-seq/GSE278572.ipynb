{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b71e6-10e7-41c9-9a5b-f5b8e70c95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import scipy.sparse as sp\n",
    "import re\n",
    "import gzip\n",
    "import urllib.request\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def download_file(url, output_path, chunk_size=8192):\n",
    "    \"\"\"\n",
    "    Download a file from a URL with progress reporting.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    url : str\n",
    "        URL to download from.\n",
    "    output_path : str or Path\n",
    "        Path to save the downloaded file.\n",
    "    chunk_size : int, optional\n",
    "        Size of chunks to download at a time.\n",
    "    \"\"\"\n",
    "    # Create parent directory if it doesn't exist\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Start the download\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            total_size = int(response.info().get('Content-Length', 0))\n",
    "            downloaded_size = 0\n",
    "            \n",
    "            with open(output_path, 'wb') as f:\n",
    "                while True:\n",
    "                    chunk = response.read(chunk_size)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    \n",
    "                    f.write(chunk)\n",
    "                    downloaded_size += len(chunk)\n",
    "                    \n",
    "                    # Calculate progress\n",
    "                    progress = downloaded_size / total_size * 100 if total_size > 0 else 0\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    speed = downloaded_size / (1024 * 1024 * elapsed_time) if elapsed_time > 0 else 0\n",
    "                    \n",
    "                    # Print progress\n",
    "                    if total_size > 0:\n",
    "                        print(f\"\\rDownloading: {progress:.1f}% ({downloaded_size/(1024*1024):.1f} MB / {total_size/(1024*1024):.1f} MB) at {speed:.2f} MB/s\", end='')\n",
    "                    else:\n",
    "                        print(f\"\\rDownloaded: {downloaded_size/(1024*1024):.1f} MB at {speed:.2f} MB/s\", end='')\n",
    "        \n",
    "        print(f\"\\nDownload completed: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError downloading {url}: {e}\")\n",
    "        if output_path.exists():\n",
    "            output_path.unlink()  # Remove partial download\n",
    "        raise\n",
    "\n",
    "def process_GSE278572(data_dir, skip_matrix=False):\n",
    "    \"\"\"\n",
    "    Process GSE278572 dataset and convert to h5ad format.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dir : str\n",
    "        Path to directory containing the dataset files.\n",
    "    skip_matrix : bool, optional\n",
    "        If True, skip downloading the large matrix file and create a placeholder matrix.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    adata : AnnData\n",
    "        Processed dataset in AnnData format.\n",
    "    \"\"\"\n",
    "    print(f\"Processing GSE278572 dataset from {data_dir}\")\n",
    "    \n",
    "    # Convert to Path object\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    # Define required files and their URLs\n",
    "    required_files = {\n",
    "        \"GSE278572_barcodes.tsv.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE278nnn/GSE278572/suppl/GSE278572_barcodes.tsv.gz\",\n",
    "        \"GSE278572_features.tsv.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE278nnn/GSE278572/suppl/GSE278572_features.tsv.gz\",\n",
    "        \"GSE278572_matrix.mtx.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE278nnn/GSE278572/suppl/GSE278572_matrix.mtx.gz\",\n",
    "        \"GSE278572_protospacer_calls_per_cell.csv.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE278nnn/GSE278572/suppl/GSE278572_protospacer_calls_per_cell.csv.gz\"\n",
    "    }\n",
    "    \n",
    "    # Check if files exist and download if needed\n",
    "    for file, url in required_files.items():\n",
    "        file_path = data_dir / file\n",
    "        \n",
    "        # Skip matrix file if requested\n",
    "        if skip_matrix and file == \"GSE278572_matrix.mtx.gz\":\n",
    "            print(f\"Skipping download of large matrix file {file} as requested.\")\n",
    "            continue\n",
    "            \n",
    "        if not file_path.exists():\n",
    "            print(f\"File {file} not found. Downloading from {url}...\")\n",
    "            download_file(url, file_path)\n",
    "        else:\n",
    "            print(f\"File {file} already exists.\")\n",
    "    \n",
    "    # Read the 10X format data\n",
    "    print(\"Reading 10X format data...\")\n",
    "    try:\n",
    "        adata = sc.read_10x_mtx(\n",
    "            data_dir,\n",
    "            var_names='gene_symbols',\n",
    "            cache=True,\n",
    "            prefix=\"GSE278572_\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading 10X data: {e}\")\n",
    "        print(\"Creating a placeholder AnnData object with perturbation data only...\")\n",
    "        \n",
    "        # Read barcodes and features to create a placeholder AnnData object\n",
    "        barcodes = []\n",
    "        with gzip.open(data_dir / \"GSE278572_barcodes.tsv.gz\", 'rt') as f:\n",
    "            for line in f:\n",
    "                barcodes.append(line.strip())\n",
    "        \n",
    "        features = []\n",
    "        with gzip.open(data_dir / \"GSE278572_features.tsv.gz\", 'rt') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 2:\n",
    "                    features.append(parts[1])  # Use gene symbol\n",
    "        \n",
    "        # Create a placeholder matrix\n",
    "        placeholder_matrix = sp.csr_matrix((len(barcodes), len(features)), dtype=np.float32)\n",
    "        \n",
    "        # Create AnnData object\n",
    "        adata = ad.AnnData(\n",
    "            X=placeholder_matrix,\n",
    "            obs=pd.DataFrame(index=barcodes),\n",
    "            var=pd.DataFrame(index=features)\n",
    "        )\n",
    "        \n",
    "        print(f\"Created placeholder AnnData with {len(barcodes)} cells and {len(features)} genes\")\n",
    "        print(\"WARNING: Gene expression data is not available, only perturbation information will be processed\")\n",
    "    \n",
    "    # Read perturbation data\n",
    "    print(\"Reading perturbation data...\")\n",
    "    perturbation_df = pd.read_csv(data_dir / \"GSE278572_protospacer_calls_per_cell.csv.gz\")\n",
    "    \n",
    "    # Process perturbation data\n",
    "    print(\"Processing perturbation data...\")\n",
    "    \n",
    "    # Create a dictionary to map cell barcodes to perturbations\n",
    "    cell_to_perturbation = dict(zip(perturbation_df['cell_barcode'], perturbation_df['feature_call']))\n",
    "    \n",
    "    # Add perturbation information to adata.obs\n",
    "    adata.obs['perturbation'] = adata.obs.index.map(lambda x: cell_to_perturbation.get(x, 'Unknown'))\n",
    "    \n",
    "    # Add number of guides per cell\n",
    "    adata.obs['num_guides'] = adata.obs['perturbation'].apply(\n",
    "        lambda x: 0 if x == 'Unknown' else len(x.split('|'))\n",
    "    )\n",
    "    \n",
    "    # Function to extract perturbation information\n",
    "    def extract_perturbation_info(perturbation_str):\n",
    "        if pd.isna(perturbation_str) or perturbation_str == 'Unknown':\n",
    "            return pd.Series({\n",
    "                'perturbation_type': 'Unknown',\n",
    "                'target_genes': 'Unknown',\n",
    "                'is_control': False,\n",
    "                'guide_ids': 'Unknown'\n",
    "            })\n",
    "        \n",
    "        # Split multiple perturbations\n",
    "        perturbations = perturbation_str.split('|')\n",
    "        \n",
    "        # Extract information from each perturbation\n",
    "        target_genes = []\n",
    "        guide_ids = []\n",
    "        perturbation_types = set()\n",
    "        is_control = True\n",
    "        has_targeting = False\n",
    "        \n",
    "        for pert in perturbations:\n",
    "            parts = pert.split('_')\n",
    "            if len(parts) >= 3:\n",
    "                gene = parts[0]\n",
    "                guide = parts[1]\n",
    "                pert_type = '_'.join(parts[2:])  # In case there are multiple parts after the guide\n",
    "                \n",
    "                guide_ids.append(f\"{gene}_{guide}\")\n",
    "                \n",
    "                if 'Non-Targeting' in gene:\n",
    "                    # This is a control perturbation\n",
    "                    pass\n",
    "                else:\n",
    "                    # This is a targeting perturbation\n",
    "                    has_targeting = True\n",
    "                    target_genes.append(gene)\n",
    "                \n",
    "                perturbation_types.add(pert_type)\n",
    "        \n",
    "        # If there are any targeting guides, this is not a control\n",
    "        is_control = not has_targeting\n",
    "        \n",
    "        # Join target genes with + for multiple perturbations\n",
    "        target_genes_str = '+'.join(sorted(set(target_genes))) if target_genes else 'Non-Targeting'\n",
    "        \n",
    "        # Join guide IDs\n",
    "        guide_ids_str = '|'.join(sorted(guide_ids))\n",
    "        \n",
    "        # Join perturbation types\n",
    "        perturbation_type_str = '+'.join(sorted(perturbation_types))\n",
    "        \n",
    "        return pd.Series({\n",
    "            'perturbation_type': perturbation_type_str,\n",
    "            'target_genes': target_genes_str,\n",
    "            'is_control': is_control,\n",
    "            'guide_ids': guide_ids_str\n",
    "        })\n",
    "    \n",
    "    # Apply the function to extract perturbation information\n",
    "    perturbation_info = adata.obs['perturbation'].apply(extract_perturbation_info)\n",
    "    adata.obs = pd.concat([adata.obs, perturbation_info], axis=1)\n",
    "    \n",
    "    # Set condition based on perturbation\n",
    "    adata.obs['condition'] = adata.obs['is_control'].map({True: 'Control', False: 'Test'})\n",
    "    \n",
    "    # Based on the dataset description, this is a human T cell dataset\n",
    "    adata.obs['organism'] = 'Homo sapiens'\n",
    "    adata.obs['cell_type'] = 'CD4+ T Cells'\n",
    "    \n",
    "    # From the dataset description, we know this includes resting and stimulated CD4+ Tregs and Teffs\n",
    "    adata.obs['stimulation_status'] = 'Unknown'\n",
    "    adata.obs['t_cell_subtype'] = 'Unknown'\n",
    "    \n",
    "    # Extract CRISPR type from perturbation data\n",
    "    adata.obs['crispr_type'] = 'CRISPRi'\n",
    "    \n",
    "    # Based on the dataset description, this is non-cancer\n",
    "    adata.obs['cancer_type'] = 'Non-Cancer'\n",
    "    \n",
    "    # Harmonize column names to match the requested format\n",
    "    adata.obs.rename(columns={\n",
    "        'target_genes': 'perturbation_name'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Add statistics about the dataset\n",
    "    adata.uns['perturbation_stats'] = {\n",
    "        'total_cells': adata.n_obs,\n",
    "        'control_cells': adata.obs['is_control'].sum(),\n",
    "        'test_cells': (~adata.obs['is_control']).sum(),\n",
    "        'unique_target_genes': len(adata.obs['perturbation_name'].unique()),\n",
    "        'crispr_types': 'CRISPRi'\n",
    "    }\n",
    "    \n",
    "    # Preserve the raw counts\n",
    "    adata.raw = adata.copy()\n",
    "    \n",
    "    # Add additional metadata based on the dataset description and our analysis\n",
    "    adata.uns['dataset_metadata'] = {\n",
    "        'accession': 'GSE278572',\n",
    "        'title': 'Centralized control of dynamic gene regulatory circuits governs human T cell rest and activation [Perturb-CITE-seq]',\n",
    "        'description': 'Perturb-CITE-seq performed with 2 donors including resting and stimulated CD4+ Tregs and Teffs',\n",
    "        'organism': 'Homo sapiens',\n",
    "        'experiment_type': 'Perturb-CITE-seq',\n",
    "        'contributors': 'Arce MM, Umhoefer JM, Arang N, Kasinathan S, Freimer JW, Steinhart Z, Shen H, Pham M, Ota M, Wadhera A, Dorovskyi D, Zhou Y, Rama D, Chen Y, Liu Q, Shy BR, Satpathy AT, Carnevale J, Krogan NJ, Pritchard JK, Marson A',\n",
    "        'perturbation_summary': 'The dataset contains 28 unique target genes with CRISPRi perturbations. About 73% of cells have a single guide, 20% have two guides, and the rest have multiple guides. Approximately 12% of cells are controls (non-targeting guides only).'\n",
    "    }\n",
    "    \n",
    "    print(f\"Processed dataset with {adata.n_obs} cells and {adata.n_vars} genes\")\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def update_adata(adata):\n",
    "    # Ensure 'perturbation_name' and 'condition' are not categorical\n",
    "    if pd.api.types.is_categorical_dtype(adata.obs['perturbation_name']):\n",
    "        adata.obs['perturbation_name'] = adata.obs['perturbation_name'].astype(str)\n",
    "    if pd.api.types.is_categorical_dtype(adata.obs['condition']):\n",
    "        adata.obs['condition'] = adata.obs['condition'].astype(str)\n",
    "    \n",
    "    # Change 'Unknown' to 'Non-targeting' in 'perturbation_name' column\n",
    "    # and set 'condition' to 'Control' for the same rows\n",
    "    mask = adata.obs['perturbation_name'] == 'Unknown'\n",
    "    adata.obs.loc[mask, 'perturbation_name'] = 'Non-targeting'\n",
    "    adata.obs.loc[mask, 'condition'] = 'Control'\n",
    "    \n",
    "    return adata\n",
    "\n",
    "# ----- Parameters for Jupyter Notebook Execution -----\n",
    "data_dir = \"/content\"  # Set your data directory. This directory will be created if it doesn't exist.\n",
    "skip_matrix = False    # Set to True to skip downloading the large matrix file and create a placeholder matrix.\n",
    "output_path = os.path.join(data_dir, \"GSE278572.h5ad\")  # Define output file path\n",
    "\n",
    "# Create the data directory if it doesn't exist\n",
    "Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process the dataset\n",
    "adata = process_GSE278572(data_dir, skip_matrix=skip_matrix)\n",
    "\n",
    "# Incorporate adhoc change by updating the AnnData object\n",
    "adata = update_adata(adata)\n",
    "print(adata.obs)\n",
    "\n",
    "# Save the processed AnnData object to h5ad file\n",
    "print(f\"Saving processed dataset to {output_path}\")\n",
    "adata.write(output_path)\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
