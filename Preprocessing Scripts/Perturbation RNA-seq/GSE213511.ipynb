{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import urllib.request\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from scipy.sparse import csc_matrix\n",
    "import re\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import anndata  # for concatenating AnnData objects\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler('harmonize_GSE213511.log')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# URLs for the dataset files\n",
    "FILE_URLS = {\n",
    "    # H5 files\n",
    "    'GSE213511_DM_CITEseq-1_NA_NM_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_DM_CITEseq-1_NA_NM_1.h5',\n",
    "    'GSE213511_DM_CITEseq-2_NA_NM_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_DM_CITEseq-2_NA_NM_1.h5',\n",
    "    'GSE213511_DM_OP0_NM_6d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_DM_OP0_NM_6d_1.h5',\n",
    "    'GSE213511_DM_OP1_NM_6d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_DM_OP1_NM_6d_1.h5',\n",
    "    'GSE213511_DM_OP1_NM_6d_2.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_DM_OP1_NM_6d_2.h5',\n",
    "    'GSE213511_DM_OP2_NM_6d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_DM_OP2_NM_6d_1.h5',\n",
    "    'GSE213511_DM_OP2_NM_6d_2.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_DM_OP2_NM_6d_2.h5',\n",
    "    'GSE213511_DM_OP2_NM_6d_3.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_DM_OP2_NM_6d_3.h5',\n",
    "    'GSE213511_DM_OP3_NM_6d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_DM_OP3_NM_6d_1.h5',\n",
    "    'GSE213511_DM_OP4_NM_6d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_DM_OP4_NM_6d_1.h5',\n",
    "    'GSE213511_DM_OP5_NM_6d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_DM_OP5_NM_6d_1.h5',\n",
    "    'GSE213511_DM_Test1_NM_6d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_DM_Test1_NM_6d_1.h5',\n",
    "    'GSE213511_DM_Test2_NM_6d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_DM_Test2_NM_6d_1.h5',\n",
    "    'GSE213511_LSK_OP0_NM_7d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_LSK_OP0_NM_7d_1.h5',\n",
    "    'GSE213511_LSK_OP1_NM_7d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_LSK_OP1_NM_7d_1.h5',\n",
    "    'GSE213511_LSK_OP1_NM_9d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_LSK_OP1_NM_9d_1.h5',\n",
    "    'GSE213511_LSK_OP2_NM_7d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_LSK_OP2_NM_7d_1.h5',\n",
    "    'GSE213511_LSK_OP2_NM_9d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_LSK_OP2_NM_9d_1.h5',\n",
    "    'GSE213511_LSK_OP3_NM_7d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_LSK_OP3_NM_7d_1.h5',\n",
    "    'GSE213511_LSK_OP3_NM_9d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_LSK_OP3_NM_9d_1.h5',\n",
    "    'GSE213511_LSK_OP4_NM_7d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_LSK_OP4_NM_7d_1.h5',\n",
    "    'GSE213511_LSK_OP4_NM_9d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_LSK_OP4_NM_9d_1.h5',\n",
    "    'GSE213511_inVivo_NTC_lin-andckit_14d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_inVivo_NTC_lin-andckit_14d_1.h5',\n",
    "    'GSE213511_inVivo_OP1_ckit_14d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_inVivo_OP1_ckit_14d_1.h5',\n",
    "    'GSE213511_inVivo_OP1_lin-_14d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_inVivo_OP1_lin-_14d_1.h5',\n",
    "    'GSE213511_inVivo_OP1_lin-_14d_2.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_inVivo_OP1_lin-_14d_2.h5',\n",
    "    'GSE213511_inVivo_OP1_lin-_28d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_inVivo_OP1_lin-_28d_1.h5',\n",
    "    'GSE213511_inVivo_OP1_lin-_28d_2.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_inVivo_OP1_lin-_28d_2.h5',\n",
    "    'GSE213511_inVivo_OP2_ckit_14d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_inVivo_OP2_ckit_14d_1.h5',\n",
    "    'GSE213511_inVivo_OP2_lin-_14d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_inVivo_OP2_lin-_14d_1.h5',\n",
    "    'GSE213511_inVivo_OP3_ckit_14d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_inVivo_OP3_ckit_14d_1.h5',\n",
    "    'GSE213511_inVivo_OP3_lin-_14d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_inVivo_OP3_lin-_14d_1.h5',\n",
    "    'GSE213511_inVivo_OP4_ckit_14d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_inVivo_OP4_ckit_14d_1.h5',\n",
    "    'GSE213511_inVivo_OP4_lin-_14d_1.h5': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_inVivo_OP4_lin-_14d_1.h5',\n",
    "    \n",
    "    # Annotation files\n",
    "    'GSE213511_CellAnnotation_exvivo.tsv.gz': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_CellAnnotation_exvivo.tsv.gz',\n",
    "    'GSE213511_CellAnnotation_invivo.tsv.gz': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_CellAnnotation_invivo.tsv.gz',\n",
    "    'GSE213511_CellAnnotation_leukemia.tsv.gz': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213511/suppl/GSE213511_CellAnnotation_leukemia.tsv.gz'\n",
    "}\n",
    "\n",
    "def download_file(url, destination):\n",
    "    \"\"\"Download a file from a URL to a destination path.\"\"\"\n",
    "    logger.info(f\"Downloading {url} to {destination}\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, destination)\n",
    "        logger.info(f\"Downloaded {destination}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to download {url}: {e}\")\n",
    "        raise\n",
    "\n",
    "def ensure_files_exist(data_dir):\n",
    "    \"\"\"Ensure all necessary files exist, downloading them if they don't.\"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    for filename, url in FILE_URLS.items():\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            download_file(url, file_path)\n",
    "        else:\n",
    "            logger.info(f\"File {filename} already exists, skipping download\")\n",
    "\n",
    "def read_gzipped_tsv(file_path):\n",
    "    \"\"\"Read a gzipped TSV file into a pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt') as f:\n",
    "            df = pd.read_csv(f, sep='\\t')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read {file_path}: {e}\")\n",
    "        raise\n",
    "\n",
    "def h5_to_anndata(h5_file_path):\n",
    "    \"\"\"Convert an h5 file to an AnnData object.\"\"\"\n",
    "    try:\n",
    "        with h5py.File(h5_file_path, 'r') as f:\n",
    "            # Get matrix dimensions\n",
    "            shape = f['matrix']['shape'][:]\n",
    "            n_genes, n_cells = shape\n",
    "            \n",
    "            # Get feature information\n",
    "            feature_ids = [id.decode('utf-8') for id in f['matrix']['features']['id'][:]]\n",
    "            feature_names = [name.decode('utf-8') for name in f['matrix']['features']['name'][:]]\n",
    "            \n",
    "            # Get barcode information\n",
    "            barcodes = [bc.decode('utf-8') for bc in f['matrix']['barcodes'][:]]\n",
    "            \n",
    "            # Create sparse matrix (stored in CSC; convert to CSR and transpose for AnnData)\n",
    "            data = f['matrix']['data'][:]\n",
    "            indices = f['matrix']['indices'][:]\n",
    "            indptr = f['matrix']['indptr'][:]\n",
    "            matrix = csc_matrix((data, indices, indptr), shape=(n_genes, n_cells))\n",
    "            matrix = matrix.tocsr().transpose()  # cells as rows, genes as columns\n",
    "            \n",
    "            # Create AnnData object\n",
    "            adata = sc.AnnData(X=matrix)\n",
    "            adata.var_names = pd.Index(feature_names)\n",
    "            adata.var['gene_ids'] = feature_ids\n",
    "            adata.obs_names = pd.Index(barcodes)\n",
    "            \n",
    "            return adata\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to convert {h5_file_path} to AnnData: {e}\")\n",
    "        raise\n",
    "\n",
    "def determine_dataset_type(file_name):\n",
    "    \"\"\"Determine the dataset type based on the file name.\"\"\"\n",
    "    if 'DM_' in file_name:\n",
    "        return 'leukemia'\n",
    "    elif 'LSK_' in file_name:\n",
    "        return 'exvivo'\n",
    "    elif 'inVivo_' in file_name:\n",
    "        return 'invivo'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "def extract_perturbation_name(guide_name):\n",
    "    \"\"\"Extract the perturbation name from the guide name.\"\"\"\n",
    "    if pd.isna(guide_name) or guide_name == 'NaN' or guide_name == '':\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Check if it's a non-targeting control\n",
    "    if 'NTC' in guide_name:\n",
    "        return 'Non-targeting'\n",
    "    \n",
    "    # Extract gene name from guide format like \"Rcor1_AS_21752\"\n",
    "    match = re.match(r'([A-Za-z0-9]+)_', guide_name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    return guide_name\n",
    "\n",
    "def determine_condition(mixscape_value):\n",
    "    \"\"\"Determine the condition based on the mixscape value.\"\"\"\n",
    "    if pd.isna(mixscape_value):\n",
    "        return 'Unknown'\n",
    "    elif mixscape_value == 'NTC':\n",
    "        return 'Control'\n",
    "    else:\n",
    "        return 'Test'\n",
    "\n",
    "def harmonize_dataset(adata, annotation_df, dataset_type):\n",
    "    \"\"\"Harmonize the dataset by adding standardized metadata.\"\"\"\n",
    "    # Create a mapping from barcode to annotation\n",
    "    barcode_to_annotation = {row['Barcode']: row for _, row in annotation_df.iterrows()}\n",
    "    \n",
    "    # Initialize standardized metadata columns\n",
    "    adata.obs['organism'] = 'Mice (Mus musculus)'\n",
    "    adata.obs['cell_type'] = 'Unknown'\n",
    "    adata.obs['crispr_type'] = 'CRISPR KO'\n",
    "    adata.obs['cancer_type'] = 'Unknown'\n",
    "    adata.obs['condition'] = 'Unknown'\n",
    "    adata.obs['perturbation_name'] = 'Unknown'\n",
    "    \n",
    "    # Add dataset-specific metadata\n",
    "    adata.obs['dataset_type'] = dataset_type\n",
    "    \n",
    "    # Add original metadata and map values\n",
    "    for barcode in adata.obs_names:\n",
    "        if barcode in barcode_to_annotation:\n",
    "            annotation = barcode_to_annotation[barcode]\n",
    "            for col in annotation.index:\n",
    "                if col != 'Barcode':  # Skip the barcode column\n",
    "                    adata.obs.loc[barcode, f'original_{col}'] = annotation[col]\n",
    "            \n",
    "            # Map cell type from Clusters column\n",
    "            if 'Clusters' in annotation:\n",
    "                adata.obs.loc[barcode, 'cell_type'] = annotation['Clusters']\n",
    "            \n",
    "            # Map perturbation name from Guide column\n",
    "            guide_col = 'Guide' if 'Guide' in annotation else None\n",
    "            if guide_col and not pd.isna(annotation[guide_col]):\n",
    "                adata.obs.loc[barcode, 'perturbation_name'] = extract_perturbation_name(annotation[guide_col])\n",
    "            \n",
    "            # Map condition from mixscape column (handles either 'mixscape' or 'Mixscape')\n",
    "            mixscape_col = next((col for col in ['mixscape', 'Mixscape'] if col in annotation), None)\n",
    "            if mixscape_col:\n",
    "                adata.obs.loc[barcode, 'condition'] = determine_condition(annotation[mixscape_col])\n",
    "    \n",
    "    # Set cancer type based on dataset type\n",
    "    if dataset_type == 'leukemia':\n",
    "        adata.obs['cancer_type'] = 'Leukemia'\n",
    "    else:\n",
    "        adata.obs['cancer_type'] = 'Non-Cancer'\n",
    "    \n",
    "    # Make var_names unique\n",
    "    adata.var_names_make_unique()\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def process_file(h5_file_path, annotation_dfs, output_dir):\n",
    "    \"\"\"\n",
    "    Process an h5 file and convert it to h5ad format with standardized metadata.\n",
    "    Returns the processed AnnData object if successful, or None otherwise.\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(h5_file_path)\n",
    "    logger.info(f\"Processing {file_name}\")\n",
    "    \n",
    "    # Determine dataset type\n",
    "    dataset_type = determine_dataset_type(file_name)\n",
    "    \n",
    "    # Select the appropriate annotation dataframe\n",
    "    if dataset_type == 'leukemia':\n",
    "        annotation_df = annotation_dfs['leukemia']\n",
    "    elif dataset_type == 'exvivo':\n",
    "        annotation_df = annotation_dfs['exvivo']\n",
    "    elif dataset_type == 'invivo':\n",
    "        annotation_df = annotation_dfs['invivo']\n",
    "    else:\n",
    "        logger.warning(f\"Unknown dataset type for {file_name}, skipping\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Convert h5 to AnnData and harmonize the dataset\n",
    "        adata = h5_to_anndata(h5_file_path)\n",
    "        adata = harmonize_dataset(adata, annotation_df, dataset_type)\n",
    "        \n",
    "        # Save individual harmonized dataset\n",
    "        output_file = os.path.join(output_dir, f\"{os.path.splitext(file_name)[0]}.h5ad\")\n",
    "        adata.write_h5ad(output_file)\n",
    "        logger.info(f\"Saved harmonized dataset to {output_file}\")\n",
    "        \n",
    "        return adata\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to process {file_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main(data_dir):\n",
    "    \"\"\"Main function to process all files and save individual as well as a combined h5ad.\"\"\"\n",
    "    logger.info(f\"Starting harmonization of GSE213511 dataset in {data_dir}\")\n",
    "    \n",
    "    # Ensure all necessary files exist\n",
    "    ensure_files_exist(data_dir)\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = os.path.join(data_dir, 'harmonized')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Read annotation files\n",
    "    logger.info(\"Reading annotation files\")\n",
    "    annotation_dfs = {\n",
    "        'exvivo': read_gzipped_tsv(os.path.join(data_dir, 'GSE213511_CellAnnotation_exvivo.tsv.gz')),\n",
    "        'invivo': read_gzipped_tsv(os.path.join(data_dir, 'GSE213511_CellAnnotation_invivo.tsv.gz')),\n",
    "        'leukemia': read_gzipped_tsv(os.path.join(data_dir, 'GSE213511_CellAnnotation_leukemia.tsv.gz'))\n",
    "    }\n",
    "    \n",
    "    # Process each h5 file and collect the processed AnnData objects\n",
    "    h5_files = [f for f in os.listdir(data_dir) if f.endswith('.h5')]\n",
    "    logger.info(f\"Found {len(h5_files)} h5 files to process\")\n",
    "    \n",
    "    adata_list = []\n",
    "    successful_files = 0\n",
    "    for file_name in tqdm(h5_files, desc=\"Processing h5 files\"):\n",
    "        h5_file_path = os.path.join(data_dir, file_name)\n",
    "        adata = process_file(h5_file_path, annotation_dfs, output_dir)\n",
    "        if adata is not None:\n",
    "            adata_list.append(adata)\n",
    "            successful_files += 1\n",
    "    \n",
    "    logger.info(f\"Harmonization complete. Successfully processed {successful_files}/{len(h5_files)} files.\")\n",
    "    \n",
    "    # Combine all processed AnnData objects\n",
    "    if adata_list:\n",
    "        combined_adata = anndata.concat(adata_list, join='outer')\n",
    "        # Exclude cells with \"Unknown\" in their perturbation_name\n",
    "        combined_adata = combined_adata[combined_adata.obs['perturbation_name'] != \"Unknown\", :]\n",
    "        \n",
    "        # Save combined AnnData\n",
    "        combined_file = os.path.join(output_dir, \"combined.h5ad\")\n",
    "        combined_adata.write_h5ad(combined_file)\n",
    "        logger.info(f\"Saved combined harmonized dataset to {combined_file}\")\n",
    "    else:\n",
    "        logger.warning(\"No AnnData objects were processed; combined file not created.\")\n",
    "\n",
    "# ----- Run in Jupyter Notebook -----\n",
    "# Set the data directory path where your files will be downloaded/stored.\n",
    "data_dir = \"/content/GSE213511\"  # <-- Change this to your actual directory\n",
    "\n",
    "# Run the main function\n",
    "main(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
