{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GSE153056 Dataset Harmonizer for Jupyter Notebook\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "class GSE153056Harmonizer:\n",
    "    \"\"\"\n",
    "    Class to download and harmonize the GSE153056 dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir):\n",
    "        \"\"\"\n",
    "        Initialize the harmonizer with the data directory.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data_dir : str\n",
    "            Path to the directory where the data will be downloaded and processed.\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.accession = \"GSE153056\"\n",
    "        self.download_urls = {\n",
    "            \"raw_tar\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE153nnn/GSE153056/suppl/GSE153056_RAW.tar\",\n",
    "            \"eccite_metadata\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE153nnn/GSE153056/suppl/GSE153056_ECCITE_metadata.tsv.gz\"\n",
    "        }\n",
    "        \n",
    "        # Create the data directory if it doesn't exist\n",
    "        os.makedirs(self.data_dir, exist_ok=True)\n",
    "    \n",
    "    def download_files(self):\n",
    "        \"\"\"\n",
    "        Download the dataset files if they don't exist.\n",
    "        \"\"\"\n",
    "        print(\"Checking and downloading required files...\")\n",
    "        \n",
    "        for file_key, url in self.download_urls.items():\n",
    "            file_name = url.split('/')[-1]\n",
    "            file_path = self.data_dir / file_name\n",
    "            \n",
    "            if not file_path.exists():\n",
    "                print(f\"Downloading {file_name}...\")\n",
    "                response = requests.get(url, stream=True)\n",
    "                total_size = int(response.headers.get('content-length', 0))\n",
    "                \n",
    "                with open(file_path, 'wb') as f, tqdm(\n",
    "                    desc=file_name,\n",
    "                    total=total_size,\n",
    "                    unit='B',\n",
    "                    unit_scale=True,\n",
    "                    unit_divisor=1024,\n",
    "                ) as bar:\n",
    "                    for data in response.iter_content(chunk_size=1024):\n",
    "                        size = f.write(data)\n",
    "                        bar.update(size)\n",
    "                \n",
    "                # Extract tar file if needed\n",
    "                if file_key == \"raw_tar\" and not (self.data_dir / \"GSM4633614_ECCITE_cDNA_counts.tsv.gz\").exists():\n",
    "                    print(f\"Extracting {file_name}...\")\n",
    "                    shutil.unpack_archive(file_path, self.data_dir)\n",
    "            else:\n",
    "                print(f\"{file_name} already exists, skipping download.\")\n",
    "    \n",
    "    def read_count_matrix_sparse(self, file_path):\n",
    "        \"\"\"\n",
    "        Read a gzipped count matrix file into a sparse matrix.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        file_path : str or Path\n",
    "            Path to the gzipped count matrix file.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple\n",
    "            A tuple containing (sparse_matrix, genes, cell_barcodes).\n",
    "        \"\"\"\n",
    "        print(f\"Reading {file_path} as sparse matrix...\")\n",
    "        \n",
    "        # First pass: get dimensions and non-zero entries\n",
    "        with gzip.open(file_path, 'rt') as f:\n",
    "            header = f.readline().strip().split('\\t')\n",
    "            cell_barcodes = header[1:]  # Skip the first empty column\n",
    "            genes = []\n",
    "            data = []\n",
    "            indices = []\n",
    "            indptr = [0]\n",
    "            \n",
    "            for i, line in enumerate(f):\n",
    "                if i % 1000 == 0:\n",
    "                    print(f\"Processed {i} rows...\")\n",
    "                \n",
    "                parts = line.strip().split('\\t')\n",
    "                genes.append(parts[0])\n",
    "                \n",
    "                # Convert counts to sparse format\n",
    "                row_data = [int(float(x)) for x in parts[1:]]\n",
    "                row_indices = [j for j, x in enumerate(row_data) if x > 0]\n",
    "                row_data = [row_data[j] for j in row_indices]\n",
    "                \n",
    "                data.extend(row_data)\n",
    "                indices.extend(row_indices)\n",
    "                indptr.append(len(indices))\n",
    "        \n",
    "        # Create sparse matrix\n",
    "        X = sparse.csr_matrix((data, indices, indptr), shape=(len(genes), len(cell_barcodes)))\n",
    "        print(f\"Finished reading {file_path}, shape: {X.shape}\")\n",
    "        \n",
    "        return X, genes, cell_barcodes\n",
    "    \n",
    "    def process_eccite_seq_data(self):\n",
    "        \"\"\"\n",
    "        Process the ECCITE-seq data from the dataset.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        anndata.AnnData\n",
    "            The processed ECCITE-seq data as an AnnData object.\n",
    "        \"\"\"\n",
    "        print(\"Processing ECCITE-seq data...\")\n",
    "        \n",
    "        # Read RNA counts as sparse matrix\n",
    "        rna_matrix, genes, cell_barcodes = self.read_count_matrix_sparse(\n",
    "            self.data_dir / \"GSM4633614_ECCITE_cDNA_counts.tsv.gz\"\n",
    "        )\n",
    "        \n",
    "        # Read ADT and GDO counts (these are smaller, so we can use pandas)\n",
    "        print(\"Reading ADT counts...\")\n",
    "        adt_counts = pd.read_csv(\n",
    "            gzip.open(self.data_dir / \"GSM4633615_ECCITE_ADT_counts.tsv.gz\", 'rt'),\n",
    "            sep='\\t', index_col=0\n",
    "        )\n",
    "        print(f\"ADT counts shape: {adt_counts.shape}\")\n",
    "        \n",
    "        print(\"Reading GDO counts...\")\n",
    "        gdo_counts = pd.read_csv(\n",
    "            gzip.open(self.data_dir / \"GSM4633618_ECCITE_GDO_counts.tsv.gz\", 'rt'),\n",
    "            sep='\\t', index_col=0\n",
    "        )\n",
    "        print(f\"GDO counts shape: {gdo_counts.shape}\")\n",
    "        \n",
    "        print(\"Reading metadata...\")\n",
    "        # Read metadata\n",
    "        metadata = pd.read_csv(self.data_dir / \"GSE153056_ECCITE_metadata.tsv.gz\", sep='\\t', index_col=0)\n",
    "        print(f\"Metadata shape: {metadata.shape}\")\n",
    "        \n",
    "        # Read ADT and GDO barcodes\n",
    "        adt_barcodes = pd.read_csv(self.data_dir / \"GSM4633615_ECCITE_ADT_Barcodes.csv.gz\", \n",
    "                                  header=None, names=['barcode', 'protein'])\n",
    "        gdo_barcodes = pd.read_csv(self.data_dir / \"GSM4633618_ECCITE_GDO_Barcodes.csv.gz\", \n",
    "                                  header=None, names=['barcode', 'guide'])\n",
    "        \n",
    "        print(\"Creating AnnData object...\")\n",
    "        # Create AnnData object with RNA counts (transposed)\n",
    "        adata = ad.AnnData(\n",
    "            X=rna_matrix.T,\n",
    "            obs=pd.DataFrame(index=cell_barcodes),\n",
    "            var=pd.DataFrame(index=genes)\n",
    "        )\n",
    "        print(f\"AnnData shape: {adata.shape}\")\n",
    "        \n",
    "        # Add ADT and GDO counts as observations\n",
    "        print(\"Adding protein and guide counts...\")\n",
    "        \n",
    "        # Create protein and guide count matrices of the right shape\n",
    "        protein_counts = np.zeros((adata.n_obs, len(adt_barcodes)))\n",
    "        guide_counts = np.zeros((adata.n_obs, len(gdo_barcodes)))\n",
    "        \n",
    "        # Add the protein and guide counts as observations\n",
    "        adata.obsm['protein_counts'] = protein_counts\n",
    "        adata.obsm['guide_counts'] = guide_counts\n",
    "        \n",
    "        # Add metadata for cells that exist in both the count matrix and metadata\n",
    "        print(\"Adding metadata to AnnData...\")\n",
    "        common_cells = adata.obs.index.intersection(metadata.index)\n",
    "        print(f\"Common cells: {len(common_cells)} out of {adata.n_obs} cells\")\n",
    "        \n",
    "        # If no common cells found, try to match by removing the prefix\n",
    "        if len(common_cells) == 0:\n",
    "            print(\"No common cells found. Trying to match by removing prefix...\")\n",
    "            # Create a mapping from cell barcodes to metadata index\n",
    "            cell_to_metadata = {}\n",
    "            for cell in adata.obs.index:\n",
    "                # Try to find a match in metadata by removing prefix\n",
    "                for meta_idx in metadata.index:\n",
    "                    if cell in meta_idx or meta_idx in cell:\n",
    "                        cell_to_metadata[cell] = meta_idx\n",
    "                        break\n",
    "            \n",
    "            print(f\"Found {len(cell_to_metadata)} matches after removing prefix\")\n",
    "            \n",
    "            # Add metadata using the mapping\n",
    "            for col in metadata.columns:\n",
    "                adata.obs[col] = np.nan\n",
    "                for cell, meta_idx in cell_to_metadata.items():\n",
    "                    adata.obs.loc[cell, col] = metadata.loc[meta_idx, col]\n",
    "        else:\n",
    "            # Add metadata directly for common cells\n",
    "            for col in metadata.columns:\n",
    "                adata.obs[col] = np.nan\n",
    "                adata.obs.loc[common_cells, col] = metadata.loc[common_cells, col].values\n",
    "        \n",
    "        # Add protein and guide names\n",
    "        adata.uns['protein_names'] = adt_barcodes['protein'].tolist()\n",
    "        adata.uns['guide_names'] = gdo_barcodes['guide'].tolist()\n",
    "        \n",
    "        # Add experiment type\n",
    "        adata.obs['experiment_type'] = 'ECCITE-seq'\n",
    "        \n",
    "        print(\"ECCITE-seq processing complete\")\n",
    "        return adata\n",
    "    \n",
    "    def harmonize_data(self, adata):\n",
    "        \"\"\"\n",
    "        Harmonize the data according to the specified format.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        adata : anndata.AnnData\n",
    "            The AnnData object to harmonize.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        anndata.AnnData\n",
    "            The harmonized AnnData object.\n",
    "        \"\"\"\n",
    "        print(\"Harmonizing ECCITE-seq data...\")\n",
    "        \n",
    "        # Create standardized metadata columns\n",
    "        adata.obs['organism'] = 'Homo sapiens'\n",
    "        adata.obs['cell_type'] = 'THP-1'  # THP-1 monocyte cell line\n",
    "        adata.obs['crispr_type'] = 'CRISPR KO'\n",
    "        adata.obs['cancer_type'] = 'Leukemia'  # THP-1 is a leukemia cell line\n",
    "        \n",
    "        # Set condition based on metadata\n",
    "        if 'con' in adata.obs.columns:\n",
    "            # Convert to string first to avoid type issues\n",
    "            adata.obs['condition'] = adata.obs['con'].astype(str).map({'tx': 'Test', 'nt': 'Control'})\n",
    "            # Fill NaN values with 'Unknown'\n",
    "            adata.obs['condition'] = adata.obs['condition'].fillna('Unknown')\n",
    "        else:\n",
    "            adata.obs['condition'] = 'Unknown'\n",
    "        \n",
    "        # Set perturbation name based on guide information\n",
    "        if 'gene' in adata.obs.columns:\n",
    "            # Extract gene name from guide_ID and convert to string\n",
    "            adata.obs['perturbation_name'] = adata.obs['gene'].astype(str)\n",
    "            \n",
    "            # Mark non-targeting controls\n",
    "            if 'NT' in adata.obs.columns:\n",
    "                # Cells with gene='NT' are non-targeting controls\n",
    "                nt_mask = (adata.obs['gene'] == 'NT')\n",
    "                adata.obs.loc[nt_mask, 'perturbation_name'] = 'Non-targeting'\n",
    "            \n",
    "            # Fill NaN values with 'Unknown'\n",
    "            adata.obs['perturbation_name'] = adata.obs['perturbation_name'].fillna('Unknown')\n",
    "        else:\n",
    "            adata.obs['perturbation_name'] = 'Unknown'\n",
    "        \n",
    "        # Fix data types for all columns to ensure compatibility with h5ad\n",
    "        for col in adata.obs.columns:\n",
    "            # Convert all object columns to string\n",
    "            if adata.obs[col].dtype == 'object' or isinstance(adata.obs[col].dtype, pd.CategoricalDtype):\n",
    "                adata.obs[col] = adata.obs[col].astype(str)\n",
    "            # Convert all float columns with NaNs to float\n",
    "            elif pd.api.types.is_float_dtype(adata.obs[col]):\n",
    "                adata.obs[col] = adata.obs[col].astype(float)\n",
    "            # Convert all int columns to int\n",
    "            elif pd.api.types.is_integer_dtype(adata.obs[col]):\n",
    "                adata.obs[col] = adata.obs[col].astype(int)\n",
    "        \n",
    "        # Add study information\n",
    "        adata.uns['study'] = {\n",
    "            'accession': self.accession,\n",
    "            'title': 'Characterizing the molecular regulation of inhibitory immune checkpoints with multi-modal single-cell screens',\n",
    "            'authors': 'Papalexi E, et al.',\n",
    "            'description': 'ECCITE-seq study of immune checkpoint regulation in THP-1 cells'\n",
    "        }\n",
    "        \n",
    "        return adata\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Run the harmonization process.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        str\n",
    "            Path to the harmonized h5ad file.\n",
    "        \"\"\"\n",
    "        # Download files if needed\n",
    "        self.download_files()\n",
    "        \n",
    "        # Process ECCITE-seq data\n",
    "        eccite_seq_data = self.process_eccite_seq_data()\n",
    "        \n",
    "        # Harmonize data\n",
    "        eccite_seq_data_harmonized = self.harmonize_data(eccite_seq_data)\n",
    "        \n",
    "        # Save harmonized data\n",
    "        output_path = self.data_dir / f\"{self.accession}_harmonized.h5ad\"\n",
    "        print(f\"Saving harmonized data to {output_path}\")\n",
    "        eccite_seq_data_harmonized.write_h5ad(output_path)\n",
    "        \n",
    "        print(\"Harmonization complete!\")\n",
    "        return str(output_path)\n",
    "\n",
    "# Helper function to run the harmonizer in Jupyter Notebook\n",
    "def run_harmonizer(data_dir='./GSE153056'):\n",
    "    harmonizer = GSE153056Harmonizer(data_dir)\n",
    "    output_path = harmonizer.run()\n",
    "    print(f\"Harmonized data saved to: {output_path}\")\n",
    "\n",
    "# Execute the harmonizer (you can change the data_dir if needed)\n",
    "run_harmonizer()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
