{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Constants\n",
    "GEO_ACCESSION = \"GSE190604\"\n",
    "BASE_URL = f\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE190nnn/{GEO_ACCESSION}/suppl\"\n",
    "FILES_TO_DOWNLOAD = [\n",
    "    f\"{GEO_ACCESSION}_barcodes.tsv.gz\",\n",
    "    f\"{GEO_ACCESSION}_features.tsv.gz\",\n",
    "    f\"{GEO_ACCESSION}_matrix.mtx.gz\",\n",
    "    f\"{GEO_ACCESSION}_cellranger-guidecalls-aggregated-unfiltered.txt.gz\",\n",
    "]\n",
    "SERIES_MATRIX_URL = f\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE190nnn/{GEO_ACCESSION}/matrix/{GEO_ACCESSION}_series_matrix.txt.gz\"\n",
    "\n",
    "\n",
    "def download_file(url: str, output_path: Path, force: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Download a file from a URL to the specified output path.\n",
    "    \"\"\"\n",
    "    if output_path.exists() and not force:\n",
    "        print(f\"File already exists: {output_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Downloading {url} to {output_path}\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 Kibibyte\n",
    "    \n",
    "    with open(output_path, 'wb') as f:\n",
    "        for data in tqdm(\n",
    "            response.iter_content(block_size),\n",
    "            total=total_size // block_size,\n",
    "            unit='KiB',\n",
    "            unit_scale=True\n",
    "        ):\n",
    "            f.write(data)\n",
    "\n",
    "\n",
    "def download_dataset(data_dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    Download all necessary files for the dataset.\n",
    "    \"\"\"\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Download main data files\n",
    "    for filename in FILES_TO_DOWNLOAD:\n",
    "        url = f\"{BASE_URL}/{filename}\"\n",
    "        output_path = data_dir / filename\n",
    "        download_file(url, output_path)\n",
    "    \n",
    "    # Download series matrix file for metadata\n",
    "    series_matrix_path = data_dir / f\"{GEO_ACCESSION}_series_matrix.txt.gz\"\n",
    "    download_file(SERIES_MATRIX_URL, series_matrix_path)\n",
    "\n",
    "\n",
    "def extract_sample_metadata(series_matrix_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract sample metadata from the series matrix file.\n",
    "    \"\"\"\n",
    "    sample_info = {}\n",
    "    sample_ids = []\n",
    "    sample_titles = []\n",
    "    \n",
    "    with gzip.open(series_matrix_path, 'rt') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('!Sample_geo_accession'):\n",
    "                sample_ids = line.strip().split('\\t')[1:]\n",
    "                sample_ids = [s.strip('\"') for s in sample_ids]\n",
    "                for sample_id in sample_ids:\n",
    "                    if sample_id not in sample_info:\n",
    "                        sample_info[sample_id] = {}\n",
    "            elif line.startswith('!Sample_title'):\n",
    "                titles = line.strip().split('\\t')[1:]\n",
    "                titles = [t.strip('\"') for t in titles]\n",
    "                sample_titles = titles\n",
    "                for i, sample_id in enumerate(sample_ids):\n",
    "                    if i < len(titles):\n",
    "                        sample_info[sample_id]['sample_title'] = titles[i]\n",
    "            elif line.startswith('!Sample_characteristics_ch1'):\n",
    "                chars = line.strip().split('\\t')[1:]\n",
    "                chars = [c.strip('\"') for c in chars]\n",
    "                for i, sample_id in enumerate(sample_ids):\n",
    "                    if i < len(chars):\n",
    "                        char_parts = chars[i].split(': ')\n",
    "                        if len(char_parts) == 2:\n",
    "                            key, value = char_parts\n",
    "                            sample_info[sample_id][key] = value\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(sample_info, orient='index')\n",
    "    \n",
    "    if df.empty and sample_titles:\n",
    "        df = pd.DataFrame({'sample_title': sample_titles}, index=sample_ids)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_guide_calls(guide_calls_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse the guide calls file to extract perturbation information.\n",
    "    \"\"\"\n",
    "    guide_calls = pd.read_csv(guide_calls_path, sep='\\t', compression='gzip')\n",
    "    \n",
    "    # Function to process each feature_call\n",
    "    def process_feature_call(feature_call):\n",
    "        # If the feature call contains \"NO-TARGET\" (case insensitive), assign as \"Non-targeting\"\n",
    "        if \"NO-TARGET\" in feature_call.upper():\n",
    "            return \"Non-targeting\"\n",
    "        else:\n",
    "            # Otherwise, extract gene names (format: GENE-guide1|GENE-guide2)\n",
    "            return '|'.join([g.split('-')[0] for g in feature_call.split('|')])\n",
    "    \n",
    "    guide_calls['perturbation_name'] = guide_calls['feature_call'].apply(process_feature_call)\n",
    "    \n",
    "    # Identify non-targeting controls by also checking for \"Non-targeting\" in the feature_call\n",
    "    guide_calls['is_non_targeting'] = guide_calls['feature_call'].str.contains('Non-targeting|NO-TARGET', case=False, regex=True)\n",
    "    guide_calls.loc[guide_calls['is_non_targeting'], 'perturbation_name'] = 'Non-targeting'\n",
    "    \n",
    "    # Set cell barcode as index for easier merging\n",
    "    guide_calls.set_index('cell_barcode', inplace=True)\n",
    "    \n",
    "    return guide_calls\n",
    "\n",
    "\n",
    "def load_10x_data(data_dir: Path) -> ad.AnnData:\n",
    "    \"\"\"\n",
    "    Load 10x data from the specified directory.\n",
    "    \"\"\"\n",
    "    matrix_file = data_dir / f\"{GEO_ACCESSION}_matrix.mtx.gz\"\n",
    "    features_file = data_dir / f\"{GEO_ACCESSION}_features.tsv.gz\"\n",
    "    barcodes_file = data_dir / f\"{GEO_ACCESSION}_barcodes.tsv.gz\"\n",
    "    \n",
    "    # Load features (genes)\n",
    "    var_names = pd.read_csv(features_file, header=None, sep='\\t', compression='gzip')\n",
    "    gene_ids = var_names[0].values\n",
    "    gene_symbols = var_names[1].values\n",
    "    \n",
    "    # Load barcodes\n",
    "    obs_names = pd.read_csv(barcodes_file, header=None, compression='gzip')\n",
    "    cell_barcodes = obs_names[0].values\n",
    "    \n",
    "    # Load the count matrix using scanpy's read_mtx function (matrix is genes x cells)\n",
    "    adata = sc.read_mtx(str(matrix_file))\n",
    "    \n",
    "    # Transpose if necessary to get cells x genes\n",
    "    if adata.shape[0] == len(gene_ids) and adata.shape[1] == len(cell_barcodes):\n",
    "        adata = adata.T\n",
    "    \n",
    "    # Set observation and variable names\n",
    "    adata.obs_names = pd.Index(cell_barcodes)\n",
    "    adata.var_names = pd.Index(gene_symbols)\n",
    "    adata.var['gene_ids'] = gene_ids\n",
    "    adata.var_names_make_unique()\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def determine_stimulation_condition(adata: ad.AnnData, sample_metadata: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Determine stimulation condition for each cell based on sample metadata and cell barcodes.\n",
    "    \"\"\"\n",
    "    has_stim_info = False\n",
    "    if 'sample_title' in sample_metadata.columns:\n",
    "        stim_samples = [title for title in sample_metadata['sample_title'] if 'stim' in title.lower()]\n",
    "        nostim_samples = [title for title in sample_metadata['sample_title'] if 'nostim' in title.lower()]\n",
    "        \n",
    "        if stim_samples or nostim_samples:\n",
    "            has_stim_info = True\n",
    "            stim_mask = adata.obs.index.str.contains('-1$')\n",
    "            adata.obs.loc[stim_mask, 'condition'] = 'Stimulated'\n",
    "            adata.obs.loc[~stim_mask, 'condition'] = 'Non-stimulated'\n",
    "    \n",
    "    if not has_stim_info:\n",
    "        stim_cells = [bc for bc in adata.obs.index if 'stim' in bc.lower()]\n",
    "        nostim_cells = [bc for bc in adata.obs.index if 'nostim' in bc.lower()]\n",
    "        \n",
    "        if stim_cells or nostim_cells:\n",
    "            stim_mask = adata.obs.index.str.contains('stim', case=False)\n",
    "            nostim_mask = adata.obs.index.str.contains('nostim', case=False)\n",
    "            adata.obs.loc[stim_mask & ~nostim_mask, 'condition'] = 'Stimulated'\n",
    "            adata.obs.loc[nostim_mask, 'condition'] = 'Non-stimulated'\n",
    "        else:\n",
    "            adata.obs['condition'] = 'unknown'\n",
    "\n",
    "\n",
    "def harmonize_dataset(data_dir: Path) -> ad.AnnData:\n",
    "    \"\"\"\n",
    "    Harmonize the dataset into a standardized format.\n",
    "    \"\"\"\n",
    "    print(\"Loading count matrix...\")\n",
    "    adata = load_10x_data(data_dir)\n",
    "    print(f\"Loaded data with {adata.n_obs} cells and {adata.n_vars} genes\")\n",
    "    \n",
    "    print(\"Loading guide calls...\")\n",
    "    guide_calls_path = data_dir / f\"{GEO_ACCESSION}_cellranger-guidecalls-aggregated-unfiltered.txt.gz\"\n",
    "    guide_calls = parse_guide_calls(guide_calls_path)\n",
    "    \n",
    "    print(\"Loading sample metadata...\")\n",
    "    series_matrix_path = data_dir / f\"{GEO_ACCESSION}_series_matrix.txt.gz\"\n",
    "    sample_metadata = extract_sample_metadata(series_matrix_path)\n",
    "    \n",
    "    print(\"Adding perturbation information...\")\n",
    "    adata.obs = adata.obs.join(guide_calls, how='left')\n",
    "    \n",
    "    print(\"Harmonizing metadata...\")\n",
    "    adata.obs['organism'] = 'Homo sapiens'\n",
    "    adata.obs['cell_type'] = 'T Cells'\n",
    "    adata.obs['crispr_type'] = 'CRISPRa'\n",
    "    adata.obs['cancer_type'] = 'Non-Cancer'\n",
    "    determine_stimulation_condition(adata, sample_metadata)\n",
    "    \n",
    "    if 'perturbation_name' not in adata.obs.columns:\n",
    "        adata.obs['perturbation_name'] = 'unknown'\n",
    "    else:\n",
    "        adata.obs['perturbation_name'] = adata.obs['perturbation_name'].fillna('Non-targeting')\n",
    "    \n",
    "    for col in guide_calls.columns:\n",
    "        if col not in adata.obs.columns and col not in ['cell_barcode', 'perturbation_name']:\n",
    "            adata.obs[col] = adata.obs.index.map(guide_calls[col]).fillna('unknown')\n",
    "    \n",
    "    required_fields = ['organism', 'cell_type', 'crispr_type', 'cancer_type', 'condition', 'perturbation_name']\n",
    "    for field in required_fields:\n",
    "        if field not in adata.obs.columns:\n",
    "            adata.obs[field] = 'unknown'\n",
    "    \n",
    "    # Override condition: if perturbation_name is \"Non-targeting\" label as \"Control\", else \"Test\"\n",
    "    adata.obs['condition'] = adata.obs['perturbation_name'].apply(lambda x: \"Control\" if x == \"Non-targeting\" else \"Test\")\n",
    "    \n",
    "    # Convert required metadata columns to categorical type\n",
    "    for col in required_fields:\n",
    "        adata.obs[col] = adata.obs[col].astype('category')\n",
    "    \n",
    "    adata.uns['dataset'] = {\n",
    "        'geo_accession': GEO_ACCESSION,\n",
    "        'title': 'CRISPR activation and interference screens decode stimulation responses in primary human T cells',\n",
    "        'organism': 'Homo sapiens',\n",
    "        'publication': ('Schmidt R, Steinhart Z, Layeghi M, Freimer JW et al. '\n",
    "                        'CRISPR activation and interference screens decode stimulation responses in primary human T cells. '\n",
    "                        'Science 2022 Feb 4;375(6580):eabj4008. PMID: 35113687')\n",
    "    }\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def run_in_jupyter(data_dir: Path = Path(f\"./{GEO_ACCESSION}\")):\n",
    "    \"\"\"\n",
    "    Run the download and harmonization pipeline in a Jupyter Notebook.\n",
    "    \"\"\"\n",
    "    print(f\"Using data directory: {data_dir}\")\n",
    "    download_dataset(data_dir)\n",
    "    adata = harmonize_dataset(data_dir)\n",
    "    \n",
    "    # Before saving, convert any categorical or object-type columns in obs to strings\n",
    "    for col in adata.obs.columns:\n",
    "        if pd.api.types.is_categorical_dtype(adata.obs[col]) or adata.obs[col].dtype == object:\n",
    "            adata.obs[col] = adata.obs[col].astype(str)\n",
    "    \n",
    "    output_file = data_dir / f\"{GEO_ACCESSION}_harmonized.h5ad\"\n",
    "    print(f\"Saving harmonized dataset to {output_file}\")\n",
    "    adata.write(output_file)\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    print(f\"Harmonized dataset saved to {output_file}\")\n",
    "    print(f\"Dataset shape: {adata.shape}\")\n",
    "    print(f\"Metadata fields: {list(adata.obs.columns)}\")\n",
    "\n",
    "\n",
    "# Run the pipeline in Jupyter Notebook\n",
    "run_in_jupyter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b38bd-1bdb-4f0a-801c-082ce9d71f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
