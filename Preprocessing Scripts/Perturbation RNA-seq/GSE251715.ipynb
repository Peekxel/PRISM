{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import gzip\n",
    "import shutil\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "def download_dataset(accession_id, output_dir):\n",
    "    \"\"\"\n",
    "    Download dataset files if they don't exist\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    accession_id : str\n",
    "        GEO accession ID\n",
    "    output_dir : str\n",
    "        Directory to save downloaded files\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Correctly construct the base URL for GEO series files.\n",
    "    # For example, for \"GSE251715\", we want \"GSE251nnn\"\n",
    "    base_url = f\"https://ftp.ncbi.nlm.nih.gov/geo/series/{accession_id[:6]}nnn/{accession_id}/suppl/\"\n",
    "    files = [\n",
    "        f\"{accession_id}_cell_annotation.csv.gz\",\n",
    "        f\"{accession_id}_normalized_matrix.csv.gz\"\n",
    "    ]\n",
    "    \n",
    "    # Download files if they don't exist\n",
    "    for file in files:\n",
    "        output_file = os.path.join(output_dir, file)\n",
    "        if not os.path.exists(output_file):\n",
    "            print(f\"Downloading {file}...\")\n",
    "            try:\n",
    "                url = base_url + file\n",
    "                urllib.request.urlretrieve(url, output_file)\n",
    "                print(f\"Downloaded {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {file}: {e}\")\n",
    "                if os.path.exists(output_file):\n",
    "                    os.remove(output_file)\n",
    "        else:\n",
    "            print(f\"File {file} already exists\")\n",
    "\n",
    "def process_GSE251715(data_dir):\n",
    "    \"\"\"\n",
    "    Process GSE251715 dataset and harmonize it into h5ad format\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dir : str\n",
    "        Directory containing the dataset files\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    anndata.AnnData\n",
    "        Harmonized dataset\n",
    "    \"\"\"\n",
    "    # Define file paths\n",
    "    annotation_file = os.path.join(data_dir, \"GSE251715_cell_annotation.csv.gz\")\n",
    "    matrix_file = os.path.join(data_dir, \"GSE251715_normalized_matrix.csv.gz\")\n",
    "    \n",
    "    # Read annotation file\n",
    "    print(\"Reading annotation file...\")\n",
    "    with gzip.open(annotation_file, 'rt') as f:\n",
    "        annotations = pd.read_csv(f)\n",
    "    \n",
    "    # Try to read the expression matrix\n",
    "    expression_data_available = False\n",
    "    try:\n",
    "        print(\"Attempting to read expression matrix...\")\n",
    "        # Try to decompress the file\n",
    "        decompressed_file = os.path.join(data_dir, \"GSE251715_normalized_matrix.csv\")\n",
    "        if not os.path.exists(decompressed_file):\n",
    "            try:\n",
    "                with gzip.open(matrix_file, 'rb') as f_in:\n",
    "                    with open(decompressed_file, 'wb') as f_out:\n",
    "                        shutil.copyfileobj(f_in, f_out)\n",
    "                print(\"Successfully decompressed expression matrix file\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error decompressing expression matrix file: {e}\")\n",
    "                if os.path.exists(decompressed_file):\n",
    "                    os.remove(decompressed_file)\n",
    "        \n",
    "        # Check if decompression was successful\n",
    "        if os.path.exists(decompressed_file) and os.path.getsize(decompressed_file) > 0:\n",
    "            # Try to read the expression matrix\n",
    "            try:\n",
    "                print(\"Reading expression matrix from decompressed file...\")\n",
    "                # Read the first few lines to get the header\n",
    "                with open(decompressed_file, 'r') as f:\n",
    "                    header = f.readline().strip().split(',')\n",
    "                \n",
    "                # Read the matrix in chunks\n",
    "                chunks = []\n",
    "                for chunk in pd.read_csv(decompressed_file, chunksize=1000):\n",
    "                    chunks.append(chunk)\n",
    "                \n",
    "                expr_matrix = pd.concat(chunks)\n",
    "                \n",
    "                # Set gene IDs as index\n",
    "                gene_ids = expr_matrix.iloc[:, 0]\n",
    "                expr_matrix = expr_matrix.iloc[:, 1:]\n",
    "                expr_matrix.index = gene_ids\n",
    "                \n",
    "                # Convert barcodes to match annotation file format\n",
    "                expr_matrix.columns = [col.replace('.', '-') for col in expr_matrix.columns]\n",
    "                \n",
    "                # Create AnnData object with expression data\n",
    "                print(\"Creating AnnData object with expression data...\")\n",
    "                adata = ad.AnnData(\n",
    "                    X=expr_matrix.T.values,\n",
    "                    obs=pd.DataFrame(index=expr_matrix.columns),\n",
    "                    var=pd.DataFrame(index=expr_matrix.index)\n",
    "                )\n",
    "                \n",
    "                expression_data_available = True\n",
    "                print(f\"Successfully created AnnData object with expression data: {adata.n_obs} cells and {adata.n_vars} genes\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading expression matrix: {e}\")\n",
    "                expression_data_available = False\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing expression matrix: {e}\")\n",
    "        expression_data_available = False\n",
    "    \n",
    "    # If expression data is not available, create a minimal AnnData object\n",
    "    if not expression_data_available:\n",
    "        print(\"Creating minimal AnnData object without expression data...\")\n",
    "        \n",
    "        # Create a list of cell barcodes from the annotation file\n",
    "        cell_barcodes = annotations['barcode'].values\n",
    "        \n",
    "        # Create a minimal AnnData object with empty expression matrix\n",
    "        adata = ad.AnnData(\n",
    "            X=np.zeros((len(cell_barcodes), 1), dtype=np.float32),\n",
    "            obs=pd.DataFrame(index=cell_barcodes),\n",
    "            var=pd.DataFrame(index=['placeholder_gene'])\n",
    "        )\n",
    "        \n",
    "        # Add a note about the missing expression data\n",
    "        adata.uns['data_status'] = 'Expression data not available due to corrupted file'\n",
    "        print(f\"Created minimal AnnData object: {adata.n_obs} cells and {adata.n_vars} genes\")\n",
    "    \n",
    "    # Note that the dataset provides normalized data\n",
    "    adata.uns['data_is_normalized'] = True\n",
    "    \n",
    "    # Add gene information to var if expression data is available\n",
    "    if expression_data_available:\n",
    "        adata.var['gene_id'] = adata.var.index\n",
    "        adata.var['gene_source'] = 'FlyBase'\n",
    "    \n",
    "    # Set the index of the annotations dataframe to match the AnnData object\n",
    "    annotations.set_index('barcode', inplace=True)\n",
    "    \n",
    "    # Ensure all barcodes in expression matrix are in annotations\n",
    "    common_barcodes = list(set(adata.obs_names) & set(annotations.index))\n",
    "    adata = adata[common_barcodes]\n",
    "    \n",
    "    # Add annotations to obs\n",
    "    adata.obs['original_annotation'] = annotations.loc[adata.obs_names, 'annotation'].values\n",
    "    adata.obs['original_sample'] = annotations.loc[adata.obs_names, 'sample'].values\n",
    "    \n",
    "    # Harmonize metadata\n",
    "    print(\"Harmonizing metadata...\")\n",
    "    \n",
    "    # Set organism\n",
    "    adata.obs['organism'] = 'Drosophila melanogaster'\n",
    "    \n",
    "    # Extract cell type from original annotation\n",
    "    adata.obs['cell_type'] = adata.obs['original_annotation'].apply(\n",
    "        lambda x: x.split(' ', 1)[1] if ' ' in x else x\n",
    "    )\n",
    "    \n",
    "    # Set condition based on sample information\n",
    "    adata.obs['condition'] = adata.obs['original_sample'].apply(\n",
    "        lambda x: 'Control' if 'w1118' in x or 'W1118' in x else 'Test'\n",
    "    )\n",
    "    \n",
    "    # Set perturbation_name based on sample information\n",
    "    def get_perturbation(sample):\n",
    "        if 'Pvr RNAi' in sample:\n",
    "            return 'Pvr'\n",
    "        elif 'Pvr Activation' in sample:\n",
    "            return 'Pvr'\n",
    "        elif 'Yki' in sample:\n",
    "            return 'Yki'\n",
    "        else:\n",
    "            return 'None'\n",
    "    \n",
    "    adata.obs['perturbation_name'] = adata.obs['original_sample'].apply(get_perturbation)\n",
    "    \n",
    "    # Set CRISPR type\n",
    "    def get_crispr_type(sample):\n",
    "        if 'RNAi' in sample:\n",
    "            return 'RNAi'\n",
    "        elif 'Activation' in sample:\n",
    "            return 'Activation'\n",
    "        elif 'Yki' in sample:\n",
    "            return 'Overexpression'\n",
    "        else:\n",
    "            return 'None'\n",
    "    \n",
    "    adata.obs['crispr_type'] = adata.obs['original_sample'].apply(get_crispr_type)\n",
    "    \n",
    "    # Set cancer_type (this is a gut tumor model)\n",
    "    adata.obs['cancer_type'] = adata.obs['original_sample'].apply(\n",
    "        lambda x: 'Gut Tumor' if 'Yki' in x else 'Non-Cancer'\n",
    "    )\n",
    "    \n",
    "    # Add additional metadata\n",
    "    adata.uns['dataset_id'] = 'GSE251715'\n",
    "    adata.uns['dataset_title'] = 'Mechanistic characterization of a Drosophila model of paraneoplastic nephrotic syndrome'\n",
    "    adata.uns['dataset_description'] = 'snRNA-seq analysis of Drosophila Malpighian tubules (MTs) with and without Yki gut tumors'\n",
    "    \n",
    "    print(\"Harmonization complete\")\n",
    "    return adata\n",
    "\n",
    "def main(root_path=None):\n",
    "    \"\"\"\n",
    "    Main function to download and process the dataset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    root_path : str, optional\n",
    "        Root directory to save the dataset. If None, uses current directory.\n",
    "    \"\"\"\n",
    "    # Set default root path if not provided\n",
    "    if root_path is None:\n",
    "        root_path = os.getcwd()\n",
    "    \n",
    "    # Create dataset directory\n",
    "    accession_id = \"GSE251715\"\n",
    "    data_dir = os.path.join(root_path, accession_id)\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    # Download dataset if files don't exist\n",
    "    download_dataset(accession_id, data_dir)\n",
    "    \n",
    "    # Process dataset\n",
    "    adata = process_GSE251715(data_dir)\n",
    "    \n",
    "    # Save harmonized dataset\n",
    "    output_file = os.path.join(data_dir, f\"{accession_id}_harmonized.h5ad\")\n",
    "    print(f\"Saving harmonized dataset to {output_file}\")\n",
    "    adata.write(output_file)\n",
    "    print(f\"Dataset saved to {output_file}\")\n",
    "    \n",
    "    return adata\n",
    "\n",
    "# Run the main function and display the AnnData object\n",
    "adata = main()\n",
    "adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3b25c8-58e1-4eb6-b7a6-5d7c96dae9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import pandas as pd\n",
    "\n",
    "def update_adata_obs(adata):\n",
    "    # Ensure the crispr_type column exists, then set all its values to \"CRISPRa\"\n",
    "    adata.obs[\"crispr_type\"] = \"CRISPRa\"\n",
    "\n",
    "    # Handle categorical column issue\n",
    "    if pd.api.types.is_categorical_dtype(adata.obs[\"perturbation_name\"]):\n",
    "        # Add \"Non-targeting\" to the category list\n",
    "        adata.obs[\"perturbation_name\"] = adata.obs[\"perturbation_name\"].cat.add_categories([\"Non-targeting\"])\n",
    "\n",
    "    # Update perturbation_name to \"Non-targeting\" where condition is \"Control\"\n",
    "    adata.obs.loc[adata.obs[\"condition\"] == \"Control\", \"perturbation_name\"] = \"Non-targeting\"\n",
    "\n",
    "    return adata\n",
    "\n",
    "# Example usage\n",
    "# adata = anndata.read_h5ad(\"your_file.h5ad\")  # Load your AnnData file\n",
    "adata = update_adata_obs(adata)  # Apply modifications\n",
    "# adata.write(\"updated_file.h5ad\")  # Save the modified AnnData object\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
