{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Check if we can use anndata, otherwise use h5py directly\n",
    "try:\n",
    "    import anndata as ad\n",
    "    HAS_ANNDATA = True\n",
    "except ImportError:\n",
    "    HAS_ANNDATA = False\n",
    "\n",
    "# Constants\n",
    "GEO_ACCESSION = \"GSE164996\"\n",
    "BASE_URL = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE164nnn/GSE164996/suppl/\"\n",
    "SAMPLES = [\"S1\", \"S2\", \"S3\", \"S4\"]\n",
    "FILE_TYPES = [\n",
    "    \"filtered_barcodes.tsv.gz\",\n",
    "    \"filtered_features.tsv.gz\",\n",
    "    \"filtered_matrix.mtx.gz\",\n",
    "    \"protospacer_calls_per_cell.csv.gz\"\n",
    "]\n",
    "\n",
    "def download_files(data_dir):\n",
    "    \"\"\"Download dataset files if they don't exist.\"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    for sample in SAMPLES:\n",
    "        for file_type in FILE_TYPES:\n",
    "            filename = f\"{GEO_ACCESSION}_{sample}_{file_type}\"\n",
    "            filepath = os.path.join(data_dir, filename)\n",
    "            \n",
    "            if not os.path.exists(filepath):\n",
    "                url = f\"{BASE_URL}{filename}\"\n",
    "                print(f\"Downloading {url} to {filepath}\")\n",
    "                urllib.request.urlretrieve(url, filepath)\n",
    "            else:\n",
    "                print(f\"File {filepath} already exists, skipping download\")\n",
    "\n",
    "def read_mtx_file(file_path):\n",
    "    \"\"\"Read a Matrix Market file and return a CSR sparse matrix.\"\"\"\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        # Skip header lines starting with %\n",
    "        while True:\n",
    "            line = f.readline().strip()\n",
    "            if not line.startswith('%'):\n",
    "                break\n",
    "        \n",
    "        # Parse dimensions\n",
    "        dims = line.split()\n",
    "        n_genes, n_cells, n_entries = map(int, dims)\n",
    "        \n",
    "        # Initialize lists for COO matrix entries\n",
    "        data = []\n",
    "        row_indices = []\n",
    "        col_indices = []\n",
    "        \n",
    "        for _ in range(n_entries):\n",
    "            line = f.readline().strip()\n",
    "            if line:\n",
    "                row, col, value = line.split()\n",
    "                # MTX format is 1-indexed\n",
    "                row_indices.append(int(row) - 1)\n",
    "                col_indices.append(int(col) - 1)\n",
    "                data.append(int(value))\n",
    "        \n",
    "        from scipy.sparse import coo_matrix\n",
    "        matrix = coo_matrix((data, (row_indices, col_indices)), shape=(n_genes, n_cells))\n",
    "        return matrix.tocsr()\n",
    "\n",
    "def process_sample(sample_id, data_dir):\n",
    "    \"\"\"Process a single sample and return its data with unique cell IDs.\"\"\"\n",
    "    print(f\"Processing sample {sample_id}\")\n",
    "    \n",
    "    # Define file paths\n",
    "    matrix_file = os.path.join(data_dir, f\"{GEO_ACCESSION}_{sample_id}_filtered_matrix.mtx.gz\")\n",
    "    features_file = os.path.join(data_dir, f\"{GEO_ACCESSION}_{sample_id}_filtered_features.tsv.gz\")\n",
    "    barcodes_file = os.path.join(data_dir, f\"{GEO_ACCESSION}_{sample_id}_filtered_barcodes.tsv.gz\")\n",
    "    protospacer_file = os.path.join(data_dir, f\"{GEO_ACCESSION}_{sample_id}_protospacer_calls_per_cell.csv.gz\")\n",
    "    \n",
    "    # Load matrix\n",
    "    try:\n",
    "        matrix = read_mtx_file(matrix_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading matrix file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Load features (genes)\n",
    "    with gzip.open(features_file, 'rt') as f:\n",
    "        features = pd.read_csv(f, sep='\\t', header=None)\n",
    "        features.columns = ['gene_id', 'gene_symbol', 'feature_type']\n",
    "    \n",
    "    # Load barcodes\n",
    "    with gzip.open(barcodes_file, 'rt') as f:\n",
    "        barcodes = pd.read_csv(f, sep='\\t', header=None)\n",
    "        barcodes.columns = ['barcode']\n",
    "    \n",
    "    # Load perturbation (protospacer) info\n",
    "    with gzip.open(protospacer_file, 'rt') as f:\n",
    "        perturbations = pd.read_csv(f)\n",
    "    \n",
    "    # Create dictionary mapping original barcode to perturbation call\n",
    "    perturbation_dict = dict(zip(perturbations['cell_barcode'], perturbations['feature_call']))\n",
    "    \n",
    "    # Create unique cell IDs by prefixing with sample_id\n",
    "    unique_barcodes = [f\"{sample_id}_{bc}\" for bc in barcodes['barcode']]\n",
    "    cell_metadata = pd.DataFrame(index=unique_barcodes)\n",
    "    cell_metadata['perturbation'] = [perturbation_dict.get(bc, 'Unknown') for bc in barcodes['barcode']]\n",
    "    cell_metadata['sample_id'] = sample_id\n",
    "    \n",
    "    return {\n",
    "        'matrix': matrix,\n",
    "        'features': features,\n",
    "        'barcodes': unique_barcodes,\n",
    "        'cell_metadata': cell_metadata\n",
    "    }\n",
    "\n",
    "def harmonize_metadata(cell_metadata):\n",
    "    \"\"\"Harmonize metadata: clean perturbation names, set conditions, and add standard fields.\"\"\"\n",
    "    metadata = cell_metadata.copy()\n",
    "    \n",
    "    def parse_perturbation(pert_string):\n",
    "        # Return 'Unknown' if missing\n",
    "        if pd.isna(pert_string) or pert_string == 'Unknown':\n",
    "            return 'Unknown'\n",
    "        \n",
    "        # Split multiple targets (if any)\n",
    "        targets = pert_string.split('|')\n",
    "        # Filter out control calls\n",
    "        non_control_targets = [t for t in targets if not (t.startswith('CTRL') or t.startswith('hRosa26'))]\n",
    "        if len(non_control_targets) == 0:\n",
    "            return 'Control'\n",
    "        # Remove numeric suffix (e.g. _5, _3)\n",
    "        cleaned_targets = [re.sub(r'_\\d+$', '', t) for t in non_control_targets]\n",
    "        if len(cleaned_targets) == 1:\n",
    "            return cleaned_targets[0]\n",
    "        else:\n",
    "            return '+'.join(sorted(cleaned_targets))\n",
    "    \n",
    "    metadata['perturbation_name'] = metadata['perturbation'].apply(parse_perturbation)\n",
    "    \n",
    "    # Set condition: if non-control, mark as \"Test\"; if control, keep as \"Control\"\n",
    "    metadata['condition'] = metadata['perturbation'].apply(\n",
    "        lambda x: 'Control' if pd.isna(x) or x == 'Unknown' or all(t.startswith('CTRL') or t.startswith('hRosa26') for t in x.split('|'))\n",
    "        else 'Test'\n",
    "    )\n",
    "    \n",
    "    # Add additional metadata fields\n",
    "    metadata['organism'] = 'Homo sapiens'\n",
    "    metadata['cell_type'] = 'MCF10A'       # MCF10A-Cas9-Venus-vector cells\n",
    "    metadata['crispr_type'] = 'CRISPR KO'\n",
    "    metadata['cancer_type'] = 'Non-Cancer'\n",
    "    \n",
    "    # Exclude cells with unknown perturbation\n",
    "    metadata = metadata[metadata['perturbation'] != 'Unknown']\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def create_h5ad(data_list, output_file):\n",
    "    \"\"\"Create an h5ad file from processed data.\"\"\"\n",
    "    if not data_list:\n",
    "        print(\"No data to process\")\n",
    "        return\n",
    "    \n",
    "    all_matrices = []\n",
    "    all_metadata = []\n",
    "    \n",
    "    # Assume features are identical across samples (use first sample's features)\n",
    "    features = data_list[0]['features']\n",
    "    \n",
    "    for data in data_list:\n",
    "        all_matrices.append(data['matrix'])\n",
    "        all_metadata.append(data['cell_metadata'])\n",
    "    \n",
    "    from scipy.sparse import hstack\n",
    "    # Horizontally stack matrices (cells are columns)\n",
    "    combined_matrix = hstack(all_matrices).tocsr()\n",
    "    \n",
    "    # Concatenate metadata (order corresponds to matrix column order)\n",
    "    combined_metadata = pd.concat(all_metadata)\n",
    "    \n",
    "    # First, filter out cells with 'Unknown' perturbation\n",
    "    mask = combined_metadata['perturbation'] != 'Unknown'\n",
    "    filtered_metadata = combined_metadata[mask]\n",
    "    \n",
    "    # Harmonize metadata on the filtered set\n",
    "    harmonized_metadata = harmonize_metadata(filtered_metadata)\n",
    "    \n",
    "    # Determine indices (in combined_metadata) of cells to keep\n",
    "    indices_to_keep = [i for i, keep in enumerate(mask) if keep]\n",
    "    filtered_matrix = combined_matrix[:, indices_to_keep]\n",
    "    \n",
    "    if HAS_ANNDATA:\n",
    "        # Create AnnData with cells as rows\n",
    "        adata = ad.AnnData(\n",
    "            X=filtered_matrix.T,\n",
    "            obs=harmonized_metadata,\n",
    "            var=features.set_index('gene_id')\n",
    "        )\n",
    "        # Set gene symbols as variable names\n",
    "        adata.var_names = features['gene_symbol'].values\n",
    "        adata.write(output_file)\n",
    "        print(f\"Saved harmonized data to {output_file}\")\n",
    "        return adata\n",
    "    else:\n",
    "        with h5py.File(output_file, 'w') as f:\n",
    "            matrix_group = f.create_group('X')\n",
    "            matrix_csr = filtered_matrix.T.tocsr()\n",
    "            matrix_group.create_dataset('data', data=matrix_csr.data)\n",
    "            matrix_group.create_dataset('indices', data=matrix_csr.indices)\n",
    "            matrix_group.create_dataset('indptr', data=matrix_csr.indptr)\n",
    "            matrix_group.attrs['shape'] = matrix_csr.shape\n",
    "            \n",
    "            obs_group = f.create_group('obs')\n",
    "            for col in harmonized_metadata.columns:\n",
    "                obs_group.create_dataset(col, data=harmonized_metadata[col].values.astype('S'))\n",
    "            \n",
    "            var_group = f.create_group('var')\n",
    "            for col in features.columns:\n",
    "                var_group.create_dataset(col, data=features[col].values.astype('S'))\n",
    "            \n",
    "            # Save unique cell IDs and gene symbols\n",
    "            f.create_dataset('obs_names', data=np.array(harmonized_metadata.index, dtype='S'))\n",
    "            f.create_dataset('var_names', data=features['gene_symbol'].values.astype('S'))\n",
    "            \n",
    "            print(f\"Saved harmonized data to {output_file} using h5py\")\n",
    "        return None\n",
    "\n",
    "def main(data_dir):\n",
    "    \"\"\"Main function to process and harmonize the dataset in Jupyter Notebook.\"\"\"\n",
    "    output_file = os.path.join(data_dir, f\"{GEO_ACCESSION}_harmonized.h5ad\")\n",
    "    \n",
    "    # Download files if necessary\n",
    "    download_files(data_dir)\n",
    "    \n",
    "    data_list = []\n",
    "    for sample in SAMPLES:\n",
    "        data = process_sample(sample, data_dir)\n",
    "        if data:\n",
    "            data_list.append(data)\n",
    "    \n",
    "    create_h5ad(data_list, output_file)\n",
    "    print(\"Processing complete!\")\n",
    "\n",
    "# Set your data directory and run the main function\n",
    "data_dir = \"data\"  # Modify if needed\n",
    "main(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b38bd-1bdb-4f0a-801c-082ce9d71f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
