{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import urllib.request\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from scipy import io\n",
    "from scipy import sparse\n",
    "\n",
    "# Base URL for GSE272457 dataset\n",
    "GSE272457_BASE_URL = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE272nnn/GSE272457/suppl/\"\n",
    "\n",
    "# List of files to download\n",
    "GSE272457_FILES = [\n",
    "    \"GSE272457_293T_LRB100_NTlib1_barcodes.tsv.gz\",\n",
    "    \"GSE272457_293T_LRB100_NTlib1_features.tsv.gz\",\n",
    "    \"GSE272457_293T_LRB100_NTlib1_matrix.mtx.gz\",\n",
    "    \"GSE272457_293T_LRB100_NTlib1-NIH3T3_LRB100_NTlib2_0hr_mix_barcodes.tsv.gz\",\n",
    "    \"GSE272457_293T_LRB100_NTlib1-NIH3T3_LRB100_NTlib2_0hr_mix_features.tsv.gz\",\n",
    "    \"GSE272457_293T_LRB100_NTlib1-NIH3T3_LRB100_NTlib2_0hr_mix_matrix.mtx.gz\",\n",
    "    \"GSE272457_293T_LRB100_NTlib1-NIH3T3_LRB100_NTlib2_72hr_mix_barcodes.tsv.gz\",\n",
    "    \"GSE272457_293T_LRB100_NTlib1-NIH3T3_LRB100_NTlib2_72hr_mix_features.tsv.gz\",\n",
    "    \"GSE272457_293T_LRB100_NTlib1-NIH3T3_LRB100_NTlib2_72hr_mix_matrix.mtx.gz\",\n",
    "    \"GSE272457_293T_MCH2_NTlib1_barcodes.tsv.gz\",\n",
    "    \"GSE272457_293T_MCH2_NTlib1_features.tsv.gz\",\n",
    "    \"GSE272457_293T_MCH2_NTlib1_matrix.mtx.gz\",\n",
    "    \"GSE272457_293T_MCH2_NTlib1-NIH3T3_MCH2_NTlib2_0hr_mix_barcodes.tsv.gz\",\n",
    "    \"GSE272457_293T_MCH2_NTlib1-NIH3T3_MCH2_NTlib2_0hr_mix_features.tsv.gz\",\n",
    "    \"GSE272457_293T_MCH2_NTlib1-NIH3T3_MCH2_NTlib2_0hr_mix_matrix.mtx.gz\",\n",
    "    \"GSE272457_293T_MCH2_NTlib1-NIH3T3_MCH2_NTlib2_72hr_mix_barcodes.tsv.gz\",\n",
    "    \"GSE272457_293T_MCH2_NTlib1-NIH3T3_MCH2_NTlib2_72hr_mix_features.tsv.gz\",\n",
    "    \"GSE272457_293T_MCH2_NTlib1-NIH3T3_MCH2_NTlib2_72hr_mix_matrix.mtx.gz\",\n",
    "    \"GSE272457_NIH3T3_LRB100_NTlib2_barcodes.tsv.gz\",\n",
    "    \"GSE272457_NIH3T3_LRB100_NTlib2_features.tsv.gz\",\n",
    "    \"GSE272457_NIH3T3_LRB100_NTlib2_matrix.mtx.gz\",\n",
    "    \"GSE272457_NIH3T3_MCH2_NTlib2_barcodes.tsv.gz\",\n",
    "    \"GSE272457_NIH3T3_MCH2_NTlib2_features.tsv.gz\",\n",
    "    \"GSE272457_NIH3T3_MCH2_NTlib2_matrix.mtx.gz\",\n",
    "]\n",
    "\n",
    "def download_file(url: str, output_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Download a file from a URL to a local path.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.exists(output_path):\n",
    "            print(f\"File already exists: {output_path}\")\n",
    "            return True\n",
    "        \n",
    "        print(f\"Downloading {url} to {output_path}\")\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        urllib.request.urlretrieve(url, output_path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def load_10x_data(barcodes_file: str, features_file: str, matrix_file: str) -> Tuple[ad.AnnData, Optional[ad.AnnData]]:\n",
    "    \"\"\"\n",
    "    Load 10x data from barcodes, features, and matrix files.\n",
    "    \"\"\"\n",
    "    # Check if files exist\n",
    "    for file_path in [barcodes_file, features_file, matrix_file]:\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    # Load data\n",
    "    barcodes = pd.read_csv(barcodes_file, header=None, sep='\\t')[0].values\n",
    "    features = pd.read_csv(features_file, header=None, sep='\\t')\n",
    "    matrix = io.mmread(matrix_file).T.tocsr()\n",
    "    \n",
    "    # Process features\n",
    "    feature_ids = features[0].values\n",
    "    feature_names = features[1].values\n",
    "    \n",
    "    # Handle feature types - they might not be present\n",
    "    if features.shape[1] > 2:\n",
    "        feature_types = features[2].values\n",
    "    else:\n",
    "        feature_types = np.array(['Gene Expression'] * len(feature_ids))\n",
    "    \n",
    "    # Check for CRISPR guide features using various possible type names\n",
    "    crispr_type_patterns = [\n",
    "        'CRISPR Guide Capture', 'CRISPR Guide', 'Guide Capture', \n",
    "        'gRNA', 'sgRNA', 'guide', 'CRISPR'\n",
    "    ]\n",
    "    \n",
    "    gene_mask = np.ones(len(feature_types), dtype=bool)\n",
    "    crispr_mask = np.zeros(len(feature_types), dtype=bool)\n",
    "    \n",
    "    for pattern in crispr_type_patterns:\n",
    "        pattern_mask = feature_types == pattern\n",
    "        crispr_mask = crispr_mask | pattern_mask\n",
    "        gene_mask = gene_mask & ~pattern_mask\n",
    "        \n",
    "        # Check for partial match (case insensitive)\n",
    "        for i, ftype in enumerate(feature_types):\n",
    "            if isinstance(ftype, str) and pattern.lower() in ftype.lower():\n",
    "                crispr_mask[i] = True\n",
    "                gene_mask[i] = False\n",
    "    \n",
    "    # If no CRISPR guides were found, try to infer from feature names\n",
    "    if not np.any(crispr_mask):\n",
    "        for i, name in enumerate(feature_names):\n",
    "            if isinstance(name, str) and any(p.lower() in name.lower() for p in ['guide', 'grna', 'sgrna', 'crispr']):\n",
    "                crispr_mask[i] = True\n",
    "                gene_mask[i] = False\n",
    "    \n",
    "    gene_indices = np.where(gene_mask)[0]\n",
    "    crispr_indices = np.where(crispr_mask)[0]\n",
    "    \n",
    "    if len(gene_indices) == 0 and len(crispr_indices) == 0:\n",
    "        gene_indices = np.arange(len(feature_types))\n",
    "        crispr_indices = np.array([], dtype=int)\n",
    "    \n",
    "    cleaned_feature_names = []\n",
    "    for name in feature_names[gene_indices]:\n",
    "        if isinstance(name, str):\n",
    "            for prefix in [\"GRCh38_\", \"mm10_\", \"hg38_\", \"hg19_\", \"mm9_\"]:\n",
    "                if name.startswith(prefix):\n",
    "                    name = name[len(prefix):]\n",
    "                    break\n",
    "            if \"(\" in name and \")\" in name:\n",
    "                symbol_match = re.search(r'\\((.*?)\\)', name)\n",
    "                if symbol_match:\n",
    "                    name = symbol_match.group(1)\n",
    "            if \".\" in name and not name.startswith(\"LOC\"):\n",
    "                name = name.split(\".\")[0]\n",
    "        cleaned_feature_names.append(name)\n",
    "    \n",
    "    # Create gene expression AnnData\n",
    "    if len(gene_indices) > 0:\n",
    "        adata_gene = ad.AnnData(X=matrix[:, gene_indices])\n",
    "        adata_gene.obs_names = barcodes\n",
    "        adata_gene.var['original_names'] = feature_names[gene_indices]\n",
    "        adata_gene.var_names = cleaned_feature_names\n",
    "        adata_gene.var['gene_ids'] = feature_ids[gene_indices]\n",
    "        adata_gene.var['feature_types'] = feature_types[gene_indices]\n",
    "    else:\n",
    "        adata_gene = None\n",
    "    \n",
    "    # Create CRISPR guide AnnData\n",
    "    if len(crispr_indices) > 0:\n",
    "        adata_crispr = ad.AnnData(X=matrix[:, crispr_indices])\n",
    "        adata_crispr.obs_names = barcodes\n",
    "        adata_crispr.var_names = feature_names[crispr_indices]\n",
    "        adata_crispr.var['guide_ids'] = feature_ids[crispr_indices]\n",
    "        adata_crispr.var['feature_types'] = feature_types[crispr_indices]\n",
    "    else:\n",
    "        adata_crispr = None\n",
    "    \n",
    "    return adata_gene, adata_crispr\n",
    "\n",
    "def extract_metadata_from_filename(filename: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Extract metadata from the filename for GSE272457 dataset.\n",
    "    \"\"\"\n",
    "    metadata = {\n",
    "        'dataset': os.path.splitext(os.path.basename(filename))[0],\n",
    "        'organism': 'Unknown',\n",
    "        'cell_type': 'Unknown',\n",
    "        'cancer_type': 'Non-Cancer',\n",
    "        'crispr_type': 'CRISPRi',\n",
    "        'condition': 'Control',\n",
    "        'perturbation_name': 'Unknown',\n",
    "        'time_point': 'Unknown',\n",
    "        'mix': False\n",
    "    }\n",
    "    \n",
    "    if '293T' in filename and 'NIH3T3' in filename:\n",
    "        metadata['organism'] = 'Mixed'\n",
    "        metadata['cell_type'] = 'Mixed'\n",
    "        metadata['mix'] = True\n",
    "    elif '293T' in filename:\n",
    "        metadata['organism'] = 'Homo sapiens'\n",
    "        metadata['cell_type'] = 'HEK293T'\n",
    "    elif 'NIH3T3' in filename:\n",
    "        metadata['organism'] = 'Mus musculus'\n",
    "        metadata['cell_type'] = 'NIH3T3'\n",
    "    \n",
    "    if '0hr' in filename:\n",
    "        metadata['time_point'] = '0hr'\n",
    "    elif '72hr' in filename:\n",
    "        metadata['time_point'] = '72hr'\n",
    "    \n",
    "    if 'NTlib1' in filename and 'NTlib2' not in filename:\n",
    "        metadata['perturbation_name'] = 'Non-targeting'\n",
    "    elif 'NTlib2' in filename and 'NTlib1' not in filename:\n",
    "        metadata['perturbation_name'] = 'Non-targeting'\n",
    "    elif 'NTlib1' in filename and 'NTlib2' in filename:\n",
    "        metadata['perturbation_name'] = 'Non-targeting'\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def find_dataset_files(data_dir: str) -> List[Tuple[str, str, str, str]]:\n",
    "    \"\"\"\n",
    "    Find all dataset files in the data directory.\n",
    "    \"\"\"\n",
    "    dataset_files = []\n",
    "    barcodes_files = glob.glob(os.path.join(data_dir, \"*_barcodes.tsv.gz\"))\n",
    "    \n",
    "    for barcodes_file in barcodes_files:\n",
    "        prefix = barcodes_file.replace(\"_barcodes.tsv.gz\", \"\")\n",
    "        features_file = f\"{prefix}_features.tsv.gz\"\n",
    "        matrix_file = f\"{prefix}_matrix.mtx.gz\"\n",
    "        \n",
    "        if os.path.exists(features_file) and os.path.exists(matrix_file):\n",
    "            dataset_files.append((prefix, barcodes_file, features_file, matrix_file))\n",
    "    \n",
    "    return dataset_files\n",
    "\n",
    "def process_datasets(data_dir: str) -> List[Tuple[ad.AnnData, Optional[ad.AnnData], Dict[str, str]]]:\n",
    "    \"\"\"\n",
    "    Process all datasets in the data directory.\n",
    "    \"\"\"\n",
    "    dataset_files = find_dataset_files(data_dir)\n",
    "    processed_datasets = []\n",
    "    \n",
    "    for prefix, barcodes_file, features_file, matrix_file in dataset_files:\n",
    "        try:\n",
    "            dataset_name = os.path.basename(prefix)\n",
    "            print(f\"Processing dataset: {dataset_name}\")\n",
    "            adata_gene, adata_crispr = load_10x_data(barcodes_file, features_file, matrix_file)\n",
    "            metadata = extract_metadata_from_filename(dataset_name)\n",
    "            processed_datasets.append((adata_gene, adata_crispr, metadata))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing dataset {prefix}: {str(e)}\")\n",
    "    \n",
    "    return processed_datasets\n",
    "\n",
    "def harmonize_datasets(processed_datasets: List[Tuple[ad.AnnData, Optional[ad.AnnData], Dict[str, str]]]) -> ad.AnnData:\n",
    "    \"\"\"\n",
    "    Harmonize multiple datasets into a single AnnData object.\n",
    "    \"\"\"\n",
    "    if not processed_datasets:\n",
    "        raise ValueError(\"No datasets to harmonize\")\n",
    "    \n",
    "    gene_datasets = []\n",
    "    for adata_gene, adata_crispr, metadata in processed_datasets:\n",
    "        if adata_gene is not None:\n",
    "            if not adata_gene.var_names.is_unique:\n",
    "                print(f\"Warning: Dataset {metadata['dataset']} has non-unique var_names. Making them unique...\")\n",
    "                adata_gene.var_names_make_unique()\n",
    "            \n",
    "            if not adata_gene.obs_names.is_unique:\n",
    "                print(f\"Warning: Dataset {metadata['dataset']} has non-unique obs_names. Making them unique...\")\n",
    "                adata_gene.obs_names_make_unique()\n",
    "            \n",
    "            for key, value in metadata.items():\n",
    "                adata_gene.obs[key] = value\n",
    "            \n",
    "            adata_gene.obs_names = [f\"{metadata['dataset']}_{bc}\" for bc in adata_gene.obs_names]\n",
    "            \n",
    "            if adata_crispr is not None:\n",
    "                if not adata_crispr.var_names.is_unique:\n",
    "                    print(f\"Warning: CRISPR data for {metadata['dataset']} has non-unique var_names. Making them unique...\")\n",
    "                    adata_crispr.var_names_make_unique()\n",
    "                if not adata_crispr.obs_names.is_unique:\n",
    "                    print(f\"Warning: CRISPR data for {metadata['dataset']} has non-unique obs_names. Making them unique...\")\n",
    "                    adata_crispr.obs_names_make_unique()\n",
    "                \n",
    "                adata_crispr.obs_names = [f\"{metadata['dataset']}_{bc}\" for bc in adata_crispr.obs_names]\n",
    "                guide_counts = adata_crispr.X.toarray()\n",
    "                max_guide_idx = np.argmax(guide_counts, axis=1)\n",
    "                guide_names = adata_crispr.var_names[max_guide_idx]\n",
    "                adata_gene.obs['guide'] = guide_names\n",
    "                is_targeting = np.array(['non-targeting' not in g.lower() for g in guide_names])\n",
    "                adata_gene.obs['is_targeting'] = is_targeting\n",
    "                if 'perturbation_name' not in adata_gene.obs:\n",
    "                    adata_gene.obs['perturbation_name'] = np.where(is_targeting, guide_names, 'Non-targeting')\n",
    "            else:\n",
    "                adata_gene.obs['guide'] = 'Unknown'\n",
    "                adata_gene.obs['is_targeting'] = False\n",
    "                if 'perturbation_name' not in adata_gene.obs:\n",
    "                    adata_gene.obs['perturbation_name'] = 'Unknown'\n",
    "            \n",
    "            gene_datasets.append(adata_gene)\n",
    "    \n",
    "    if len(gene_datasets) > 1:\n",
    "        common_genes = set(gene_datasets[0].var_names)\n",
    "        for adata in gene_datasets[1:]:\n",
    "            common_genes &= set(adata.var_names)\n",
    "        \n",
    "        if common_genes:\n",
    "            print(f\"Found {len(common_genes)} common genes across all datasets\")\n",
    "            adata_harmonized = ad.concat(\n",
    "                gene_datasets,\n",
    "                join='inner',\n",
    "                merge='same'\n",
    "            )\n",
    "        else:\n",
    "            print(\"Warning: No common genes found across all datasets. Using outer join.\")\n",
    "            adata_harmonized = ad.concat(\n",
    "                gene_datasets,\n",
    "                join='outer',\n",
    "                merge='same',\n",
    "                fill_value=0\n",
    "            )\n",
    "    else:\n",
    "        adata_harmonized = gene_datasets[0]\n",
    "    \n",
    "    required_fields = ['organism', 'cell_type', 'cancer_type', 'crispr_type', 'condition', 'perturbation_name']\n",
    "    for field in required_fields:\n",
    "        if field not in adata_harmonized.obs:\n",
    "            adata_harmonized.obs[field] = 'Unknown'\n",
    "    \n",
    "    return adata_harmonized\n",
    "\n",
    "def download_gse272457_dataset(output_dir: str) -> bool:\n",
    "    \"\"\"\n",
    "    Download GSE272457 dataset files.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    all_successful = True\n",
    "    for file_name in GSE272457_FILES:\n",
    "        url = f\"{GSE272457_BASE_URL}{file_name}\"\n",
    "        output_path = os.path.join(output_dir, file_name)\n",
    "        success = download_file(url, output_path)\n",
    "        all_successful = all_successful and success\n",
    "    return all_successful\n",
    "\n",
    "def run_pipeline(output_dir: str):\n",
    "    \"\"\"\n",
    "    Run the entire pipeline to download, process, harmonize, and save the dataset.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory to save the harmonized dataset and downloads.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    dataset_dir = os.path.join(output_dir, 'GSE272457')\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    \n",
    "    # Download dataset files if they don't exist\n",
    "    if not all(os.path.exists(os.path.join(dataset_dir, file_name)) for file_name in GSE272457_FILES):\n",
    "        print(\"Downloading GSE272457 dataset files...\")\n",
    "        download_gse272457_dataset(dataset_dir)\n",
    "    \n",
    "    print(\"Processing datasets...\")\n",
    "    processed_datasets = process_datasets(dataset_dir)\n",
    "    \n",
    "    print(\"Harmonizing datasets...\")\n",
    "    adata_harmonized = harmonize_datasets(processed_datasets)\n",
    "    \n",
    "    output_path = os.path.join(dataset_dir, 'GSE272457_harmonized.h5ad')\n",
    "    adata_harmonized.write_h5ad(output_path)\n",
    "    \n",
    "    print(\"\\nHarmonization complete!\")\n",
    "    print(f\"Number of cells: {adata_harmonized.n_obs}\")\n",
    "    print(f\"Number of genes: {adata_harmonized.n_vars}\")\n",
    "    print(f\"Organisms: {', '.join(adata_harmonized.obs['organism'].unique())}\")\n",
    "    print(f\"Cell types: {', '.join(adata_harmonized.obs['cell_type'].unique())}\")\n",
    "    print(f\"CRISPR types: {', '.join(adata_harmonized.obs['crispr_type'].unique())}\")\n",
    "    print(f\"Perturbation types: {', '.join(adata_harmonized.obs['perturbation_name'].unique())}\")\n",
    "\n",
    "# Example call from a Jupyter cell:\n",
    "run_pipeline('/content/GSE272457')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b38bd-1bdb-4f0a-801c-082ce9d71f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
