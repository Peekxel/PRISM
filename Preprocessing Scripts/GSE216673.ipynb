{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import gzip\n",
    "import shutil\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "\n",
    "# Set up logging\n",
    "sc.settings.verbosity = 1\n",
    "sc.logging.print_header()\n",
    "\n",
    "class DatasetHarmonizer:\n",
    "    \"\"\"Base class for harmonizing scRNA-seq datasets into standardized h5ad format.\"\"\"\n",
    "    \n",
    "    def __init__(self, accession, root_path):\n",
    "        \"\"\"\n",
    "        Initialize the harmonizer with the accession number and root path.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        accession : str\n",
    "            GEO accession number (e.g., GSE216673)\n",
    "        root_path : str\n",
    "            Path to the directory where data will be stored\n",
    "        \"\"\"\n",
    "        self.accession = accession\n",
    "        self.root_path = Path(root_path)\n",
    "        self.dataset_path = self.root_path / self.accession\n",
    "        \n",
    "        # Ensure the dataset directory exists\n",
    "        os.makedirs(self.dataset_path, exist_ok=True)\n",
    "    \n",
    "    def download_data(self):\n",
    "        \"\"\"Download the dataset if it doesn't exist locally.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement download_data method\")\n",
    "    \n",
    "    def harmonize_dataset(self):\n",
    "        \"\"\"\n",
    "        Process and harmonize the dataset according to the specified standards.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        anndata.AnnData\n",
    "            Harmonized AnnData object\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement harmonize_dataset method\")\n",
    "    \n",
    "    def print_dataset_summary(self, adata):\n",
    "        \"\"\"\n",
    "        Print a summary of the harmonized dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        adata : anndata.AnnData\n",
    "            The harmonized dataset\n",
    "        \"\"\"\n",
    "        print(\"\\nDataset Summary:\")\n",
    "        print(f\"  Total cells: {adata.n_obs}\")\n",
    "        print(f\"  Total genes: {adata.n_vars}\")\n",
    "        \n",
    "        # Count cells by condition\n",
    "        condition_counts = adata.obs['condition'].value_counts()\n",
    "        print(\"\\n  Cells by condition:\")\n",
    "        for condition, count in condition_counts.items():\n",
    "            print(f\"    {condition}: {count} cells\")\n",
    "        \n",
    "        # Count cells by perturbation\n",
    "        perturbation_counts = adata.obs['perturbation_name'].value_counts()\n",
    "        print(\"\\n  Cells by perturbation:\")\n",
    "        for perturbation, count in perturbation_counts.items():\n",
    "            print(f\"    {perturbation}: {count} cells\")\n",
    "        \n",
    "        # Count cells by experiment if available\n",
    "        if 'experiment' in adata.obs:\n",
    "            experiment_counts = adata.obs['experiment'].value_counts()\n",
    "            print(\"\\n  Cells by experiment:\")\n",
    "            for experiment, count in experiment_counts.items():\n",
    "                print(f\"    {experiment}: {count} cells\")\n",
    "        \n",
    "        # Count cells by sample\n",
    "        sample_counts = adata.obs['sample'].value_counts()\n",
    "        print(\"\\n  Cells by sample:\")\n",
    "        for sample, count in sample_counts.items():\n",
    "            print(f\"    {sample}: {count} cells\")\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Main processing function to download, harmonize, and save the dataset.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        str\n",
    "            Path to the saved h5ad file\n",
    "        \"\"\"\n",
    "        # Download and extract data if needed\n",
    "        self.download_data()\n",
    "        \n",
    "        # Harmonize the dataset\n",
    "        adata = self.harmonize_dataset()\n",
    "        \n",
    "        # Save the harmonized dataset\n",
    "        output_file = self.dataset_path / f\"{self.accession}_harmonized.h5ad\"\n",
    "        adata.write_h5ad(output_file)\n",
    "        \n",
    "        print(f\"Harmonized dataset saved to: {output_file}\")\n",
    "        print(f\"Dataset shape: {adata.shape}\")\n",
    "        print(f\"Observations metadata: {list(adata.obs.columns)}\")\n",
    "        \n",
    "        # Print dataset summary\n",
    "        self.print_dataset_summary(adata)\n",
    "        \n",
    "        return str(output_file)\n",
    "\n",
    "\n",
    "class GSE216673Harmonizer(DatasetHarmonizer):\n",
    "    \"\"\"Class to harmonize GSE216673 dataset into standardized h5ad format.\"\"\"\n",
    "    \n",
    "    def __init__(self, root_path):\n",
    "        \"\"\"\n",
    "        Initialize the harmonizer with the root path for data storage.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        root_path : str\n",
    "            Path to the directory where data will be stored\n",
    "        \"\"\"\n",
    "        super().__init__(\"GSE216673\", root_path)\n",
    "        self.raw_data_url = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE216nnn/GSE216673/suppl/GSE216673_RAW.tar\"\n",
    "        self.raw_tar_path = self.dataset_path / \"GSE216673_RAW.tar\"\n",
    "    \n",
    "    def download_data(self):\n",
    "        \"\"\"Download the dataset if it doesn't exist locally.\"\"\"\n",
    "        if not self.raw_tar_path.exists():\n",
    "            print(f\"Downloading {self.accession} dataset...\")\n",
    "            urllib.request.urlretrieve(self.raw_data_url, self.raw_tar_path)\n",
    "            print(f\"Download complete: {self.raw_tar_path}\")\n",
    "        else:\n",
    "            print(f\"Dataset already downloaded: {self.raw_tar_path}\")\n",
    "        \n",
    "        # Extract the tar file if needed\n",
    "        sample_files = list(self.dataset_path.glob(\"GSM*.gz\"))\n",
    "        if not sample_files:\n",
    "            print(\"Extracting tar file...\")\n",
    "            shutil.unpack_archive(self.raw_tar_path, self.dataset_path)\n",
    "            print(\"Extraction complete\")\n",
    "    \n",
    "    def load_10x_data(self, sample_prefix):\n",
    "        \"\"\"\n",
    "        Load a 10X dataset from the specified sample prefix.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        sample_prefix : str\n",
    "            Prefix of the sample files (e.g., \"GSM6685596_WT_TREX1_microglia-Exp1\")\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        anndata.AnnData\n",
    "            AnnData object containing the loaded data\n",
    "        \"\"\"\n",
    "        print(f\"Loading {sample_prefix}...\")\n",
    "        \n",
    "        # File paths\n",
    "        matrix_file = self.dataset_path / f\"{sample_prefix}_matrix.mtx.gz\"\n",
    "        features_file = self.dataset_path / f\"{sample_prefix}_features.tsv.gz\"\n",
    "        barcodes_file = self.dataset_path / f\"{sample_prefix}_barcodes.tsv.gz\"\n",
    "        \n",
    "        # Load the count matrix\n",
    "        counts = sparse.csr_matrix(sc.read_mtx(str(matrix_file)).X.T)\n",
    "        \n",
    "        # Load features (genes)\n",
    "        with gzip.open(features_file, 'rt') as f:\n",
    "            gene_ids = []\n",
    "            gene_symbols = []\n",
    "            for line in f:\n",
    "                fields = line.strip().split('\\t')\n",
    "                gene_ids.append(fields[0])\n",
    "                gene_symbols.append(fields[1])\n",
    "        \n",
    "        # Load cell barcodes\n",
    "        with gzip.open(barcodes_file, 'rt') as f:\n",
    "            barcodes = [line.strip() for line in f]\n",
    "        \n",
    "        # Create a var DataFrame with gene symbols and IDs\n",
    "        var_df = pd.DataFrame({\n",
    "            'gene_ids': gene_ids,\n",
    "            'gene_symbols': gene_symbols\n",
    "        })\n",
    "        \n",
    "        # Make gene symbols unique for index\n",
    "        var_df.index = pd.Index([f\"{s}_{i}\" if gene_symbols.count(s) > 1 else s \n",
    "                                for i, s in enumerate(gene_symbols)])\n",
    "        \n",
    "        # Create AnnData object\n",
    "        adata = ad.AnnData(\n",
    "            X=counts,\n",
    "            obs=pd.DataFrame(index=barcodes),\n",
    "            var=var_df\n",
    "        )\n",
    "        \n",
    "        # Extract metadata from sample name.\n",
    "        # Expecting format: [GSM_ID, condition (WT/KO), perturbation, ...]\n",
    "        sample_info = sample_prefix.split('_')\n",
    "        condition_indicator = sample_info[1]  # \"WT\" or \"KO\"\n",
    "        experiment = sample_info[-1].split('-')[1]  # Exp1, Exp2, etc.\n",
    "        \n",
    "        # Assign metadata using the new rules:\n",
    "        # - For WT samples, condition=\"Control\" and perturbation_name=\"Non-targeting\"\n",
    "        # - For KO samples, condition=\"Test\" and perturbation_name=\"TREX1\"\n",
    "        adata.obs['sample'] = sample_prefix\n",
    "        adata.obs['condition'] = 'Control' if condition_indicator == 'WT' else 'Test'\n",
    "        adata.obs['experiment'] = experiment\n",
    "        adata.obs['perturbation_name'] = 'Non-targeting' if condition_indicator == 'WT' else 'TREX1'\n",
    "        \n",
    "        return adata\n",
    "    \n",
    "    def harmonize_dataset(self):\n",
    "        \"\"\"\n",
    "        Process and harmonize the dataset according to the specified standards.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        anndata.AnnData\n",
    "            Harmonized AnnData object\n",
    "        \"\"\"\n",
    "        # Find all sample prefixes\n",
    "        sample_files = list(self.dataset_path.glob(\"GSM*_barcodes.tsv.gz\"))\n",
    "        sample_prefixes = [f.name.replace(\"_barcodes.tsv.gz\", \"\") for f in sample_files]\n",
    "        \n",
    "        # Load and combine all samples\n",
    "        adatas = []\n",
    "        for prefix in sample_prefixes:\n",
    "            adata = self.load_10x_data(prefix)\n",
    "            adatas.append(adata)\n",
    "        \n",
    "        # Concatenate all samples\n",
    "        if len(adatas) > 1:\n",
    "            combined = ad.concat(\n",
    "                adatas, \n",
    "                join='outer', \n",
    "                merge='same',\n",
    "                label='sample',\n",
    "                keys=sample_prefixes,\n",
    "                index_unique='-'\n",
    "            )\n",
    "        else:\n",
    "            combined = adatas[0]\n",
    "        \n",
    "        # Standardize additional metadata columns\n",
    "        combined.obs['organism'] = 'Homo sapiens'\n",
    "        combined.obs['cell_type'] = 'Microglia'  # Based on dataset description\n",
    "        combined.obs['crispr_type'] = 'CRISPR KO'  # Based on dataset description (TREX1 KO)\n",
    "        combined.obs['cancer_type'] = 'Non-Cancer'  # Based on dataset description\n",
    "        \n",
    "        # Ensure all metadata columns are strings\n",
    "        for col in combined.obs.columns:\n",
    "            combined.obs[col] = combined.obs[col].astype(str)\n",
    "        \n",
    "        # Update metadata based on sample name.\n",
    "        # If the sample name contains \"_KO_\", update as KO sample; otherwise, WT.\n",
    "        combined.obs['condition'] = combined.obs['sample'].apply(\n",
    "            lambda x: 'Test' if '_KO_' in x else 'Control'\n",
    "        )\n",
    "        combined.obs['perturbation_name'] = combined.obs['sample'].apply(\n",
    "            lambda x: 'TREX1' if '_KO_' in x else 'Non-targeting'\n",
    "        )\n",
    "        \n",
    "        # Store original gene symbols for reference\n",
    "        combined.var['original_gene_symbols'] = combined.var['gene_symbols']\n",
    "        \n",
    "        # Ensure we have unique gene symbols as var_names\n",
    "        print(\"Ensuring gene symbols are unique in the final dataset...\")\n",
    "        if not combined.var_names.is_unique:\n",
    "            print(\"Warning: Gene symbols are not unique. They were made unique during loading.\")\n",
    "        \n",
    "        return combined\n",
    "\n",
    "\n",
    "def get_harmonizer(accession, root_path):\n",
    "    \"\"\"\n",
    "    Factory function to get the appropriate harmonizer for a given accession.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    accession : str\n",
    "        GEO accession number\n",
    "    root_path : str\n",
    "        Path to store the data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DatasetHarmonizer\n",
    "        Appropriate harmonizer for the given accession\n",
    "    \"\"\"\n",
    "    if accession == \"GSE216673\":\n",
    "        return GSE216673Harmonizer(root_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported accession: {accession}. Currently only GSE216673 is supported.\")\n",
    "\n",
    "\n",
    "def main(accession=\"GSE216673\", root_path=os.getcwd()):\n",
    "    \"\"\"Main function to run the harmonization process.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    accession : str, optional\n",
    "        GEO accession number (default is \"GSE216673\")\n",
    "    root_path : str, optional\n",
    "        Directory to store data (default is the current working directory)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        harmonizer = get_harmonizer(accession, root_path)\n",
    "        harmonized_file = harmonizer.process()\n",
    "        print(f\"Harmonization complete. File saved at: {harmonized_file}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Usage: call main(accession, root_path)\")\n",
    "\n",
    "# In a Jupyter Notebook, simply call main() to run the harmonization process.\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8e670-7c91-4cb5-8aac-00102b8176b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b38bd-1bdb-4f0a-801c-082ce9d71f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
