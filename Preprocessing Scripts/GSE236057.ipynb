{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "from scipy.io import mmread\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def download_file(url, output_path):\n",
    "    \"\"\"Download a file from a URL to the specified output path.\"\"\"\n",
    "    print(f\"Downloading {url} to {output_path}...\")\n",
    "    urllib.request.urlretrieve(url, output_path)\n",
    "    print(f\"Downloaded {output_path}\")\n",
    "\n",
    "def ensure_files_exist(data_dir):\n",
    "    \"\"\"Ensure all required files exist, downloading them if necessary.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    data_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    base_url = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE236nnn/GSE236057/suppl/\"\n",
    "    files = [\n",
    "        \"GSE236057_FinalCells_Barcodes.tsv.gz\",\n",
    "        \"GSE236057_FinalCells_Counts.mtx.gz\",\n",
    "        \"GSE236057_FinalCells_GeneNames.tsv.gz\",\n",
    "        \"GSE236057_FinalCells_Metadata.csv.gz\"\n",
    "    ]\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = data_dir / file\n",
    "        if not file_path.exists():\n",
    "            url = f\"{base_url}{file}\"\n",
    "            download_file(url, file_path)\n",
    "    \n",
    "    return data_dir\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\"Load the dataset from the specified directory.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    print(\"Loading gene names...\")\n",
    "    genes_df = pd.read_csv(\n",
    "        data_dir / \"GSE236057_FinalCells_GeneNames.tsv.gz\",\n",
    "        sep='\\t', header=None, names=['gene_symbol', 'ensembl_id', 'feature_type']\n",
    "    )\n",
    "    \n",
    "    print(\"Loading cell barcodes...\")\n",
    "    barcodes = pd.read_csv(\n",
    "        data_dir / \"GSE236057_FinalCells_Barcodes.tsv.gz\",\n",
    "        sep='\\t', header=None, names=['barcode']\n",
    "    )\n",
    "    \n",
    "    print(\"Loading count matrix...\")\n",
    "    count_matrix = mmread(str(data_dir / \"GSE236057_FinalCells_Counts.mtx.gz\")).T.tocsr()\n",
    "    \n",
    "    print(\"Loading metadata...\")\n",
    "    metadata = pd.read_csv(data_dir / \"GSE236057_FinalCells_Metadata.csv.gz\", index_col=0)\n",
    "    \n",
    "    print(\"Creating AnnData object...\")\n",
    "    adata = ad.AnnData(\n",
    "        X=count_matrix,\n",
    "        obs=metadata,\n",
    "        var=genes_df.set_index('gene_symbol')\n",
    "    )\n",
    "    adata.obs.index = barcodes['barcode']\n",
    "    adata.obs_names_make_unique()\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def process_guide_information(adata):\n",
    "    \"\"\"\n",
    "    Identify all columns in adata.obs that contain a guide (look for '_g').\n",
    "    - If it's an enhancer-style column (e.g., 'Enh12_g3_chr...'), rename it to 'Enhancer_12'.\n",
    "    - If it starts with 'Pos_', remove 'Pos_' and any trailing '_g\\\\d+.*' (e.g. 'Pos_RPL29_g1' -> 'RPL29').\n",
    "    - Otherwise, remove the trailing '_g\\\\d+.*' from the column name (e.g. 'RPL29_g1' -> 'RPL29').\n",
    "    - Combine multiple guides in the same cell using '+'.\n",
    "    - Finally, set `condition='Control'` for Non-targeting cells, else 'Test'.\n",
    "    \"\"\"\n",
    "    print(\"Processing guide information (removing _g1, _g2, etc.)...\")\n",
    "    \n",
    "    # Start all cells as \"Non-targeting\"\n",
    "    adata.obs['perturbation_name'] = 'Non-targeting'\n",
    "    \n",
    "    # Identify any column that contains '_g' (typical CRISPR guide naming)\n",
    "    guide_cols = [col for col in adata.obs.columns if '_g' in col]\n",
    "    \n",
    "    # Regex to detect enhancers of the form \"Enh(\\d+)_g(\\d+)_chr...\"\n",
    "    enhancer_pat = re.compile(r'^Enh(\\d+)_g\\d+_chr')\n",
    "    \n",
    "    for col in guide_cols:\n",
    "        # 1) Check if it matches the enhancer pattern (Enh12_g3_chrXYZ)\n",
    "        m_enh = enhancer_pat.match(col)\n",
    "        if m_enh:\n",
    "            # Example: Enh12_g3_chr -> 'Enhancer_12'\n",
    "            name = f\"Enhancer_{m_enh.group(1)}\"\n",
    "        \n",
    "        # 2) Else if it starts with 'Pos_', treat as a \"positive-control\" style column\n",
    "        elif col.startswith(\"Pos_\"):\n",
    "            # Remove the 'Pos_' prefix, then remove trailing _g\\d+...\n",
    "            # e.g. Pos_RPL29_g1 -> remove 'Pos_' -> 'RPL29_g1' -> remove '_g1' -> 'RPL29'\n",
    "            subcol = col[len(\"Pos_\"):]  # e.g. 'RPL29_g1'\n",
    "            name = re.sub(r'_g\\d+.*', '', subcol)\n",
    "        \n",
    "        # 3) Otherwise, it's a normal gene column, remove trailing _g\\d+...\n",
    "        else:\n",
    "            name = re.sub(r'_g\\d+.*', '', col)\n",
    "        \n",
    "        # Now set or append this name for cells that are True in that column\n",
    "        cells_with_guide = adata.obs.index[adata.obs[col] == True]\n",
    "        for cell in cells_with_guide:\n",
    "            current = adata.obs.at[cell, 'perturbation_name']\n",
    "            if current == 'Non-targeting':\n",
    "                adata.obs.at[cell, 'perturbation_name'] = name\n",
    "            else:\n",
    "                # If there's already another guide, append with '+'\n",
    "                current_parts = current.split('+')\n",
    "                if name not in current_parts:\n",
    "                    new_val = '+'.join(sorted(current_parts + [name]))\n",
    "                    adata.obs.at[cell, 'perturbation_name'] = new_val\n",
    "    \n",
    "    # Now set condition: 'Control' for Non-targeting, 'Test' otherwise\n",
    "    adata.obs['condition'] = np.where(\n",
    "        adata.obs['perturbation_name'] == 'Non-targeting',\n",
    "        'Control', \n",
    "        'Test'\n",
    "    )\n",
    "    \n",
    "    # Print stats\n",
    "    num_perturbed = (adata.obs['perturbation_name'] != 'Non-targeting').sum()\n",
    "    print(f\"Processed {num_perturbed} cells with a guide (perturbation).\")\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def remove_enhancer_only_cells(adata):\n",
    "    \"\"\"\n",
    "    Remove cells that are enhancer-only (i.e. no gene perturbation, only one or more 'Enhancer_xxx').\n",
    "    \n",
    "    After 'process_guide_information', some cells might have:\n",
    "      - 'Non-targeting'\n",
    "      - 'GeneName' (or 'GeneName+GeneName2')\n",
    "      - 'Enhancer_123' (or multiple enhancers combined)\n",
    "      - 'Gene+Enhancer_123'\n",
    "    This function drops cells that have only enhancers in 'perturbation_name'.\n",
    "    \"\"\"\n",
    "    def is_enhancer_only(p):\n",
    "        if p == \"Non-targeting\":\n",
    "            return False\n",
    "        # If *every* part is 'Enhancer_xxx', then it's \"Enhancer only\"\n",
    "        parts = p.split('+')\n",
    "        return all(part.startswith(\"Enhancer_\") for part in parts)\n",
    "\n",
    "    mask = adata.obs['perturbation_name'].apply(is_enhancer_only)\n",
    "    n_remove = mask.sum()\n",
    "    print(f\"Removing {n_remove} cells that are enhancer-only.\")\n",
    "    \n",
    "    # Drop those cells from the dataset\n",
    "    adata = adata[~mask].copy()\n",
    "    # Optionally, if you want them labeled as Non-targeting instead of removing them,\n",
    "    # you could do something like:\n",
    "    # adata.obs.loc[mask, 'perturbation_name'] = 'Non-targeting'\n",
    "    # adata.obs.loc[mask, 'condition'] = 'Control'\n",
    "    return adata\n",
    "\n",
    "def harmonize_metadata(adata):\n",
    "    \"\"\"Harmonize metadata according to the required standards.\"\"\"\n",
    "    print(\"Harmonizing metadata...\")\n",
    "    \n",
    "    # Add or update relevant metadata fields\n",
    "    adata.obs['organism'] = 'Homo sapiens'\n",
    "    adata.obs['cell_type'] = 'Astrocyte'\n",
    "    adata.obs['crispr_type'] = 'CRISPRi'\n",
    "    adata.obs['cancer_type'] = 'Non-Cancer'\n",
    "    # We do NOT reset 'condition' here because it's already set\n",
    "    # based on whether the cell is Non-targeting or has a perturbation.\n",
    "    \n",
    "    # Rename some columns to more standard names if they exist\n",
    "    rename_dict = {\n",
    "        'UMI_Total': 'umi_count',\n",
    "        'Gene_Total': 'gene_count',\n",
    "        'Mito_Pct': 'mito_percent',\n",
    "        'Library': 'library',\n",
    "        'Cycle_Seurat_Phase': 'cell_cycle_phase',\n",
    "        'Cluster': 'cluster',\n",
    "        'MOI': 'multiplicity_of_infection',\n",
    "        'TransductionPool': 'transduction_pool'\n",
    "    }\n",
    "    \n",
    "    for old_name, new_name in rename_dict.items():\n",
    "        if old_name in adata.obs.columns:\n",
    "            adata.obs[new_name] = adata.obs[old_name]\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def filter_metadata_columns(adata, keep_guide_columns=False):\n",
    "    \"\"\"Filter out unnecessary metadata columns to reduce file size.\"\"\"\n",
    "    print(\"Filtering metadata columns...\")\n",
    "    \n",
    "    # Required columns\n",
    "    required_cols = [\n",
    "        'organism', 'cell_type', 'crispr_type', 'cancer_type', \n",
    "        'condition', 'perturbation_name'\n",
    "    ]\n",
    "    \n",
    "    # Additional useful columns\n",
    "    useful_cols = [\n",
    "        'umi_count', 'gene_count', 'mito_percent', 'library',\n",
    "        'cell_cycle_phase', 'cluster', 'multiplicity_of_infection',\n",
    "        'transduction_pool'\n",
    "    ]\n",
    "    \n",
    "    # Original columns to keep (if they exist)\n",
    "    original_cols = [\n",
    "        'Library', 'UMI_Total', 'Gene_Total', 'Mito_Pct', \n",
    "        'Cycle_Seurat_Phase', 'Cluster', 'MOI', 'TransductionPool',\n",
    "        'AnyGuide'\n",
    "    ]\n",
    "    \n",
    "    keep_cols = required_cols + useful_cols + original_cols\n",
    "    all_cols = adata.obs.columns.tolist()\n",
    "    \n",
    "    if keep_guide_columns:\n",
    "        # Keep columns that match 'Enh' or 'Pos' or anything with '_g'\n",
    "        drop_cols = [\n",
    "            col for col in all_cols \n",
    "            if col not in keep_cols \n",
    "            # only drop if it doesn't look like a guide column\n",
    "            and not re.search(r'(Enh|Pos)_|\\_g\\d+', col)\n",
    "        ]\n",
    "    else:\n",
    "        # Drop columns with any guide pattern\n",
    "        drop_cols = [col for col in all_cols if col not in keep_cols]\n",
    "    \n",
    "    adata.obs = adata.obs.drop(columns=drop_cols)\n",
    "    \n",
    "    print(f\"Kept {len(adata.obs.columns)} columns, dropped {len(drop_cols)} columns\")\n",
    "    return adata\n",
    "\n",
    "\n",
    "def main(data_dir=\"GSE236057\", keep_guide_columns=False):\n",
    "    \"\"\"\n",
    "    Main function to process and harmonize the dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir : str\n",
    "        Directory where data will be downloaded and processed.\n",
    "    keep_guide_columns : bool\n",
    "        If True, keep the original guide columns in adata.obs.\n",
    "    \"\"\"\n",
    "    # Ensure files exist\n",
    "    data_dir = ensure_files_exist(data_dir)\n",
    "    \n",
    "    # Load data\n",
    "    adata = load_data(data_dir)\n",
    "    \n",
    "    # Remove guide suffixes (_g1, etc.) and unify perturbation naming\n",
    "    adata = process_guide_information(adata)\n",
    "    \n",
    "    # >>> Remove enhancer-only cells <<<\n",
    "    adata = remove_enhancer_only_cells(adata)\n",
    "    \n",
    "    # Harmonize metadata\n",
    "    adata = harmonize_metadata(adata)\n",
    "    \n",
    "    # Filter metadata columns\n",
    "    adata = filter_metadata_columns(adata, keep_guide_columns=keep_guide_columns)\n",
    "    \n",
    "    # Save the processed data\n",
    "    output_file = os.path.join(data_dir, \"GSE236057_harmonized_no_enhancer_only.h5ad\")\n",
    "    print(f\"Saving harmonized data (no enhancer-only cells) to {output_file}...\")\n",
    "    adata.write(output_file)\n",
    "    \n",
    "    print(f\"Harmonization complete. Output file: {output_file}\")\n",
    "    print(f\"Dataset shape: {adata.shape}\")\n",
    "    print(f\"Number of unique perturbations: {adata.obs['perturbation_name'].nunique()}\")\n",
    "    \n",
    "    # Print top 10 perturbations\n",
    "    perturbation_counts = adata.obs['perturbation_name'].value_counts()\n",
    "    print(\"\\nTop 10 perturbations by frequency:\")\n",
    "    print(perturbation_counts.head(10))\n",
    "    \n",
    "    return adata\n",
    "\n",
    "# Usage in Jupyter:\n",
    "# 1. Run this entire cell to define the functions.\n",
    "# 2. Then run:\n",
    "adata = main(data_dir=\"GSE236057\", keep_guide_columns=False)\n",
    "#    to process the dataset. This version will remove any cells that only had enhancers\n",
    "#    (e.g. 'Enhancer_123' or 'Enhancer_123+Enhancer_456'), so your final dataset\n",
    "#    contains only Non-targeting cells, gene-targeting cells, or gene+enhancer cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b38bd-1bdb-4f0a-801c-082ce9d71f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
