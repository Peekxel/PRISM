{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% [code]\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import anndata\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('GSE289235_Harmonizer')\n",
    "\n",
    "# Constants\n",
    "GEO_ACCESSION = \"GSE289235\"\n",
    "DATASET_URL = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE289nnn/GSE289235/suppl/GSE289235_RAW.tar\"\n",
    "SAMPLE_ID = \"GSM8787485\"\n",
    "FILE_NAME = \"GSM8787485_EXP224.h5ad\"\n",
    "\n",
    "\n",
    "def download_dataset(data_path):\n",
    "    \"\"\"\n",
    "    Download the dataset if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path where the dataset will be downloaded\n",
    "        \n",
    "    Returns:\n",
    "        Path to the downloaded tar file\n",
    "    \"\"\"\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    tar_path = os.path.join(data_path, f\"{GEO_ACCESSION}_RAW.tar\")\n",
    "    \n",
    "    if not os.path.exists(tar_path):\n",
    "        logger.info(f\"Downloading {GEO_ACCESSION} dataset...\")\n",
    "        urllib.request.urlretrieve(DATASET_URL, tar_path)\n",
    "        logger.info(f\"Download complete: {tar_path}\")\n",
    "    else:\n",
    "        logger.info(f\"Dataset already downloaded: {tar_path}\")\n",
    "    \n",
    "    return tar_path\n",
    "\n",
    "\n",
    "def extract_dataset(tar_path, data_path):\n",
    "    \"\"\"\n",
    "    Extract the dataset from the tar file.\n",
    "    \n",
    "    Args:\n",
    "        tar_path: Path to the tar file\n",
    "        data_path: Path where the dataset will be extracted\n",
    "        \n",
    "    Returns:\n",
    "        Path to the extracted h5ad file\n",
    "    \"\"\"\n",
    "    h5ad_path = os.path.join(data_path, FILE_NAME)\n",
    "    \n",
    "    if not os.path.exists(h5ad_path):\n",
    "        logger.info(f\"Extracting {tar_path}...\")\n",
    "        with tarfile.open(tar_path) as tar:\n",
    "            tar.extract(FILE_NAME, data_path)\n",
    "        logger.info(f\"Extraction complete: {h5ad_path}\")\n",
    "    else:\n",
    "        logger.info(f\"Dataset already extracted: {h5ad_path}\")\n",
    "    \n",
    "    return h5ad_path\n",
    "\n",
    "\n",
    "def load_h5ad_with_h5py(h5ad_path):\n",
    "    \"\"\"\n",
    "    Load the h5ad file using h5py and convert to AnnData.\n",
    "    \n",
    "    Args:\n",
    "        h5ad_path: Path to the h5ad file\n",
    "        \n",
    "    Returns:\n",
    "        AnnData object\n",
    "    \"\"\"\n",
    "    logger.info(f\"Loading {h5ad_path} with h5py...\")\n",
    "    \n",
    "    with h5py.File(h5ad_path, 'r') as f:\n",
    "        # Get the shape of the data matrix\n",
    "        x_shape = f['X'].attrs['shape']\n",
    "        \n",
    "        # Load the CSR matrix components\n",
    "        data = f['X/data'][:]\n",
    "        indices = f['X/indices'][:]\n",
    "        indptr = f['X/indptr'][:]\n",
    "        \n",
    "        # Create a CSR matrix\n",
    "        X = sp.csr_matrix((data, indices, indptr), shape=x_shape)\n",
    "        \n",
    "        # Load obs data\n",
    "        obs_index = [s.decode('utf-8') for s in f['obs/_index'][:]]\n",
    "        \n",
    "        # Load guide information\n",
    "        guide_categories = [s.decode('utf-8') for s in f['obs/guide/categories'][:]]\n",
    "        guide_codes = f['obs/guide/codes'][:]\n",
    "        guides = pd.Categorical.from_codes(guide_codes, categories=guide_categories)\n",
    "        \n",
    "        # Load sample_id information\n",
    "        sample_categories = [s.decode('utf-8') for s in f['obs/sample_id/categories'][:]]\n",
    "        sample_codes = f['obs/sample_id/codes'][:]\n",
    "        sample_ids = pd.Categorical.from_codes(sample_codes, categories=sample_categories)\n",
    "        \n",
    "        # Create obs DataFrame\n",
    "        obs = pd.DataFrame({\n",
    "            'guide': guides,\n",
    "            'sample_id': sample_ids\n",
    "        }, index=obs_index)\n",
    "        \n",
    "        # Load var data (gene names)\n",
    "        var_index = [s.decode('utf-8') for s in f['var/_index'][:]]\n",
    "        var = pd.DataFrame(index=var_index)\n",
    "        \n",
    "    # Create AnnData object\n",
    "    adata = anndata.AnnData(X=X, obs=obs, var=var)\n",
    "    logger.info(f\"Successfully loaded data with shape {adata.shape}\")\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def process_guide_information(adata):\n",
    "    \"\"\"\n",
    "    Process guide information to extract perturbation targets.\n",
    "    Excludes cells with NaN perturbation names, labels non-targeting controls,\n",
    "    and assigns a condition based on the guide.\n",
    "    \n",
    "    Args:\n",
    "        adata: AnnData object\n",
    "        \n",
    "    Returns:\n",
    "        Updated AnnData object with processed perturbation information and conditions.\n",
    "    \"\"\"\n",
    "    logger.info(\"Processing guide information...\")\n",
    "    \n",
    "    # Convert guide to string type\n",
    "    adata.obs['guide'] = adata.obs['guide'].astype(str)\n",
    "    \n",
    "    # Extract gene names from guide names (format: GENE_i1, GENE_i2, etc.)\n",
    "    adata.obs['perturbation_name'] = adata.obs['guide'].str.split('_i', expand=True)[0]\n",
    "    \n",
    "    # Identify non-targeting controls using patterns 'NTC' or 'non-targeting'\n",
    "    is_non_targeting = adata.obs['guide'].str.contains('NTC', case=False, na=False) | \\\n",
    "                       adata.obs['guide'].str.contains('non-targeting', case=False, na=False)\n",
    "    \n",
    "    # Set perturbation_name for controls to 'Non-targeting'\n",
    "    adata.obs.loc[is_non_targeting, 'perturbation_name'] = 'Non-targeting'\n",
    "    \n",
    "    # Exclude cells with 'nan' as the perturbation name (case insensitive)\n",
    "    before_drop = adata.n_obs\n",
    "    adata = adata[adata.obs['perturbation_name'].str.lower() != 'nan'].copy()\n",
    "    after_drop = adata.n_obs\n",
    "    logger.info(f\"Dropped {before_drop - after_drop} cells with NaN perturbation names.\")\n",
    "    \n",
    "    # Set condition: 'Control' for non-targeting and 'Test' for all others\n",
    "    adata.obs['condition'] = np.where(adata.obs['perturbation_name'] == 'Non-targeting', 'Control', 'Test')\n",
    "    \n",
    "    logger.info(f\"Identified {adata.obs['perturbation_name'].nunique()} unique perturbation targets\")\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def harmonize_metadata(adata):\n",
    "    \"\"\"\n",
    "    Harmonize metadata according to the specified requirements.\n",
    "    \n",
    "    Args:\n",
    "        adata: AnnData object\n",
    "        \n",
    "    Returns:\n",
    "        Harmonized AnnData object\n",
    "    \"\"\"\n",
    "    logger.info(\"Harmonizing metadata...\")\n",
    "    \n",
    "    # Add required metadata fields (do not overwrite condition as it's set already)\n",
    "    adata.obs['organism'] = 'Homo sapiens'\n",
    "    adata.obs['cell_type'] = 'iPSC-derived neurons'\n",
    "    adata.obs['crispr_type'] = 'CRISPRi'\n",
    "    adata.obs['cancer_type'] = 'Non-Cancer'\n",
    "    \n",
    "    # Add study information to uns\n",
    "    adata.uns['dataset_id'] = GEO_ACCESSION\n",
    "    adata.uns['sample_id'] = SAMPLE_ID\n",
    "    adata.uns['study_description'] = (\n",
    "        \"A Massively Parallel CRISPR-Based Screening Platform for Modifiers of Neuronal Activity. \"\n",
    "        \"The study used CRISPR interference (CRISPRi) and the fluorescent calcium integrator CaMPARI2 \"\n",
    "        \"to evaluate 1343 genes for their effect on excitability in human iPSC-derived neurons.\"\n",
    "    )\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def save_harmonized_data(adata, output_path):\n",
    "    \"\"\"\n",
    "    Save the harmonized data to h5ad format.\n",
    "    \n",
    "    Args:\n",
    "        adata: AnnData object\n",
    "        output_path: Path where the harmonized data will be saved\n",
    "    \"\"\"\n",
    "    logger.info(f\"Saving harmonized data to {output_path}...\")\n",
    "    adata.write_h5ad(output_path)\n",
    "    logger.info(\"Harmonization complete!\")\n",
    "\n",
    "\n",
    "def main(data_root_path='.'):\n",
    "    \"\"\"\n",
    "    Main function to download, process, and harmonize the dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_root_path: Root path where data will be stored\n",
    "        \n",
    "    Returns:\n",
    "        Path to the harmonized h5ad file\n",
    "    \"\"\"\n",
    "    # Create paths\n",
    "    data_root_path = Path(data_root_path)\n",
    "    data_path = data_root_path / GEO_ACCESSION\n",
    "    output_path = data_path / f\"{GEO_ACCESSION}_harmonized.h5ad\"\n",
    "    \n",
    "    # Download and extract dataset\n",
    "    tar_path = download_dataset(data_path)\n",
    "    h5ad_path = extract_dataset(tar_path, data_path)\n",
    "    \n",
    "    # Load and process data\n",
    "    adata = load_h5ad_with_h5py(h5ad_path)\n",
    "    adata = process_guide_information(adata)\n",
    "    adata = harmonize_metadata(adata)\n",
    "    \n",
    "    # Save harmonized data\n",
    "    save_harmonized_data(adata, output_path)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Run main and display the output path\n",
    "harmonized_file = main('.')\n",
    "print(f\"Harmonized data saved to: {harmonized_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
