{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "import time\n",
    "\n",
    "# URLs for the dataset files\n",
    "DATASET_FILES = {\n",
    "    \"metadata_CER\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE261nnn/GSE261157/suppl/GSE261157_metadata_CER.csv.gz\",\n",
    "    \"metadata_Ctx\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE261nnn/GSE261157/suppl/GSE261157_metadata_Ctx.csv.gz\",\n",
    "    \"preprocessed_data\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE261nnn/GSE261157/suppl/GSE261157_preprocessed_data.txt.gz\"\n",
    "}\n",
    "\n",
    "def download_files(data_dir):\n",
    "    \"\"\"Download dataset files if they don't exist.\"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    for file_name, url in DATASET_FILES.items():\n",
    "        file_path = os.path.join(data_dir, os.path.basename(url))\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Downloading {file_name}...\")\n",
    "            urllib.request.urlretrieve(url, file_path)\n",
    "            print(f\"Downloaded {file_path}\")\n",
    "        else:\n",
    "            print(f\"File {file_path} already exists, skipping download.\")\n",
    "\n",
    "def load_metadata(data_dir):\n",
    "    \"\"\"Load and combine metadata from both CER and Ctx files.\"\"\"\n",
    "    metadata_cer_path = os.path.join(data_dir, \"GSE261157_metadata_CER.csv.gz\")\n",
    "    metadata_ctx_path = os.path.join(data_dir, \"GSE261157_metadata_Ctx.csv.gz\")\n",
    "    \n",
    "    print(\"Loading CER metadata...\")\n",
    "    metadata_cer = pd.read_csv(metadata_cer_path, index_col=0)\n",
    "    print(\"Loading Ctx metadata...\")\n",
    "    metadata_ctx = pd.read_csv(metadata_ctx_path, index_col=0)\n",
    "    \n",
    "    # Combine metadata\n",
    "    metadata = pd.concat([metadata_cer, metadata_ctx])\n",
    "    return metadata\n",
    "\n",
    "def process_expression_data(data_path, metadata_df):\n",
    "    \"\"\"Process expression data efficiently using sparse matrices.\"\"\"\n",
    "    print(f\"Processing expression data from {data_path}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # First pass: get cell barcodes and gene names\n",
    "    print(\"First pass: reading gene names and cell barcodes...\")\n",
    "    with gzip.open(data_path, 'rt') as f:\n",
    "        header = f.readline().strip().replace('\"', '').split(',')\n",
    "        cell_barcodes = header[1:]  # Skip the first column (gene names)\n",
    "        \n",
    "        gene_names = []\n",
    "        for line in f:\n",
    "            gene_names.append(line.strip().split(',')[0].replace('\"', ''))\n",
    "    \n",
    "    print(f\"Found {len(cell_barcodes)} cells in expression data\")\n",
    "    \n",
    "    # Find common cells between metadata and expression data\n",
    "    common_cells = list(set(metadata_df.index) & set(cell_barcodes))\n",
    "    print(f\"Found {len(common_cells)} cells in both metadata and expression data\")\n",
    "    \n",
    "    # Get indices of common cells in the expression data\n",
    "    common_cell_indices = [cell_barcodes.index(cell) for cell in common_cells]\n",
    "    \n",
    "    # Filter metadata to include only the common cells\n",
    "    filtered_metadata = metadata_df.loc[common_cells].copy()\n",
    "    \n",
    "    # Second pass: process gene expression data in chunks\n",
    "    print(\"Second pass: processing gene expression data in chunks...\")\n",
    "    data_values = []\n",
    "    row_indices = []\n",
    "    col_indices = []\n",
    "    \n",
    "    with gzip.open(data_path, 'rt') as f:\n",
    "        f.readline()  # skip header\n",
    "        for gene_idx, line in enumerate(f):\n",
    "            if gene_idx % 1000 == 0:\n",
    "                print(f\"Processed {gene_idx} genes...\")\n",
    "            \n",
    "            parts = line.strip().replace('\"', '').split(',')\n",
    "            \n",
    "            # Extract expression values for common cells only\n",
    "            for i, cell_idx in enumerate(common_cell_indices):\n",
    "                expr_value = int(parts[cell_idx+1]) if parts[cell_idx+1] else 0\n",
    "                if expr_value > 0:  # only store non-zero values\n",
    "                    row_indices.append(i)\n",
    "                    col_indices.append(gene_idx)\n",
    "                    data_values.append(expr_value)\n",
    "    \n",
    "    print(f\"Processed {len(gene_names)} genes total\")\n",
    "    \n",
    "    # Create sparse matrix (cells x genes)\n",
    "    print(\"Creating sparse matrix...\")\n",
    "    expression_matrix = sparse.csr_matrix(\n",
    "        (data_values, (row_indices, col_indices)),\n",
    "        shape=(len(common_cells), len(gene_names))\n",
    "    )\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Expression data processing completed in {elapsed_time:.2f} seconds\")\n",
    "    return expression_matrix, gene_names, filtered_metadata\n",
    "\n",
    "def create_harmonized_anndata(expression_matrix, gene_names, metadata_df):\n",
    "    \"\"\"Create an AnnData object with harmonized metadata.\"\"\"\n",
    "    print(\"Creating AnnData object...\")\n",
    "    adata = ad.AnnData(\n",
    "        X=expression_matrix,\n",
    "        obs=metadata_df,\n",
    "        var=pd.DataFrame(index=gene_names)\n",
    "    )\n",
    "    \n",
    "    print(\"Adding standardized metadata fields...\")\n",
    "    # Organism\n",
    "    adata.obs['organism'] = 'Homo sapiens'\n",
    "    \n",
    "    # Cell type\n",
    "    adata.obs['cell_type'] = adata.obs['clusters_annot']\n",
    "    \n",
    "    # Perturbation name: default is set to \"Non-targeting\"\n",
    "    adata.obs['perturbation_name'] = 'Non-targeting'\n",
    "    # For cells with Genotype \"AxD\", set perturbation name to \"GFAP_R239C\"\n",
    "    adata.obs.loc[adata.obs['Genotype'] == 'AxD', 'perturbation_name'] = 'GFAP'\n",
    "    \n",
    "    # Condition: if perturbation is \"Non-targeting\", set to \"Control\", otherwise use Genotype and Cultivation\n",
    "    adata.obs['condition'] = adata.obs.apply(\n",
    "        lambda row: \"Control\" if row['perturbation_name'] == 'Non-targeting' \n",
    "        else row['Genotype'] + '_' + row['Cultivation'], axis=1)\n",
    "    \n",
    "    # CRISPR type (not applicable for this dataset)\n",
    "    adata.obs['crispr_type'] = 'None'\n",
    "    \n",
    "    # Cancer type (not applicable for this dataset)\n",
    "    adata.obs['cancer_type'] = 'Non-Cancer'\n",
    "    \n",
    "    # Ensure var_names are gene symbols\n",
    "    adata.var_names_make_unique()\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def process_dataset(data_dir):\n",
    "    \"\"\"Process the GSE261157 dataset and create harmonized h5ad file.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    download_files(data_dir)\n",
    "    \n",
    "    print(\"Loading metadata...\")\n",
    "    metadata = load_metadata(data_dir)\n",
    "    print(f\"Metadata loaded: {metadata.shape[0]} cells x {metadata.shape[1]} features\")\n",
    "    \n",
    "    data_path = os.path.join(data_dir, \"GSE261157_preprocessed_data.txt.gz\")\n",
    "    expression_matrix, gene_names, filtered_metadata = process_expression_data(data_path, metadata)\n",
    "    \n",
    "    adata = create_harmonized_anndata(expression_matrix, gene_names, filtered_metadata)\n",
    "    \n",
    "    output_file = os.path.join(data_dir, \"GSE261157_harmonized.h5ad\")\n",
    "    print(f\"Saving harmonized dataset to {output_file}...\")\n",
    "    adata.write(output_file)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Harmonization complete in {total_time:.2f} seconds. Output file: {output_file}\")\n",
    "    print(f\"AnnData object shape: {adata.shape}\")\n",
    "    \n",
    "    print(\"\\nHarmonized dataset summary:\")\n",
    "    print(f\"Number of cells: {adata.n_obs}\")\n",
    "    print(f\"Number of genes: {adata.n_vars}\")\n",
    "    print(f\"Organism: {adata.obs['organism'].unique()[0]}\")\n",
    "    print(f\"Cell types: {', '.join(adata.obs['cell_type'].unique())}\")\n",
    "    print(f\"Conditions: {', '.join(adata.obs['condition'].unique())}\")\n",
    "    print(f\"Perturbations: {', '.join(adata.obs['perturbation_name'].unique())}\")\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def main(data_dir=None):\n",
    "    \"\"\"Main function to process the dataset. Provide a data_dir if desired.\"\"\"\n",
    "    if data_dir is None:\n",
    "        data_dir = os.path.join(os.getcwd(), \"GSE261157\")\n",
    "    \n",
    "    print(f\"Processing GSE261157 dataset in directory: {data_dir}\")\n",
    "    adata = process_dataset(data_dir)\n",
    "    return adata\n",
    "\n",
    "# Run the main function to process the dataset\n",
    "adata = main()  # You can pass a custom directory by calling main('your_directory_path')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8e670-7c91-4cb5-8aac-00102b8176b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b38bd-1bdb-4f0a-801c-082ce9d71f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
