{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eeafb4-c1c2-41f2-95c9-3817cf6e50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import gzip\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "from scipy.io import mmread\n",
    "from pathlib import Path\n",
    "\n",
    "def download_and_extract_data(data_dir):\n",
    "    \"\"\"\n",
    "    Download and extract the GSE247599 dataset if not already present.\n",
    "    \"\"\"\n",
    "    data_path = Path(data_dir) / \"GSE247599\"\n",
    "    data_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Files we expect after extraction\n",
    "    expected_files = [\n",
    "        \"GSM7897841_JKLAT-LRA-Positive_barcodes.tsv.gz\",\n",
    "        \"GSM7897841_JKLAT-LRA-Positive_features.tsv.gz\",\n",
    "        \"GSM7897841_JKLAT-LRA-Positive_matrix.mtx.gz\",\n",
    "        \"GSM7897842_JKLAT-LRA-Negative_barcodes.tsv.gz\",\n",
    "        \"GSM7897842_JKLAT-LRA-Negative_features.tsv.gz\",\n",
    "        \"GSM7897842_JKLAT-LRA-Negative_matrix.mtx.gz\",\n",
    "        \"GSM7897843_JKLAT-NoDrug_barcodes.tsv.gz\",\n",
    "        \"GSM7897843_JKLAT-NoDrug_features.tsv.gz\",\n",
    "        \"GSM7897843_JKLAT-NoDrug_matrix.mtx.gz\"\n",
    "    ]\n",
    "    \n",
    "    all_files_exist = all((data_path / file).exists() for file in expected_files)\n",
    "    \n",
    "    if not all_files_exist:\n",
    "        print(\"Downloading GSE247599 dataset...\")\n",
    "        tar_path = data_path / \"GSE247599_RAW.tar\"\n",
    "        \n",
    "        if not tar_path.exists():\n",
    "            url = \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE247599&format=file\"\n",
    "            urllib.request.urlretrieve(url, tar_path)\n",
    "        \n",
    "        print(\"Extracting files...\")\n",
    "        with tarfile.open(tar_path, \"r\") as tar:\n",
    "            tar.extractall(path=data_path)\n",
    "    \n",
    "    return data_path\n",
    "\n",
    "def get_guide_to_gene_mapping(guide_features):\n",
    "    \"\"\"\n",
    "    Create a mapping from guide names to target genes.\n",
    "    For example, if 'HSPD0000005747_CCNT1' is the feature name, we map that to 'CCNT1'.\n",
    "    \"\"\"\n",
    "    guide_to_gene = {}\n",
    "    for _, row in guide_features.iterrows():\n",
    "        guide_name = row['name']\n",
    "        if '_' in guide_name:\n",
    "            parts = guide_name.split('_')\n",
    "            if len(parts) > 1:\n",
    "                target_gene = parts[-1]\n",
    "                guide_to_gene[guide_name] = target_gene\n",
    "        else:\n",
    "            guide_to_gene[guide_name] = guide_name\n",
    "    return guide_to_gene\n",
    "\n",
    "def process_sample(data_path, sample_id, condition_info, output_dir):\n",
    "    \"\"\"\n",
    "    Process a single sample and save it as an intermediate h5ad file.\n",
    "    \"\"\"\n",
    "    print(f\"Processing {sample_id}...\")\n",
    "    output_file = output_dir / f\"{sample_id}.h5ad\"\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if output_file.exists():\n",
    "        print(f\"  {sample_id} already processed, skipping...\")\n",
    "        return output_file\n",
    "    \n",
    "    # File paths\n",
    "    matrix_file = data_path / f\"{sample_id}_matrix.mtx.gz\"\n",
    "    features_file = data_path / f\"{sample_id}_features.tsv.gz\"\n",
    "    barcodes_file = data_path / f\"{sample_id}_barcodes.tsv.gz\"\n",
    "    \n",
    "    # Read features to separate gene expression and CRISPR guides\n",
    "    with gzip.open(features_file, 'rt') as f:\n",
    "        features_df = pd.read_csv(f, sep='\\t', header=None, names=['id', 'name', 'feature_type'])\n",
    "    \n",
    "    # Identify gene expression and CRISPR guide features\n",
    "    gene_indices = features_df['feature_type'] == 'Gene Expression'\n",
    "    guide_indices = features_df['feature_type'] == 'CRISPR Guide Capture'\n",
    "    \n",
    "    gene_features = features_df[gene_indices].reset_index(drop=True)\n",
    "    guide_features = features_df[guide_indices].reset_index(drop=True) if guide_indices.any() else None\n",
    "    \n",
    "    # Read barcodes and verify uniqueness\n",
    "    with gzip.open(barcodes_file, 'rt') as f:\n",
    "        barcodes = pd.read_csv(f, sep='\\t', header=None)[0].values\n",
    "    \n",
    "    if len(set(barcodes)) != len(barcodes):\n",
    "        print(\"Warning: Duplicate barcodes found in the barcodes file!\")\n",
    "    \n",
    "    # Read the matrix\n",
    "    print(f\"  Reading matrix for {sample_id}...\")\n",
    "    with gzip.open(matrix_file, 'rb') as f:\n",
    "        X = mmread(f).tocsr()\n",
    "    \n",
    "    # Transpose so that rows=cell-barcodes, columns=features\n",
    "    X = X.transpose()\n",
    "    \n",
    "    # Extract the gene-expression columns\n",
    "    gene_indices_list = np.where(gene_indices)[0]\n",
    "    gene_X = X[:, gene_indices_list]\n",
    "    \n",
    "    # Build AnnData for gene expression\n",
    "    print(f\"  Creating AnnData object for {sample_id}...\")\n",
    "    adata = sc.AnnData(X=gene_X)\n",
    "    adata.obs_names = pd.Index(barcodes)\n",
    "    adata.var_names = pd.Index(gene_features['name'].values)\n",
    "    adata.var['gene_ids'] = gene_features['id'].values\n",
    "    \n",
    "    # Make var names unique if needed\n",
    "    adata.var_names_make_unique()\n",
    "    \n",
    "    # Add standardized metadata\n",
    "    print(f\"  Adding metadata for {sample_id}...\")\n",
    "    adata.obs['organism'] = \"Homo sapiens\"         # from the experiment description\n",
    "    adata.obs['cell_type'] = \"Jurkat T Cells\"       # known from the publication\n",
    "    adata.obs['crispr_type'] = \"CRISPR KO\"          # from the text, they used Cas9-based perturbation\n",
    "    adata.obs['cancer_type'] = \"T-cell leukemia\"    # Jurkat is a T-leukemia line\n",
    "    adata.obs['sample_id'] = sample_id\n",
    "    \n",
    "    # For user-defined conditions\n",
    "    adata.obs['stimulation'] = condition_info.get('stimulation', 'NA')\n",
    "    adata.obs['gfp_status'] = condition_info.get('gfp_status', 'NA')\n",
    "    adata.obs['sample_condition'] = condition_info.get('condition', 'NA')\n",
    "    \n",
    "    # Parse CRISPR guides\n",
    "    if guide_features is not None and not guide_features.empty:\n",
    "        print(f\"  Processing CRISPR guide data for {sample_id}...\")\n",
    "        guide_indices_list = np.where(guide_indices)[0]\n",
    "        \n",
    "        # guide -> gene mapping\n",
    "        guide_to_gene = get_guide_to_gene_mapping(guide_features)\n",
    "        \n",
    "        # We'll iterate over cells in small batches to avoid memory spikes\n",
    "        batch_size = 20000\n",
    "        num_cells = X.shape[0]\n",
    "        perturbation_names = [\"None\"] * num_cells\n",
    "        \n",
    "        for i in range(0, num_cells, batch_size):\n",
    "            end_idx = min(i + batch_size, num_cells)\n",
    "            if i % 100000 == 0:\n",
    "                print(f\"  Processing cells {i}-{end_idx} of {num_cells}...\")\n",
    "            \n",
    "            # Extract only the guide columns for the batch\n",
    "            batch_X = X[i:end_idx, guide_indices_list].toarray()\n",
    "            \n",
    "            # For each cell in the batch\n",
    "            for j in range(batch_X.shape[0]):\n",
    "                nonzero_indices = np.where(batch_X[j, :] > 0)[0]\n",
    "                if len(nonzero_indices) > 0:\n",
    "                    # The guide names we see\n",
    "                    detected_guides = [guide_features.iloc[idx]['name'] for idx in nonzero_indices]\n",
    "                    \n",
    "                    # Map to target genes\n",
    "                    target_genes = [guide_to_gene.get(g, g) for g in detected_guides]\n",
    "                    target_genes = sorted(set(target_genes))\n",
    "                    \n",
    "                    # Summarize in a single string\n",
    "                    perturbation_names[i + j] = \" + \".join(target_genes)\n",
    "            \n",
    "            del batch_X\n",
    "            gc.collect()\n",
    "        \n",
    "        adata.obs['perturbation_name'] = perturbation_names\n",
    "        adata.uns['guide_targets'] = guide_to_gene\n",
    "    else:\n",
    "        adata.obs['perturbation_name'] = \"None\"\n",
    "    \n",
    "    # Determine whether a cell is \"Control\" or \"Test\" based on the 'perturbation_name'\n",
    "    def classify_condition(pert_name):\n",
    "        if pert_name in ['None', 'NegativeControl1', 'NegativeControl2', \n",
    "                         'NegativeControl3', 'HScontrol_AAVS1']:\n",
    "            return 'Control'\n",
    "        else:\n",
    "            return 'Test'\n",
    "    \n",
    "    adata.obs['condition'] = adata.obs['perturbation_name'].apply(classify_condition)\n",
    "    \n",
    "    # Save the processed sample\n",
    "    print(f\"  Saving {sample_id} to {output_file}\")\n",
    "    adata.write_h5ad(output_file)\n",
    "    \n",
    "    # Cleanup\n",
    "    del X, gene_X, adata\n",
    "    gc.collect()\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "def combine_samples(sample_files, output_file):\n",
    "    \"\"\"\n",
    "    Combine multiple h5ad files into a single h5ad file.\n",
    "    \"\"\"\n",
    "    print(\"Combining samples...\")\n",
    "    adata_list = []\n",
    "    for i, sf in enumerate(sample_files):\n",
    "        print(f\"  Reading {sf}\")\n",
    "        ad = sc.read_h5ad(sf)\n",
    "        adata_list.append(ad)\n",
    "    \n",
    "    print(\"  Concatenating samples...\")\n",
    "    adata_combined = sc.concat(adata_list, join='outer', merge='same')\n",
    "    \n",
    "    print(f\"  Saving combined dataset to {output_file}\")\n",
    "    adata_combined.write_h5ad(output_file)\n",
    "    \n",
    "    print(f\"Dataset saved to {output_file}\")\n",
    "    print(f\"Final dataset shape: {adata_combined.shape}\")\n",
    "    print(f\"Number of cells: {adata_combined.n_obs}\")\n",
    "    print(f\"Number of genes: {adata_combined.n_vars}\")\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "def filter_combined_dataset(combined_file, min_genes=200, min_counts=500):\n",
    "    \"\"\"\n",
    "    Filter the combined AnnData object based on QC metrics:\n",
    "      - Retains cells with at least `min_genes` expressed genes\n",
    "      - Retains cells with at least `min_counts` total counts\n",
    "    \"\"\"\n",
    "    print(\"Filtering combined dataset for QC metrics...\")\n",
    "    adata = sc.read_h5ad(combined_file)\n",
    "    \n",
    "    # Compute QC metrics\n",
    "    adata.obs[\"n_counts\"] = np.ravel(adata.X.sum(axis=1))\n",
    "    adata.obs[\"n_genes\"] = np.ravel((adata.X > 0).sum(axis=1))\n",
    "    \n",
    "    # Apply the filters\n",
    "    filtered_adata = adata[\n",
    "        (adata.obs[\"n_genes\"] >= min_genes) & \n",
    "        (adata.obs[\"n_counts\"] >= min_counts)\n",
    "    ].copy()\n",
    "    \n",
    "    print(\"Original shape:\", adata.shape)\n",
    "    print(\"Filtered shape:\", filtered_adata.shape)\n",
    "    \n",
    "    filtered_file = combined_file.parent / \"GSE247599_harmonized_filtered.h5ad\"\n",
    "    filtered_adata.write_h5ad(filtered_file)\n",
    "    print(\"Filtered dataset saved to\", filtered_file)\n",
    "    return filtered_file\n",
    "\n",
    "def harmonize_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    Main entry point:\n",
    "      - Download/unzip data if needed\n",
    "      - Process each sample\n",
    "      - Combine into a single h5ad\n",
    "      - Filter the combined dataset based on QC metrics\n",
    "    \"\"\"\n",
    "    data_path = download_and_extract_data(data_dir)\n",
    "    \n",
    "    # Create a directory for intermediate output\n",
    "    output_dir = data_path / \"processed\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Sample information\n",
    "    samples = {\n",
    "        \"GSM7897841_JKLAT-LRA-Positive\": {\n",
    "            \"condition\": \"Stimulated\",\n",
    "            \"gfp_status\": \"GFP+\",\n",
    "            \"stimulation\": \"PMA/I\"\n",
    "        },\n",
    "        \"GSM7897842_JKLAT-LRA-Negative\": {\n",
    "            \"condition\": \"Stimulated\",\n",
    "            \"gfp_status\": \"GFP-\",\n",
    "            \"stimulation\": \"PMA/I\"\n",
    "        },\n",
    "        \"GSM7897843_JKLAT-NoDrug\": {\n",
    "            \"condition\": \"Unstimulated\",\n",
    "            \"gfp_status\": \"NA\",\n",
    "            \"stimulation\": \"None\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Process each sample\n",
    "    sample_files = []\n",
    "    for sample_id, condition_info in samples.items():\n",
    "        sf = process_sample(data_path, sample_id, condition_info, output_dir)\n",
    "        sample_files.append(sf)\n",
    "    \n",
    "    # Combine the samples\n",
    "    combined_file = data_path / \"GSE247599_harmonized.h5ad\"\n",
    "    combine_samples(sample_files, combined_file)\n",
    "    \n",
    "    # Apply filtering to the combined dataset\n",
    "    filtered_file = filter_combined_dataset(combined_file, min_genes=200, min_counts=500)\n",
    "    \n",
    "    return filtered_file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage: python script.py /path/to/data\n",
    "    # If no argument is passed, default to current directory\n",
    "    if len(sys.argv) > 1:\n",
    "        data_dir = sys.argv[1]\n",
    "    else:\n",
    "        data_dir = \"/content\"\n",
    "\n",
    "    final_file = harmonize_dataset(data_dir)\n",
    "    print(\"Harmonization and filtering complete! File saved at:\", final_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
