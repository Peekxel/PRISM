{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy.sparse as sparse\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def download_data(data_dir):\n",
    "    \"\"\"\n",
    "    Download the GSE272093 dataset if not already present.\n",
    "    \"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    files_to_download = {\n",
    "        \"GSE272093_RAW.tar\": \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE272093&format=file\",\n",
    "        \"GSE272093_sgRNA_assignments.txt.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE272nnn/GSE272093/suppl/GSE272093_sgRNA_assignments.txt.gz\"\n",
    "    }\n",
    "    \n",
    "    for filename, url in files_to_download.items():\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            try:\n",
    "                urllib.request.urlretrieve(url, filepath)\n",
    "                print(f\"Downloaded {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {filename}: {e}\")\n",
    "                if os.path.exists(filepath):\n",
    "                    os.remove(filepath)\n",
    "        else:\n",
    "            print(f\"{filename} already exists, skipping download\")\n",
    "    \n",
    "    tar_filepath = os.path.join(data_dir, \"GSE272093_RAW.tar\")\n",
    "    if os.path.exists(tar_filepath):\n",
    "        sample_file = os.path.join(data_dir, \"GSM8392917_EL1_Day14_matrix.mtx.gz\")\n",
    "        if not os.path.exists(sample_file):\n",
    "            print(\"Extracting GSE272093_RAW.tar...\")\n",
    "            try:\n",
    "                with tarfile.open(tar_filepath) as tar:\n",
    "                    tar.extractall(path=data_dir)\n",
    "                print(\"Extracted GSE272093_RAW.tar\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting {tar_filepath}: {e}\")\n",
    "        else:\n",
    "            print(\"Files already extracted, skipping extraction\")\n",
    "\n",
    "def load_10x_data(data_dir, sample_id):\n",
    "    \"\"\"\n",
    "    Load 10x data for a given sample.\n",
    "    \"\"\"\n",
    "    matrix_file = os.path.join(data_dir, f\"{sample_id}_matrix.mtx.gz\")\n",
    "    features_file = os.path.join(data_dir, f\"{sample_id}_features.tsv.gz\")\n",
    "    barcodes_file = os.path.join(data_dir, f\"{sample_id}_barcodes.tsv.gz\")\n",
    "    \n",
    "    for file_path in [matrix_file, features_file, barcodes_file]:\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File {file_path} not found\")\n",
    "    \n",
    "    print(f\"Loading matrix from {matrix_file}...\")\n",
    "    start_time = time.time()\n",
    "    with gzip.open(matrix_file, 'rb') as f:\n",
    "        X = sio.mmread(f).T.tocsr()  # Transpose so that cells are rows, genes are columns\n",
    "    print(f\"Matrix loaded in {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    print(f\"Loading features from {features_file}...\")\n",
    "    features = pd.read_csv(features_file, sep='\\t', header=None)\n",
    "    gene_ids = features[0].values\n",
    "    gene_symbols = features[1].values\n",
    "    \n",
    "    print(f\"Loading barcodes from {barcodes_file}...\")\n",
    "    barcodes = pd.read_csv(barcodes_file, sep='\\t', header=None)[0].values\n",
    "    \n",
    "    return {'X': X, 'gene_ids': gene_ids, 'gene_symbols': gene_symbols, 'barcodes': barcodes}\n",
    "\n",
    "def load_sgRNA_assignments(data_dir):\n",
    "    \"\"\"\n",
    "    Load sgRNA assignments.\n",
    "    \"\"\"\n",
    "    sgRNA_file = os.path.join(data_dir, \"GSE272093_sgRNA_assignments.txt.gz\")\n",
    "    print(f\"Loading sgRNA assignments from {sgRNA_file}...\")\n",
    "    sgRNA_assignments = pd.read_csv(sgRNA_file, sep='\\t')\n",
    "    return sgRNA_assignments\n",
    "\n",
    "def load_mapped_data(data_dir, sample_id):\n",
    "    \"\"\"\n",
    "    Load mapped data (CSV with sgRNA assignments) for a sample.\n",
    "    \"\"\"\n",
    "    mapped_file = os.path.join(data_dir, f\"{sample_id}.csv.gz\")\n",
    "    if not os.path.exists(mapped_file):\n",
    "        raise FileNotFoundError(f\"File {mapped_file} not found\")\n",
    "    \n",
    "    print(f\"Loading mapped data from {mapped_file}...\")\n",
    "    start_time = time.time()\n",
    "    chunks = []\n",
    "    chunk_size = 100000\n",
    "    for chunk in pd.read_csv(mapped_file, chunksize=chunk_size):\n",
    "        chunks.append(chunk)\n",
    "        print(f\"Loaded {len(chunks) * chunk_size} rows...\")\n",
    "    mapped_data = pd.concat(chunks, ignore_index=True)\n",
    "    print(f\"Mapped data loaded in {time.time() - start_time:.2f} seconds\")\n",
    "    return mapped_data\n",
    "\n",
    "def extract_perturbation_info(guide_name):\n",
    "    \"\"\"\n",
    "    Extract perturbation information from a guide name.\n",
    "    \"\"\"\n",
    "    if pd.isna(guide_name) or guide_name == \"None\":\n",
    "        return {\"perturbation_name\": \"Non-targeting\", \"crispr_type\": \"CRISPRi\", \"targeting\": \"Non-targeting\"}\n",
    "    \n",
    "    match = re.match(r'guide_([^_]+)', guide_name)\n",
    "    if match:\n",
    "        gene_name = match.group(1)\n",
    "        return {\"perturbation_name\": gene_name, \"crispr_type\": \"CRISPRi\", \"targeting\": \"Targeting\"}\n",
    "    else:\n",
    "        return {\"perturbation_name\": \"Unknown\", \"crispr_type\": \"CRISPRi\", \"targeting\": \"Unknown\"}\n",
    "\n",
    "def parse_multi_guide_name(guide_str):\n",
    "    \"\"\"\n",
    "    Split a multi-guide string on commas and extract only the gene name portion.\n",
    "    Example:\n",
    "        \"guide_CDK8_-_26828453.23-P1P2,guide_UQCRQ_-_132202364.23-P1P2\"\n",
    "        -> \"CDK8 + UQCRQ\"\n",
    "    \"\"\"\n",
    "    if pd.isna(guide_str):\n",
    "        return None\n",
    "    \n",
    "    # Split on commas to get each guide entry\n",
    "    guide_entries = guide_str.split(',')\n",
    "    \n",
    "    # For each guide, extract the gene name (the piece after 'guide_' and before the next underscore)\n",
    "    genes = []\n",
    "    for entry in guide_entries:\n",
    "        parts = entry.split('_')\n",
    "        if len(parts) > 1:\n",
    "            gene_name = parts[1]  # e.g. \"CDK8\", \"NonTargeting\"\n",
    "        else:\n",
    "            gene_name = \"Unknown\"\n",
    "        genes.append(gene_name)\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    # Example: if \"CDK8\" appears multiple times, we keep only one\n",
    "    genes = list(dict.fromkeys(genes))\n",
    "    \n",
    "    # Join with \" + \"\n",
    "    return \" + \".join(genes)\n",
    "\n",
    "def process_sample(data_dir, sample_info):\n",
    "    \"\"\"\n",
    "    Example of how to integrate the parse_multi_guide_name function\n",
    "    to create a multi-gene 'perturbation_name'.\n",
    "    \"\"\"\n",
    "    print(f\"Processing sample {sample_info['sample_id']}...\")\n",
    "    \n",
    "    # -- Load expression data (unchanged) --\n",
    "    data = load_10x_data(data_dir, sample_info['expression_id'])\n",
    "    \n",
    "    # Create obs and var\n",
    "    obs = pd.DataFrame(index=data['barcodes'])\n",
    "    var = pd.DataFrame(index=data['gene_symbols'])\n",
    "    var['gene_ids'] = data['gene_ids']\n",
    "    \n",
    "    # If mapped data exists\n",
    "    if sample_info['mapped_id']:\n",
    "        try:\n",
    "            mapped_data = load_mapped_data(data_dir, sample_info['mapped_id'])\n",
    "            print(\"Processing sgRNA assignments...\")\n",
    "            cell_to_guide = {}\n",
    "            \n",
    "            # Build a dict of {cell_barcode: \"guide1,guide2,...\"}\n",
    "            for _, row in mapped_data.iterrows():\n",
    "                cell_barcode = row['cell']\n",
    "                gRNA = row['gRNA']\n",
    "                if cell_barcode in cell_to_guide:\n",
    "                    # Append this guide if not already present\n",
    "                    existing = cell_to_guide[cell_barcode].split(',')\n",
    "                    if gRNA not in existing:\n",
    "                        existing.append(gRNA)\n",
    "                        cell_to_guide[cell_barcode] = ','.join(existing)\n",
    "                else:\n",
    "                    cell_to_guide[cell_barcode] = gRNA\n",
    "            \n",
    "            # Assign new multi-guide string to obs['guide']\n",
    "            parsed_guides = []\n",
    "            parsed_perturbations = []\n",
    "            \n",
    "            for cell in obs.index:\n",
    "                raw_guides = cell_to_guide.get(cell, None)\n",
    "                \n",
    "                # The 'guide' column can store the raw comma-delimited info\n",
    "                parsed_guides.append(raw_guides)\n",
    "                \n",
    "                # Convert the raw string into a \"gene1 + gene2\" format\n",
    "                p_name = parse_multi_guide_name(raw_guides)\n",
    "                parsed_perturbations.append(p_name)\n",
    "            \n",
    "            obs['guide'] = parsed_guides\n",
    "            obs['perturbation_name'] = parsed_perturbations\n",
    "            \n",
    "            # For example, define 'crispr_type' always as 'CRISPRi',\n",
    "            # and 'targeting' is 'Non-targeting' if *all* genes are NonTargeting,\n",
    "            # or 'Targeting' otherwise.\n",
    "            targeting_list = []\n",
    "            for p_name in obs['perturbation_name']:\n",
    "                if p_name is None:\n",
    "                    targeting_list.append(\"Unknown\")\n",
    "                elif p_name.startswith(\"NonTargeting\"):\n",
    "                    targeting_list.append(\"Non-targeting\")\n",
    "                else:\n",
    "                    targeting_list.append(\"Targeting\")\n",
    "            \n",
    "            obs['crispr_type'] = \"CRISPRi\"\n",
    "            obs['targeting'] = targeting_list\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing mapped data: {e}\")\n",
    "            # Fallback defaults\n",
    "            obs['guide'] = None\n",
    "            obs['perturbation_name'] = \"Unknown\"\n",
    "            obs['crispr_type'] = \"CRISPRi\"\n",
    "            obs['targeting'] = \"Unknown\"\n",
    "    else:\n",
    "        # If no mapped data\n",
    "        obs['guide'] = None\n",
    "        obs['perturbation_name'] = \"Unknown\"\n",
    "        obs['crispr_type'] = \"CRISPRi\"\n",
    "        obs['targeting'] = \"Unknown\"\n",
    "    \n",
    "    # Standard metadata\n",
    "    obs['organism'] = \"Homo sapiens\"\n",
    "    obs['cell_type'] = sample_info['cell_type']\n",
    "    obs['condition'] = sample_info['condition']\n",
    "    obs['cancer_type'] = \"Non-Cancer\"\n",
    "    obs['sample_id'] = sample_info['sample_id']\n",
    "    obs['culture_type'] = sample_info['culture_type']\n",
    "    \n",
    "    harmonized_data = {\n",
    "        'X': data['X'],\n",
    "        'obs': obs,\n",
    "        'var': var,\n",
    "        'uns': {\n",
    "            'sample_info': sample_info,\n",
    "            'dataset_id': 'GSE272093',\n",
    "            'harmonization_date': datetime.now().strftime('%Y-%m-%d'),\n",
    "            'description': 'CRISPRi-based screens in iAssembloids to elucidate neuron-glia interactions'\n",
    "        }\n",
    "    }\n",
    "    return harmonized_data\n",
    "\n",
    "def save_h5ad(harmonized_data, output_file):\n",
    "    \"\"\"\n",
    "    Save harmonized data to h5ad format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import anndata as ad\n",
    "        print(f\"Creating AnnData object...\")\n",
    "        start_time = time.time()\n",
    "        adata = ad.AnnData(\n",
    "            X=harmonized_data['X'],\n",
    "            obs=harmonized_data['obs'],\n",
    "            var=harmonized_data['var'],\n",
    "            uns=harmonized_data['uns']\n",
    "        )\n",
    "        print(f\"AnnData object created in {time.time() - start_time:.2f} seconds\")\n",
    "        print(f\"Saving to {output_file}...\")\n",
    "        start_time = time.time()\n",
    "        adata.write(output_file)\n",
    "        print(f\"Saved harmonized data to {output_file} in {time.time() - start_time:.2f} seconds\")\n",
    "        return adata\n",
    "    except ImportError:\n",
    "        print(\"Warning: anndata package not available, saving in numpy format instead\")\n",
    "        np.savez(\n",
    "            output_file.replace('.h5ad', '.npz'),\n",
    "            X=harmonized_data['X'].toarray(),\n",
    "            obs=harmonized_data['obs'].to_dict('list'),\n",
    "            var=harmonized_data['var'].to_dict('list'),\n",
    "            uns=harmonized_data['uns']\n",
    "        )\n",
    "        print(f\"Saved harmonized data to {output_file.replace('.h5ad', '.npz')}\")\n",
    "        return None\n",
    "\n",
    "def harmonize_dataset(data_dir=None):\n",
    "    \"\"\"\n",
    "    Harmonize the GSE272093 dataset across multiple samples.\n",
    "    \"\"\"\n",
    "    if data_dir is None:\n",
    "        data_dir = os.getcwd()\n",
    "    \n",
    "    download_data(data_dir)\n",
    "    \n",
    "    samples = [\n",
    "        {\n",
    "            'sample_id': 'GSM8392917',\n",
    "            'expression_id': 'GSM8392917_EL1_Day14',\n",
    "            'mapped_id': 'GSM8392920_EL1_Monoculture_1_mapped',\n",
    "            'description': '2D monoculture neuron CROP-seq rep 1',\n",
    "            'cell_type': 'Neurons',\n",
    "            'condition': 'Control',\n",
    "            'culture_type': '2D monoculture'\n",
    "        },\n",
    "        {\n",
    "            'sample_id': 'GSM8392918',\n",
    "            'expression_id': 'GSM8392918_EL2_Day14_3D_Culture1',\n",
    "            'mapped_id': 'GSM8392921_EL2_iAssembloid_1_mapped',\n",
    "            'description': 'iAssembloids neuron CROP-seq rep 1',\n",
    "            'cell_type': 'Mixed (Neurons, Astrocytes, Microglia)',\n",
    "            'condition': 'Control',\n",
    "            'culture_type': '3D iAssembloid'\n",
    "        },\n",
    "        {\n",
    "            'sample_id': 'GSM8392919',\n",
    "            'expression_id': 'GSM8392919_EL3_Day14_3D_Culture2',\n",
    "            'mapped_id': 'GSM8392922_EL3_iAssembloid_2_mapped',\n",
    "            'description': 'iAssembloids neuron CROP-seq rep 2',\n",
    "            'cell_type': 'Mixed (Neurons, Astrocytes, Microglia)',\n",
    "            'condition': 'Control',\n",
    "            'culture_type': '3D iAssembloid'\n",
    "        },\n",
    "        {\n",
    "            'sample_id': 'GSM8392923',\n",
    "            'expression_id': 'GSM8392923_EL7_Lane1_2D_CROP',\n",
    "            'mapped_id': 'GSM8392924_EL7_Monoculture_2_mapped',\n",
    "            'description': '2D monoculture neuron CROP-seq rep 2',\n",
    "            'cell_type': 'Neurons',\n",
    "            'condition': 'Control',\n",
    "            'culture_type': '2D monoculture'\n",
    "        },\n",
    "        {\n",
    "            'sample_id': 'GSM8392925',\n",
    "            'expression_id': 'GSM8392925_EL8_Lane2_2D_CROP',\n",
    "            'mapped_id': 'GSM8392926_EL8_Monoculture_3_mapped',\n",
    "            'description': '2D monoculture neuron CROP-seq rep 3',\n",
    "            'cell_type': 'Neurons',\n",
    "            'condition': 'Control',\n",
    "            'culture_type': '2D monoculture'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    output_files = []\n",
    "    adatas = []\n",
    "    for sample_info in samples:\n",
    "        output_file = os.path.join(data_dir, f\"{sample_info['sample_id']}_harmonized.h5ad\")\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"File {output_file} already exists, loading...\")\n",
    "            try:\n",
    "                import scanpy as sc\n",
    "                adata = sc.read_h5ad(output_file)\n",
    "                adatas.append(adata)\n",
    "                output_files.append(output_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {output_file}: {e}\")\n",
    "        else:\n",
    "            try:\n",
    "                harmonized_data = process_sample(data_dir, sample_info)\n",
    "                adata = save_h5ad(harmonized_data, output_file)\n",
    "                if adata is not None:\n",
    "                    adatas.append(adata)\n",
    "                output_files.append(output_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sample {sample_info['sample_id']}: {e}\")\n",
    "                traceback.print_exc()\n",
    "    return output_files, adatas\n",
    "\n",
    "def validate_harmonized_data(output_files):\n",
    "    \"\"\"\n",
    "    Validate the harmonized data by printing summary information.\n",
    "    \"\"\"\n",
    "    import scanpy as sc\n",
    "    print(\"\\nValidating harmonized data...\")\n",
    "    for output_file in output_files:\n",
    "        if not os.path.exists(output_file):\n",
    "            print(f\"File {output_file} does not exist, skipping validation\")\n",
    "            continue\n",
    "        print(f\"Validating {output_file}...\")\n",
    "        try:\n",
    "            adata = sc.read_h5ad(output_file)\n",
    "            print(f\"  AnnData object with {adata.n_obs} cells and {adata.n_vars} genes\")\n",
    "            is_gene_symbols = all(adata.var_names.str.match(r'^[A-Za-z0-9\\-\\.]+$'))\n",
    "            print(f\"  Gene symbols used as var_names: {is_gene_symbols}\")\n",
    "            for col in ['organism', 'cell_type', 'crispr_type', 'cancer_type', 'condition', 'perturbation_name']:\n",
    "                if col in adata.obs.columns:\n",
    "                    unique_values = adata.obs[col].unique()\n",
    "                    print(f\"  {col}: {unique_values[:5]} {'...' if len(unique_values) > 5 else ''}\")\n",
    "                else:\n",
    "                    print(f\"  {col}: Not available\")\n",
    "            print(f\"  Validation complete for {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error validating {output_file}: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "def combine_and_qc(data_dir=None, combined_output='combined_filtered.h5ad'):\n",
    "    \"\"\"\n",
    "    Combine individual harmonized h5ad files, remove cells with NaN in 'guide',\n",
    "    apply QC filtering, update the condition column, and save the combined dataset.\n",
    "    \"\"\"\n",
    "    import scanpy as sc\n",
    "    import anndata as ad\n",
    "    if data_dir is None:\n",
    "        data_dir = os.getcwd()\n",
    "    \n",
    "    # 1. Get the list of existing harmonized files and associated AnnData objects.\n",
    "    output_files, adatas = harmonize_dataset(data_dir)\n",
    "    if not adatas:\n",
    "        adatas = []\n",
    "        for f in output_files:\n",
    "            try:\n",
    "                adata = sc.read_h5ad(f)\n",
    "                adatas.append(adata)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {f}: {e}\")\n",
    "    \n",
    "    # 2. For each AnnData:\n",
    "    #    - Ensure obs (cell) names are unique\n",
    "    #    - Prefix each obs_name with the sample ID\n",
    "    #    - Ensure var (gene) names are also unique\n",
    "    for adata in adatas:\n",
    "        # Make cell IDs unique in case of duplicates\n",
    "        adata.obs_names_make_unique()\n",
    "        \n",
    "        # Make gene names unique for each dataset\n",
    "        adata.var_names_make_unique()\n",
    "        \n",
    "        # Prefix obs_names with sample_id\n",
    "        sample_id = adata.obs['sample_id'].iloc[0]\n",
    "        adata.obs_names = [f\"{sample_id}_{cell_id}\" for cell_id in adata.obs_names]\n",
    "    \n",
    "    # 3. Concatenate AnnData objects\n",
    "    combined = ad.concat(adatas, join='outer', label='sample')\n",
    "    \n",
    "    # 4. Remove cells with NaN in 'guide'\n",
    "    combined = combined[combined.obs['guide'].notna(), :].copy()\n",
    "    print(f\"Combined AnnData after removing cells with NaN in guide: {combined.n_obs} cells\")\n",
    "    \n",
    "    # 5. Ensure final var names are unique across the combined dataset\n",
    "    combined.var_names_make_unique()\n",
    "    \n",
    "    # 6. Identify mitochondrial genes (assuming gene names start with 'MT-')\n",
    "    combined.var['mt'] = combined.var_names.str.startswith('MT-')\n",
    "    \n",
    "    # 7. Calculate QC metrics\n",
    "    sc.pp.calculate_qc_metrics(combined, qc_vars=['mt'], inplace=True)\n",
    "    \n",
    "    # 8. Apply QC filtering: remove cells with >20% mitochondrial counts and <200 genes\n",
    "    combined_filtered = combined[\n",
    "        (combined.obs['pct_counts_mt'] < 20) & (combined.obs['n_genes_by_counts'] > 200),\n",
    "        :\n",
    "    ].copy()\n",
    "    print(f\"After QC filtering: {combined_filtered.n_obs} cells\")\n",
    "    \n",
    "    # 9. Update the condition column\n",
    "    #    If perturbation_name is \"Non-targeting\", set condition to \"Control\", else \"Test\"\n",
    "    combined_filtered.obs['condition'] = combined_filtered.obs.apply(\n",
    "        lambda row: 'Control' if row['perturbation_name'] == 'Non-targeting' else 'Test',\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # 10. Save the combined, filtered AnnData object\n",
    "    combined_filtered.write(os.path.join(data_dir, combined_output))\n",
    "    print(f\"Combined filtered AnnData saved to {os.path.join(data_dir, combined_output)}\")\n",
    "    \n",
    "    return combined_filtered\n",
    "\n",
    "\n",
    "\n",
    "def run_all(data_dir=None):\n",
    "    \"\"\"\n",
    "    Run the entire harmonization, combination, and QC process.\n",
    "    \"\"\"\n",
    "    if data_dir is None:\n",
    "        data_dir = os.getcwd()\n",
    "    output_files, _ = harmonize_dataset(data_dir)\n",
    "    validate_harmonized_data(output_files)\n",
    "    combined_filtered = combine_and_qc(data_dir)\n",
    "    return combined_filtered\n",
    "\n",
    "# Run the entire process in Jupyter.\n",
    "combined_filtered = run_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b38bd-1bdb-4f0a-801c-082ce9d71f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
