{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from scipy.io import mmread\n",
    "from scipy.sparse import csr_matrix\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "# Dataset-specific metadata\n",
    "DATASET_METADATA = {\n",
    "    \"GSE263524\": {\n",
    "        \"title\": \"Inhibition of MBTPS1 reprograms cold into inflamed tumors and potentiates anti-PD-1 immunotherapy [scRNA-seq]\",\n",
    "        \"organism\": \"Mus musculus\",\n",
    "        \"download_url\": \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE263524&format=file\",\n",
    "        \"samples\": {\n",
    "            \"GSM8193978\": {\n",
    "                \"name\": \"NC\", \n",
    "                \"description\": \"MC38 tumor, WT\", \n",
    "                \"condition\": \"Control\", \n",
    "                \"perturbation_name\": \"Non-targeting\",\n",
    "                \"cell_type\": \"MC38 tumor cell\",\n",
    "                \"crispr_type\": \"CRISPR KO\",\n",
    "                \"cancer_type\": \"Colorectal cancer\"\n",
    "            },\n",
    "            \"GSM8193979\": {\n",
    "                \"name\": \"SHM\", \n",
    "                \"description\": \"MC38 tumor, SHM\", \n",
    "                \"condition\": \"Knockout\", \n",
    "                \"perturbation_name\": \"Mbtps1\",\n",
    "                \"cell_type\": \"MC38 tumor cell\",\n",
    "                \"crispr_type\": \"CRISPR KO\",\n",
    "                \"cancer_type\": \"Colorectal cancer\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def download_data(geo_accession, data_dir):\n",
    "    \"\"\"\n",
    "    Download and extract the dataset if not already present.\n",
    "    \n",
    "    Args:\n",
    "        geo_accession: GEO accession number.\n",
    "        data_dir: Directory to store the downloaded data.\n",
    "    \"\"\"\n",
    "    if geo_accession not in DATASET_METADATA:\n",
    "        raise ValueError(f\"Dataset {geo_accession} is not supported\")\n",
    "    \n",
    "    metadata = DATASET_METADATA[geo_accession]\n",
    "    download_url = metadata[\"download_url\"]\n",
    "    samples = metadata[\"samples\"]\n",
    "    \n",
    "    tar_path = os.path.join(data_dir, f\"{geo_accession}_RAW.tar\")\n",
    "    \n",
    "    if not os.path.exists(tar_path):\n",
    "        print(f\"Downloading {geo_accession} dataset...\")\n",
    "        urllib.request.urlretrieve(download_url, tar_path)\n",
    "        \n",
    "    # Check if all required files exist; if not, extract the tar file\n",
    "    all_files_exist = True\n",
    "    for sample_id in samples:\n",
    "        for suffix in [\"_barcodes.tsv.gz\", \"_features.tsv.gz\", \"_matrix.mtx.gz\"]:\n",
    "            file_path = os.path.join(data_dir, f\"{sample_id}_{samples[sample_id]['name']}{suffix}\")\n",
    "            if not os.path.exists(file_path):\n",
    "                all_files_exist = False\n",
    "                break\n",
    "    \n",
    "    if not all_files_exist:\n",
    "        print(\"Extracting tar file...\")\n",
    "        with tarfile.open(tar_path, 'r') as tar:\n",
    "            tar.extractall(path=data_dir)\n",
    "    \n",
    "    print(\"Data files are ready.\")\n",
    "\n",
    "def read_10x_data(data_dir, sample_id, sample_info):\n",
    "    \"\"\"\n",
    "    Read 10X Genomics formatted data files.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the data files.\n",
    "        sample_id: GEO sample ID (e.g., GSM8193978).\n",
    "        sample_info: Dictionary with sample metadata.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the loaded data.\n",
    "    \"\"\"\n",
    "    sample_name = sample_info['name']\n",
    "    \n",
    "    # File paths\n",
    "    barcodes_path = os.path.join(data_dir, f\"{sample_id}_{sample_name}_barcodes.tsv.gz\")\n",
    "    features_path = os.path.join(data_dir, f\"{sample_id}_{sample_name}_features.tsv.gz\")\n",
    "    matrix_path = os.path.join(data_dir, f\"{sample_id}_{sample_name}_matrix.mtx.gz\")\n",
    "    \n",
    "    # Read barcodes\n",
    "    with gzip.open(barcodes_path, 'rt') as f:\n",
    "        barcodes = pd.read_csv(f, sep='\\t', header=None, names=['barcode'])\n",
    "    \n",
    "    # Read features\n",
    "    with gzip.open(features_path, 'rt') as f:\n",
    "        features = pd.read_csv(f, sep='\\t', header=None, names=['gene_id', 'gene_symbol', 'feature_type'])\n",
    "    \n",
    "    # Read matrix (this can be memory-intensive)\n",
    "    print(f\"Reading matrix for {sample_id}...\")\n",
    "    with gzip.open(matrix_path, 'rb') as f:\n",
    "        matrix = mmread(f).tocsr()\n",
    "    \n",
    "    print(f\"Matrix shape: {matrix.shape}\")\n",
    "    \n",
    "    return {\n",
    "        'barcodes': barcodes,\n",
    "        'features': features,\n",
    "        'matrix': matrix,\n",
    "        'sample_id': sample_id,\n",
    "        'sample_info': sample_info\n",
    "    }\n",
    "\n",
    "def make_gene_symbols_unique(gene_symbols):\n",
    "    \"\"\"\n",
    "    Make gene symbols unique by appending a suffix to duplicates.\n",
    "    \n",
    "    Args:\n",
    "        gene_symbols: Array of gene symbols.\n",
    "        \n",
    "    Returns:\n",
    "        Array of unique gene symbols.\n",
    "    \"\"\"\n",
    "    if len(gene_symbols) == len(set(gene_symbols)):\n",
    "        return gene_symbols\n",
    "    \n",
    "    print(f\"Found {len(gene_symbols) - len(set(gene_symbols))} duplicate gene symbols. Making them unique...\")\n",
    "    \n",
    "    gene_counts = {}\n",
    "    unique_gene_symbols = []\n",
    "    \n",
    "    for symbol in gene_symbols:\n",
    "        if symbol in gene_counts:\n",
    "            gene_counts[symbol] += 1\n",
    "            unique_gene_symbols.append(f\"{symbol}_{gene_counts[symbol]}\")\n",
    "        else:\n",
    "            gene_counts[symbol] = 0\n",
    "            unique_gene_symbols.append(symbol)\n",
    "    \n",
    "    return np.array(unique_gene_symbols)\n",
    "\n",
    "def create_anndata(data, geo_accession):\n",
    "    \"\"\"\n",
    "    Create an AnnData object from the data.\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary containing the loaded data.\n",
    "        geo_accession: GEO accession number.\n",
    "        \n",
    "    Returns:\n",
    "        AnnData object with harmonized metadata.\n",
    "    \"\"\"\n",
    "    matrix = data['matrix']\n",
    "    barcodes = data['barcodes']['barcode'].values\n",
    "    features = data['features']\n",
    "    sample_info = data['sample_info']\n",
    "    \n",
    "    # The matrix from 10X is genes x cells, but AnnData expects cells x genes; transpose it.\n",
    "    matrix = matrix.transpose()\n",
    "    \n",
    "    # Create observation (cell) metadata\n",
    "    obs = pd.DataFrame(index=barcodes)\n",
    "    obs['organism'] = DATASET_METADATA[geo_accession][\"organism\"]\n",
    "    obs['cell_type'] = sample_info['cell_type']\n",
    "    obs['crispr_type'] = sample_info['crispr_type']\n",
    "    obs['cancer_type'] = sample_info['cancer_type']\n",
    "    obs['condition'] = sample_info['condition']\n",
    "    obs['perturbation_name'] = sample_info['perturbation_name']\n",
    "    obs['sample_id'] = data['sample_id']\n",
    "    obs['description'] = sample_info['description']\n",
    "    \n",
    "    # Make gene symbols unique\n",
    "    gene_symbols = make_gene_symbols_unique(features['gene_symbol'].values)\n",
    "    \n",
    "    # Create variable (gene) metadata\n",
    "    var = pd.DataFrame(index=gene_symbols)\n",
    "    var['gene_id'] = features['gene_id'].values\n",
    "    var['feature_type'] = features['feature_type'].values\n",
    "    var['original_gene_symbol'] = features['gene_symbol'].values\n",
    "    \n",
    "    # Create AnnData object\n",
    "    adata = ad.AnnData(\n",
    "        X=matrix,\n",
    "        obs=obs,\n",
    "        var=var,\n",
    "        uns={\n",
    "            'sample_id': data['sample_id'],\n",
    "            'description': sample_info['description'],\n",
    "            'geo_accession': geo_accession,\n",
    "            'title': DATASET_METADATA[geo_accession][\"title\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def process_sample(geo_accession, data_dir, sample_id, sample_info):\n",
    "    \"\"\"\n",
    "    Process a single sample.\n",
    "    \n",
    "    Args:\n",
    "        geo_accession: GEO accession number.\n",
    "        data_dir: Directory containing the data files.\n",
    "        sample_id: GEO sample ID (e.g., GSM8193978).\n",
    "        sample_info: Dictionary with sample metadata.\n",
    "        \n",
    "    Returns:\n",
    "        Path to the output h5ad file.\n",
    "    \"\"\"\n",
    "    print(f\"Processing sample {sample_id} ({sample_info['description']})...\")\n",
    "    \n",
    "    data = read_10x_data(data_dir, sample_id, sample_info)\n",
    "    adata = create_anndata(data, geo_accession)\n",
    "    \n",
    "    output_dir = os.path.join(data_dir, \"processed\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    output_path = os.path.join(output_dir, f\"{sample_id}.h5ad\")\n",
    "    adata.write(output_path)\n",
    "    \n",
    "    print(f\"Created h5ad file: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def run_processing(geo_accession='GSE263524', data_dir=os.getcwd()):\n",
    "    \"\"\"\n",
    "    Run the processing of the dataset in a Jupyter Notebook environment.\n",
    "    \n",
    "    Args:\n",
    "        geo_accession: GEO accession number (default: GSE263524).\n",
    "        data_dir: Directory to store the data (default: current directory).\n",
    "    \"\"\"\n",
    "    if geo_accession not in DATASET_METADATA:\n",
    "        print(f\"Error: Dataset {geo_accession} is not supported\")\n",
    "        print(\"Supported datasets:\")\n",
    "        for accession in DATASET_METADATA:\n",
    "            print(f\"  - {accession}: {DATASET_METADATA[accession]['title']}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing dataset: {geo_accession}\")\n",
    "    print(f\"Using data directory: {data_dir}\")\n",
    "    \n",
    "    # Create a directory for the dataset if it doesn't exist\n",
    "    data_dir = os.path.join(data_dir, geo_accession)\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    download_data(geo_accession, data_dir)\n",
    "    \n",
    "    output_files = []\n",
    "    for sample_id, sample_info in DATASET_METADATA[geo_accession][\"samples\"].items():\n",
    "        output_file = process_sample(geo_accession, data_dir, sample_id, sample_info)\n",
    "        output_files.append(output_file)\n",
    "    \n",
    "    metadata_path = os.path.join(data_dir, \"processed\", f\"{geo_accession}_metadata.json\")\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(DATASET_METADATA[geo_accession], f, indent=2)\n",
    "    \n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(\"Output files:\")\n",
    "    for file_path in output_files:\n",
    "        print(f\"  - {file_path}\")\n",
    "    print(f\"  - {metadata_path}\")\n",
    "\n",
    "# Call the run_processing function directly (you can change parameters if needed)\n",
    "run_processing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8e670-7c91-4cb5-8aac-00102b8176b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "\n",
    "# File paths for the two h5ad files\n",
    "file1 = '/content/GSE263524/processed/GSM8193978.h5ad'\n",
    "file2 = '/content/GSE263524/processed/GSM8193979.h5ad'\n",
    "\n",
    "# Load the datasets\n",
    "adata1 = ad.read_h5ad(file1)\n",
    "adata2 = ad.read_h5ad(file2)\n",
    "\n",
    "def compute_total_counts(adata):\n",
    "    \"\"\"Compute the total counts per cell.\"\"\"\n",
    "    if hasattr(adata.X, 'toarray'):\n",
    "        return np.array(adata.X.sum(axis=1)).flatten()\n",
    "    else:\n",
    "        return adata.X.sum(axis=1)\n",
    "\n",
    "def compute_mito_percentage(adata):\n",
    "    \"\"\"\n",
    "    Compute the percentage of counts from mitochondrial genes.\n",
    "    Assumes mitochondrial genes are annotated in the 'original_gene_symbol'\n",
    "    and start with \"MT-\" (case-insensitive).\n",
    "    \"\"\"\n",
    "    mito_genes = adata.var['original_gene_symbol'].str.upper().str.startswith('MT-')\n",
    "    if hasattr(adata.X, 'toarray'):\n",
    "        mito_counts = np.array(adata.X[:, mito_genes].sum(axis=1)).flatten()\n",
    "        total_counts = np.array(adata.X.sum(axis=1)).flatten()\n",
    "    else:\n",
    "        mito_counts = np.array(adata.X[:, mito_genes].sum(axis=1)).flatten()\n",
    "        total_counts = np.array(adata.X.sum(axis=1)).flatten()\n",
    "    mito_pct = mito_counts / total_counts * 100\n",
    "    return mito_pct\n",
    "\n",
    "def compute_n_genes(adata):\n",
    "    \"\"\"Compute the number of genes detected per cell (nonzero counts).\"\"\"\n",
    "    if hasattr(adata.X, 'toarray'):\n",
    "        n_genes = np.array((adata.X.toarray() > 0).sum(axis=1)).flatten()\n",
    "    else:\n",
    "        n_genes = np.array((adata.X > 0).sum(axis=1)).flatten()\n",
    "    return n_genes\n",
    "\n",
    "# Add QC metrics to adata1\n",
    "adata1.obs['total_counts'] = compute_total_counts(adata1)\n",
    "adata1.obs['mito_pct'] = compute_mito_percentage(adata1)\n",
    "adata1.obs['n_genes'] = compute_n_genes(adata1)\n",
    "\n",
    "# Add QC metrics to adata2\n",
    "adata2.obs['total_counts'] = compute_total_counts(adata2)\n",
    "adata2.obs['mito_pct'] = compute_mito_percentage(adata2)\n",
    "adata2.obs['n_genes'] = compute_n_genes(adata2)\n",
    "\n",
    "# Define QC thresholds\n",
    "min_total_counts = 500\n",
    "max_mito_pct = 10\n",
    "max_n_genes = 7500\n",
    "\n",
    "# Apply filtering for adata1\n",
    "initial_cells_1 = adata1.n_obs\n",
    "adata1_qc = adata1[(adata1.obs['total_counts'] > min_total_counts) &\n",
    "                   (adata1.obs['mito_pct'] < max_mito_pct) &\n",
    "                   (adata1.obs['n_genes'] < max_n_genes)].copy()\n",
    "filtered_cells_1 = adata1_qc.n_obs\n",
    "\n",
    "# Apply filtering for adata2\n",
    "initial_cells_2 = adata2.n_obs\n",
    "adata2_qc = adata2[(adata2.obs['total_counts'] > min_total_counts) &\n",
    "                   (adata2.obs['mito_pct'] < max_mito_pct) &\n",
    "                   (adata2.obs['n_genes'] < max_n_genes)].copy()\n",
    "filtered_cells_2 = adata2_qc.n_obs\n",
    "\n",
    "# Print cell counts before and after QC for each sample\n",
    "print(\"GSM8193978:\")\n",
    "print(\"  Original cell count:\", initial_cells_1)\n",
    "print(\"  After QC cell count:\", filtered_cells_1)\n",
    "\n",
    "print(\"\\nGSM8193979:\")\n",
    "print(\"  Original cell count:\", initial_cells_2)\n",
    "print(\"  After QC cell count:\", filtered_cells_2)\n",
    "\n",
    "\n",
    "# Combine the QC filtered datasets\n",
    "combined_adata = ad.concat(\n",
    "    [adata1_qc, adata2_qc],\n",
    "    join='outer',          # include all features from both datasets\n",
    "    merge='unique',        # resolves duplicate observations if needed\n",
    "    label='sample',        # adds a column indicating sample of origin\n",
    "    keys=['GSM8193978', 'GSM8193979']\n",
    ")\n",
    "\n",
    "\n",
    "combined_adata.write_h5ad('/content/GSE263524.h5ad', compression=\"gzip\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b38bd-1bdb-4f0a-801c-082ce9d71f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
