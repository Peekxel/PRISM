{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import anndata as ad\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import re\n",
    "\n",
    "def download_file(url, output_path):\n",
    "    \"\"\"Download a file from a URL to a specified path.\"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        print(f\"Downloading {url} to {output_path}\")\n",
    "        urllib.request.urlretrieve(url, output_path)\n",
    "        print(f\"Downloaded {output_path}\")\n",
    "    else:\n",
    "        print(f\"File {output_path} already exists, skipping download\")\n",
    "\n",
    "def download_gse266225_files(data_dir):\n",
    "    \"\"\"\n",
    "    Download GSE266225 files from NCBI's FTP, \n",
    "    using the correct file names from the GEO page.\n",
    "    \"\"\"\n",
    "    base_url = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE266nnn/GSE266225/suppl/\"\n",
    "    # NOTE: Updated 2wPC and 8wPC Citeseq file names \n",
    "    #       to remove \"_filtered_\" where GEO does not have it.\n",
    "    files = [\n",
    "        # Multiome data\n",
    "        \"GSE266225_liver_naive_JVG28_feature_bc_matrix.h5\",\n",
    "        \"GSE266225_liver_8wPC_JVG29_feature_bc_matrix.h5\",\n",
    "        # CITE-seq data\n",
    "        \"GSE266225_MF_naive_MMU1_filtered_feature_bc_matrix.h5\",\n",
    "        \"GSE266225_MF_infected_MMU2_feature_bc_matrix.h5\",\n",
    "        \"GSE266225_MF_2wPC_MMU3_feature_bc_matrix.h5\",  # removed '_filtered_'\n",
    "        \"GSE266225_MF_8wPC_MMU4_feature_bc_matrix.h5\",  # removed '_filtered_'\n",
    "        # Metadata (may or may not exist)\n",
    "        \"GSE266225_Metadata_Citeseq_Macrophages.csv.gz\",\n",
    "        \"GSE266225_adt_feature_reference.csv.gz\"\n",
    "    ]\n",
    "    \n",
    "    # Attempt download\n",
    "    for file in files:\n",
    "        url = base_url + file\n",
    "        output_path = os.path.join(data_dir, file)\n",
    "        download_file(url, output_path)\n",
    "        \n",
    "        # Decompress gzipped files if needed\n",
    "        if output_path.endswith('.gz'):\n",
    "            uncompressed_path = output_path[:-3]\n",
    "            if not os.path.exists(uncompressed_path):\n",
    "                print(f\"Decompressing {output_path}\")\n",
    "                with gzip.open(output_path, 'rb') as f_in:\n",
    "                    with open(uncompressed_path, 'wb') as f_out:\n",
    "                        f_out.write(f_in.read())\n",
    "                print(f\"Decompressed {output_path} to {uncompressed_path}\")\n",
    "\n",
    "def read_h5_to_anndata(file_path):\n",
    "    \"\"\"\n",
    "    Read a 10x h5 file and convert it to an AnnData object (gene expression or protein, etc.)\n",
    "    \"\"\"\n",
    "    print(f\"Reading {file_path}\")\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        # Barcodes\n",
    "        barcodes = f['matrix/barcodes'][:]\n",
    "        barcodes = [b.decode('utf-8') for b in barcodes]\n",
    "        \n",
    "        # Features\n",
    "        feature_ids = f['matrix/features/id'][:]\n",
    "        feature_ids = [f0.decode('utf-8') for f0 in feature_ids]\n",
    "        \n",
    "        feature_names = f['matrix/features/name'][:]\n",
    "        feature_names = [f0.decode('utf-8') for f0 in feature_names]\n",
    "        \n",
    "        # Feature types\n",
    "        if 'feature_type' in f['matrix/features']:\n",
    "            feature_types = f['matrix/features/feature_type'][:]\n",
    "            feature_types = [f0.decode('utf-8') for f0 in feature_types]\n",
    "        else:\n",
    "            feature_types = ['Gene Expression'] * len(feature_ids)\n",
    "        \n",
    "        # Matrix shape\n",
    "        shape = f['matrix/shape'][:]\n",
    "        \n",
    "        # Sparse matrix data\n",
    "        data = f['matrix/data'][:]\n",
    "        indices = f['matrix/indices'][:]\n",
    "        indptr = f['matrix/indptr'][:]\n",
    "        \n",
    "        # Create csc_matrix, then transpose\n",
    "        mat = sparse.csc_matrix((data, indices, indptr), shape=shape).transpose()\n",
    "        \n",
    "        # var DataFrame\n",
    "        var = pd.DataFrame(index=feature_names)\n",
    "        var[\"gene_ids\"] = feature_ids\n",
    "        var[\"feature_types\"] = feature_types\n",
    "        \n",
    "        # obs DataFrame\n",
    "        obs = pd.DataFrame(index=barcodes)\n",
    "        \n",
    "        # Create AnnData\n",
    "        adata = ad.AnnData(X=mat, obs=obs, var=var)\n",
    "        \n",
    "        return adata\n",
    "\n",
    "def clean_protein_names_final(adata):\n",
    "    \"\"\"\n",
    "    Simplify protein names by keeping only one instance of each base protein.\n",
    "    This approach keeps only the first occurrence of each protein and removes duplicates.\n",
    "    \n",
    "    Parameters:\n",
    "    adata (AnnData): AnnData object with protein features\n",
    "    \n",
    "    Returns:\n",
    "    AnnData: New AnnData object with unique protein names\n",
    "    \"\"\"\n",
    "    import re\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Extract base names (remove _# or -# suffixes)\n",
    "    var_names = adata.var_names.tolist()\n",
    "    base_names = [re.sub(r'[_-][0-9]+$', '', name) for name in var_names]\n",
    "    \n",
    "    # Create mapping to find first occurrence of each base name\n",
    "    unique_indices = {}\n",
    "    for i, base in enumerate(base_names):\n",
    "        if base not in unique_indices:\n",
    "            unique_indices[base] = i\n",
    "    \n",
    "    # Get list of indices to keep (first occurrence of each base name)\n",
    "    indices_to_keep = sorted(list(unique_indices.values()))\n",
    "    \n",
    "    # Create new filtered AnnData with only one instance of each protein\n",
    "    filtered_adata = adata[:, indices_to_keep].copy()\n",
    "    \n",
    "    # Set var_names to the clean base names\n",
    "    cleaned_names = [base_names[i] for i in indices_to_keep]\n",
    "    filtered_adata.var_names = pd.Index(cleaned_names)\n",
    "    \n",
    "    # Make sure there are no duplicates in final names\n",
    "    if len(set(filtered_adata.var_names)) < len(filtered_adata.var_names):\n",
    "        filtered_adata.var_names_make_unique()\n",
    "    \n",
    "    print(f\"Reduced from {adata.shape[1]} to {filtered_adata.shape[1]} protein features\")\n",
    "    return filtered_adata\n",
    "\n",
    "# Alternate simpler approach - just pick the first instance of each protein\n",
    "def simplify_protein_names(adata):\n",
    "    \"\"\"\n",
    "    Simplify protein names by keeping only one instance of each base protein.\n",
    "    This approach keeps only the first occurrence and drops duplicate proteins.\n",
    "    WARNING: This will remove data if there are true duplicates.\n",
    "    \n",
    "    Parameters:\n",
    "    adata (AnnData): AnnData object with protein features\n",
    "    \n",
    "    Returns:\n",
    "    AnnData: A new AnnData object with simplified var_names\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Extract base names\n",
    "    base_names = [re.sub(r'[_-][0-9]+$', '', name) for name in adata.var_names]\n",
    "    \n",
    "    # Find unique base names and their first occurrence\n",
    "    unique_bases = {}\n",
    "    for i, base_name in enumerate(base_names):\n",
    "        if base_name not in unique_bases:\n",
    "            unique_bases[base_name] = i\n",
    "    \n",
    "    # Filter adata to keep only the first occurrence of each protein\n",
    "    indices_to_keep = list(unique_bases.values())\n",
    "    \n",
    "    # Create new filtered AnnData\n",
    "    filtered_adata = adata[:, indices_to_keep].copy()\n",
    "    \n",
    "    # Update var_names to base names\n",
    "    base_names_list = [base_names[i] for i in indices_to_keep]\n",
    "    filtered_adata.var_names = pd.Index(base_names_list)\n",
    "    \n",
    "    return filtered_adata\n",
    "\n",
    "def process_multiome_data(data_dir):\n",
    "    \"\"\"\n",
    "    Process multiome data from GSE266225 (two .h5 files: naive + 8wPC).\n",
    "    Returns concatenated AnnData with only gene expression.\n",
    "    \"\"\"\n",
    "    file_paths = {\n",
    "        \"control\": os.path.join(data_dir, \"GSE266225_liver_naive_JVG28_feature_bc_matrix.h5\"),\n",
    "        \"8we treated\": os.path.join(data_dir, \"GSE266225_liver_8wPC_JVG29_feature_bc_matrix.h5\"),\n",
    "    }\n",
    "    \n",
    "    gene_adatas = []\n",
    "    for condition, file_path in file_paths.items():\n",
    "        print(f\"Processing multiome condition: {condition}\")\n",
    "        adata = read_h5_to_anndata(file_path)\n",
    "        \n",
    "        # Add condition\n",
    "        adata.obs[\"condition\"] = {\n",
    "            \"control\": \"Control\",\n",
    "            \"8we treated\": \"8 weeks post curing\"\n",
    "        }.get(condition, condition)\n",
    "        \n",
    "        # Add consistent metadata\n",
    "        adata.obs[\"organism\"] = \"Mus musculus\"\n",
    "        adata.obs[\"cell_type\"] = \"Liver cells\"\n",
    "        adata.obs[\"crispr_type\"] = \"None\"\n",
    "        adata.obs[\"cancer_type\"] = \"Non-Cancer\"\n",
    "        adata.obs[\"perturbation_name\"] = \"None\"\n",
    "        \n",
    "        # Keep only gene expression features\n",
    "        gene_mask = adata.var[\"feature_types\"] == \"Gene Expression\"\n",
    "        gene_adata = adata[:, gene_mask].copy()\n",
    "        gene_adata.var_names_make_unique()\n",
    "        \n",
    "        # Mark batch\n",
    "        gene_adata.obs[\"batch\"] = condition\n",
    "        \n",
    "        gene_adatas.append(gene_adata)\n",
    "    \n",
    "    # Fix repeated var names across multiple sets\n",
    "    all_gene_names = []\n",
    "    for adata in gene_adatas:\n",
    "        all_gene_names.extend(adata.var_names)\n",
    "    dup_series = pd.Series(all_gene_names).value_counts()\n",
    "    duplicates = dup_series[dup_series > 1].index.tolist()\n",
    "    \n",
    "    for i, adata in enumerate(gene_adatas):\n",
    "        for dup in duplicates:\n",
    "            if dup in adata.var_names:\n",
    "                idx = adata.var_names.get_loc(dup)\n",
    "                adata.var_names.values[idx] = f\"{dup}_{i}\"\n",
    "    \n",
    "    # Concatenate\n",
    "    print(\"Concatenating multiome gene data...\")\n",
    "    multi_adata = ad.concat(gene_adatas, join='outer')\n",
    "    multi_adata.obs_names_make_unique()\n",
    "    multi_adata.var_names_make_unique()\n",
    "    \n",
    "    return multi_adata\n",
    "\n",
    "def process_citeseq_data(data_dir):\n",
    "    \"\"\"\n",
    "    Process CITE-seq data from GSE266225 (four .h5 files: naive, infected, 2wPC, 8wPC).\n",
    "    Returns (gene_adata_combined, protein_adata_combined).\n",
    "    \"\"\"\n",
    "    file_paths = {\n",
    "        \"naive\": os.path.join(data_dir, \"GSE266225_MF_naive_MMU1_filtered_feature_bc_matrix.h5\"),\n",
    "        \"infected\": os.path.join(data_dir, \"GSE266225_MF_infected_MMU2_feature_bc_matrix.h5\"),\n",
    "        \"2wPC\": os.path.join(data_dir, \"GSE266225_MF_2wPC_MMU3_feature_bc_matrix.h5\"),\n",
    "        \"8wPC\": os.path.join(data_dir, \"GSE266225_MF_8wPC_MMU4_feature_bc_matrix.h5\"),\n",
    "    }\n",
    "    \n",
    "    # Attempt to load macrophage metadata if it exists\n",
    "    meta_csv = os.path.join(data_dir, \"GSE266225_Metadata_Citeseq_Macrophages.csv\")\n",
    "    metadata = None\n",
    "    if os.path.exists(meta_csv):\n",
    "        print(f\"Loading macrophage metadata from {meta_csv}\")\n",
    "        metadata = pd.read_csv(meta_csv, index_col=0)\n",
    "    \n",
    "    gene_list = []\n",
    "    prot_list = []\n",
    "    \n",
    "    for condition, file_path in file_paths.items():\n",
    "        print(f\"Processing Citeseq condition: {condition}\")\n",
    "        adata = read_h5_to_anndata(file_path)\n",
    "        \n",
    "        # Condition labeling\n",
    "        adata.obs[\"condition\"] = {\n",
    "            \"naive\": \"Control\",\n",
    "            \"infected\": \"Infected\",\n",
    "            \"2wPC\": \"2 weeks post curing\",\n",
    "            \"8wPC\": \"8 weeks post curing\",\n",
    "        }.get(condition, condition)\n",
    "        \n",
    "        # More metadata\n",
    "        adata.obs[\"organism\"] = \"Mus musculus\"\n",
    "        adata.obs[\"cell_type\"] = \"Macrophages\"\n",
    "        adata.obs[\"crispr_type\"] = \"None\"\n",
    "        adata.obs[\"cancer_type\"] = \"Non-Cancer\"\n",
    "        adata.obs[\"perturbation_name\"] = \"None\"\n",
    "        adata.obs[\"batch\"] = condition\n",
    "        \n",
    "        # Split gene vs protein\n",
    "        gene_mask = adata.var[\"feature_types\"] == \"Gene Expression\"\n",
    "        prot_mask = adata.var[\"feature_types\"] == \"Antibody Capture\"\n",
    "        \n",
    "        gene_adata = adata[:, gene_mask].copy()\n",
    "        gene_adata.var_names_make_unique()\n",
    "        \n",
    "        prot_adata = adata[:, prot_mask].copy() if prot_mask.sum() > 0 else None\n",
    "        if prot_adata is not None:\n",
    "            prot_adata.var_names_make_unique()\n",
    "        \n",
    "        # Add extra metadata if available\n",
    "        if metadata is not None:\n",
    "            common_barcodes = set(gene_adata.obs_names).intersection(metadata.index)\n",
    "            if common_barcodes:\n",
    "                print(f\"  Found {len(common_barcodes)} cells in metadata for {condition}\")\n",
    "                for col in metadata.columns:\n",
    "                    # Gene:\n",
    "                    gene_adata.obs[col] = pd.Series(index=gene_adata.obs_names, dtype=metadata[col].dtype)\n",
    "                    for bc in common_barcodes:\n",
    "                        gene_adata.obs.loc[bc, col] = metadata.loc[bc, col]\n",
    "                # Protein:\n",
    "                if prot_adata is not None:\n",
    "                    for col in metadata.columns:\n",
    "                        prot_adata.obs[col] = pd.Series(index=prot_adata.obs_names, dtype=metadata[col].dtype)\n",
    "                        for bc in common_barcodes:\n",
    "                            if bc in prot_adata.obs_names:\n",
    "                                prot_adata.obs.loc[bc, col] = metadata.loc[bc, col]\n",
    "        \n",
    "        gene_list.append(gene_adata)\n",
    "        if prot_adata is not None:\n",
    "            prot_list.append(prot_adata)\n",
    "    \n",
    "    # Resolve gene name collisions\n",
    "    all_gene_names = []\n",
    "    for g in gene_list:\n",
    "        all_gene_names.extend(g.var_names)\n",
    "    dup_series = pd.Series(all_gene_names).value_counts()\n",
    "    duplicates = dup_series[dup_series > 1].index.tolist()\n",
    "    \n",
    "    for i, g in enumerate(gene_list):\n",
    "        for dup in duplicates:\n",
    "            if dup in g.var_names:\n",
    "                idx = g.var_names.get_loc(dup)\n",
    "                g.var_names.values[idx] = f\"{dup}_{i}\"\n",
    "    \n",
    "    print(\"Concatenating CITE-seq gene data...\")\n",
    "    gene_adata_combined = ad.concat(gene_list, join='outer')\n",
    "    gene_adata_combined.obs_names_make_unique()\n",
    "    gene_adata_combined.var_names_make_unique()\n",
    "    \n",
    "    # Resolve protein name collisions if any\n",
    "    if len(prot_list) > 0:\n",
    "        all_prot_names = []\n",
    "        for p in prot_list:\n",
    "            all_prot_names.extend(p.var_names)\n",
    "        dup_series_p = pd.Series(all_prot_names).value_counts()\n",
    "        duplicates_p = dup_series_p[dup_series_p > 1].index.tolist()\n",
    "        \n",
    "        for i, p in enumerate(prot_list):\n",
    "            for dup in duplicates_p:\n",
    "                if dup in p.var_names:\n",
    "                    idx = p.var_names.get_loc(dup)\n",
    "                    p.var_names.values[idx] = f\"{dup}_{i}\"\n",
    "        \n",
    "        print(\"Concatenating CITE-seq protein data...\")\n",
    "        protein_adata_combined = ad.concat(prot_list, join='outer')\n",
    "        protein_adata_combined.obs_names_make_unique()\n",
    "        protein_adata_combined.var_names_make_unique()\n",
    "        \n",
    "        # Clean protein names after concatenation\n",
    "        print(\"Cleaning protein names (removing suffixes)...\")\n",
    "        protein_adata_combined = clean_protein_names(protein_adata_combined)\n",
    "    else:\n",
    "        protein_adata_combined = None\n",
    "    \n",
    "    return gene_adata_combined, protein_adata_combined\n",
    "\n",
    "def get_paired_data(gene_adata, protein_adata):\n",
    "    \"\"\"\n",
    "    Given gene and protein AnnData from the same cells, find overlap \n",
    "    and return matched gene/protein objects.\n",
    "    \"\"\"\n",
    "    if protein_adata is None:\n",
    "        return gene_adata, None\n",
    "    \n",
    "    # Overlap in barcodes\n",
    "    common_barcodes = list(set(gene_adata.obs_names).intersection(protein_adata.obs_names))\n",
    "    print(f\"Found {len(common_barcodes)} overlapping barcodes in gene & protein data.\")\n",
    "    if len(common_barcodes) == 0:\n",
    "        return gene_adata, protein_adata\n",
    "    \n",
    "    # Subset both\n",
    "    gene_paired = gene_adata[common_barcodes].copy()\n",
    "    prot_paired = protein_adata[common_barcodes].copy()\n",
    "    \n",
    "    # Sync metadata columns\n",
    "    for col in gene_paired.obs.columns:\n",
    "        if col in prot_paired.obs.columns:\n",
    "            prot_paired.obs[col] = gene_paired.obs[col]\n",
    "    \n",
    "    return gene_paired, prot_paired\n",
    "\n",
    "def run_pipeline(data_dir: str):\n",
    "    \"\"\"\n",
    "    Main pipeline in one function.\n",
    "    \"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    # Download files (make sure the file names match GEO)\n",
    "    download_gse266225_files(data_dir)\n",
    "    \n",
    "    # Process multiome\n",
    "    print(\"\\n--- Processing Multiome data ---\")\n",
    "    multiome_gene = process_multiome_data(data_dir)\n",
    "    \n",
    "    # Process Citeseq\n",
    "    print(\"\\n--- Processing CITE-seq data ---\")\n",
    "    c_gene, c_protein = process_citeseq_data(data_dir)\n",
    "    \n",
    "    # Attempt to pair gene & protein\n",
    "    print(\"\\n--- Getting paired gene-protein from CITE-seq ---\")\n",
    "    c_gene_paired, c_protein_paired = get_paired_data(c_gene, c_protein)\n",
    "    \n",
    "    # Save out\n",
    "    out_dir = os.path.join(data_dir, \"harmonized\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    # Multiome gene\n",
    "    multi_fn = os.path.join(out_dir, \"GSE266225_multiome_gene_expression.h5ad\")\n",
    "    print(f\"\\nSaving multiome gene to {multi_fn}\")\n",
    "    multiome_gene.write_h5ad(multi_fn, compression=\"gzip\")\n",
    "    \n",
    "    # Citeseq gene\n",
    "    citeseq_gene_fn = os.path.join(out_dir, \"GSE266225_citeseq_gene_expression.h5ad\")\n",
    "    print(f\"Saving Citeseq gene to {citeseq_gene_fn}\")\n",
    "    c_gene_paired.write_h5ad(citeseq_gene_fn, compression=\"gzip\")\n",
    "    \n",
    "    # Citeseq protein - Use the improved function to clean protein names\n",
    "    if c_protein_paired is not None:\n",
    "        print(\"\\n--- Cleaning protein names (removing duplicates) ---\")\n",
    "        # Use the new function that keeps only one instance of each protein\n",
    "        c_protein_unique = clean_protein_names_final(c_protein_paired)\n",
    "        \n",
    "        # Print the final list of protein names\n",
    "        print(\"Final protein features:\")\n",
    "        print(\", \".join([f\"'{name}'\" for name in c_protein_unique.var_names[:20]]) + \n",
    "              (\", ...\" if len(c_protein_unique.var_names) > 20 else \"\"))\n",
    "        \n",
    "        citeseq_prot_fn = os.path.join(out_dir, \"GSE266225_citeseq_protein_expression.h5ad\")\n",
    "        print(f\"Saving Citeseq protein to {citeseq_prot_fn}\")\n",
    "        c_protein_unique.write_h5ad(citeseq_prot_fn, compression=\"gzip\")\n",
    "    \n",
    "    print(\"\\n--- Pipeline done! ---\")\n",
    "    print(\"Multiome gene shape:\", multiome_gene.shape)\n",
    "    print(\"Citeseq gene shape:\", c_gene_paired.shape)\n",
    "    if c_protein_paired is not None:\n",
    "        print(\"Original protein shape:\", c_protein_paired.shape)\n",
    "        print(\"Cleaned protein shape:\", c_protein_unique.shape)\n",
    "\n",
    "# --------------------------\n",
    "# In a Jupyter notebook, just do:\n",
    "data_directory = \"./GSE266225\"  # or another path\n",
    "run_pipeline(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
