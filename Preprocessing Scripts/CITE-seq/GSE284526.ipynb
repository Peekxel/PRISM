{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import anndata as ad\n",
    "\n",
    "# Base URL for downloading files\n",
    "BASE_URL = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE284nnn/GSE284526/suppl/\"\n",
    "\n",
    "# Files to download\n",
    "FILES = [\n",
    "    \"GSE284526_LBA001_matrix.mtx.gz\",\n",
    "    \"GSE284526_LBA001_features.tsv.gz\",\n",
    "    \"GSE284526_LBA001_barcodes.tsv.gz\",\n",
    "    \"GSE284526_LBA001_feature_reference.csv.gz\",\n",
    "    \"GSE284526_LBA002_matrix.mtx.gz\",\n",
    "    \"GSE284526_LBA002_features.tsv.gz\",\n",
    "    \"GSE284526_LBA002_barcodes.tsv.gz\",\n",
    "    \"GSE284526_LBA002_feature_reference.csv.gz\",\n",
    "    \"GSE284526_LBA003_matrix.mtx.gz\",\n",
    "    \"GSE284526_LBA003_features.tsv.gz\",\n",
    "    \"GSE284526_LBA003_barcodes.tsv.gz\",\n",
    "    \"GSE284526_LBA003_feature_reference.csv.gz\",\n",
    "    \"GSE284526_LBA004_matrix.mtx.gz\",\n",
    "    \"GSE284526_LBA004_features.tsv.gz\",\n",
    "    \"GSE284526_LBA004_barcodes.tsv.gz\",\n",
    "    \"GSE284526_LBA004_feature_reference.csv.gz\"\n",
    "]\n",
    "\n",
    "\n",
    "def download_files(data_dir):\n",
    "    \"\"\"\n",
    "    Download required files if they don't exist.\n",
    "    Raises an error if download fails.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the data directory\n",
    "    \"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    for file in FILES:\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        if not os.path.exists(file_path):\n",
    "            try:\n",
    "                print(f\"Downloading {file}...\")\n",
    "                url = f\"{BASE_URL}{file}\"\n",
    "                urllib.request.urlretrieve(url, file_path)\n",
    "                print(f\"Downloaded {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {file}: {e}\")\n",
    "                print(\"Please download the file manually and place it in the data directory.\")\n",
    "                raise\n",
    "        else:\n",
    "            print(f\"File {file} already exists, skipping download\")\n",
    "\n",
    "\n",
    "def make_names_unique(names):\n",
    "    \"\"\"\n",
    "    Make a list of names unique by appending a suffix to duplicates.\n",
    "    \"\"\"\n",
    "    name_count = {}\n",
    "    unique_names = []\n",
    "    for name in names:\n",
    "        if name in name_count:\n",
    "            name_count[name] += 1\n",
    "            unique_names.append(f\"{name}_{name_count[name]}\")\n",
    "        else:\n",
    "            name_count[name] = 0\n",
    "            unique_names.append(name)\n",
    "    return unique_names\n",
    "\n",
    "\n",
    "def read_mtx_data(data_dir, prefix):\n",
    "    \"\"\"\n",
    "    Read data from 10X mtx format.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the data directory\n",
    "        prefix: Prefix of the files to read (e.g. GSE284526_LBA001)\n",
    "        \n",
    "    Returns:\n",
    "        ad.AnnData object with the data\n",
    "    \"\"\"\n",
    "    mtx_file = os.path.join(data_dir, f\"{prefix}_matrix.mtx.gz\")\n",
    "    features_file = os.path.join(data_dir, f\"{prefix}_features.tsv.gz\")\n",
    "    barcodes_file = os.path.join(data_dir, f\"{prefix}_barcodes.tsv.gz\")\n",
    "    \n",
    "    # Read matrix\n",
    "    matrix = sio.mmread(mtx_file).T.tocsr()\n",
    "    \n",
    "    # Read features\n",
    "    with gzip.open(features_file, 'rt') as f:\n",
    "        feature_df = pd.DataFrame([line.strip().split('\\t') for line in f])\n",
    "    \n",
    "    # Read barcodes\n",
    "    with gzip.open(barcodes_file, 'rt') as f:\n",
    "        # Add prefix to barcode to keep them unique across multiple samples\n",
    "        barcodes = [f\"{line.strip()}_{prefix}\" for line in f]\n",
    "    \n",
    "    # Create AnnData object\n",
    "    adata = ad.AnnData(X=matrix, obs=pd.DataFrame(index=barcodes))\n",
    "    \n",
    "    # Set var names and attributes\n",
    "    # Typically:\n",
    "    #   feature_df col0 = gene ID\n",
    "    #   feature_df col1 = gene name\n",
    "    #   feature_df col2 = feature type\n",
    "    if feature_df.shape[1] >= 3:\n",
    "        var_names = pd.Series(feature_df[1].values).astype(str)\n",
    "        adata.var['original_name'] = var_names.values\n",
    "        \n",
    "        # Make var_names unique\n",
    "        var_names_unique = pd.Series(make_names_unique(var_names))\n",
    "        adata.var_names = var_names_unique\n",
    "        \n",
    "        adata.var['feature_id'] = feature_df[0].values\n",
    "        adata.var['feature_type'] = feature_df[2].values\n",
    "    else:\n",
    "        # Fallback if the file has fewer columns\n",
    "        var_names = pd.Series(feature_df[0].values).astype(str)\n",
    "        adata.var['original_name'] = var_names.values\n",
    "        adata.var_names = pd.Series(make_names_unique(var_names))\n",
    "    \n",
    "    # Add sample information\n",
    "    adata.obs['sample_id'] = prefix\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def split_gene_protein_data(adata):\n",
    "    \"\"\"\n",
    "    Split AnnData object into gene expression and protein data.\n",
    "    \n",
    "    Args:\n",
    "        adata: AnnData object with gene expression and protein data\n",
    "        \n",
    "    Returns:\n",
    "        (gene_adata, protein_adata)\n",
    "    \"\"\"\n",
    "    # Get gene expression data\n",
    "    gene_mask = adata.var['feature_type'] == 'Gene Expression'\n",
    "    gene_adata = adata[:, gene_mask].copy()\n",
    "    \n",
    "    # Get protein data\n",
    "    protein_mask = adata.var['feature_type'] == 'Antibody Capture'\n",
    "    protein_adata = adata[:, protein_mask].copy()\n",
    "    \n",
    "    # Filter out \"Hashtag\" features from protein data, if present\n",
    "    if 'original_name' in protein_adata.var:\n",
    "        non_hashtag_mask = ~protein_adata.var['original_name'].str.contains('Hashtag', na=False)\n",
    "        protein_adata = protein_adata[:, non_hashtag_mask].copy()\n",
    "    \n",
    "    return gene_adata, protein_adata\n",
    "\n",
    "\n",
    "def add_metadata(adata, sample_id):\n",
    "    \"\"\"\n",
    "    Add metadata to AnnData object based on sample ID and hashtags.\n",
    "    \n",
    "    Args:\n",
    "        adata: AnnData object\n",
    "        sample_id: Sample ID (e.g. GSE284526_LBA001, GSE284526_LBA002, etc.)\n",
    "        \n",
    "    Returns:\n",
    "        adata with added metadata\n",
    "    \"\"\"\n",
    "    # Identify any hashtag-based sub-samples if present\n",
    "    if sample_id in ['GSE284526_LBA001', 'GSE284526_LBA002']:\n",
    "        if 'original_name' in adata.var:\n",
    "            hashtag_features = adata.var[adata.var['original_name'].str.contains('Hashtag', na=False)]\n",
    "        else:\n",
    "            hashtag_features = pd.DataFrame()\n",
    "        \n",
    "        if not hashtag_features.empty:\n",
    "            # Summed hashtag expression\n",
    "            hashtag_indices = hashtag_features.index\n",
    "            hashtag_names = hashtag_features['original_name'].values\n",
    "            idx_to_name = dict(zip(hashtag_indices, hashtag_names))\n",
    "            \n",
    "            hashtag_counts = pd.DataFrame(\n",
    "                adata[:, hashtag_indices].X.toarray(),\n",
    "                index=adata.obs_names,\n",
    "                columns=[idx_to_name[idx] for idx in hashtag_indices]\n",
    "            )\n",
    "            \n",
    "            # Each cell assigned to the hashtag with the highest count\n",
    "            adata.obs['hashtag'] = hashtag_counts.idxmax(axis=1)\n",
    "            \n",
    "            if sample_id == 'GSE284526_LBA001':\n",
    "                adata.obs['sample'] = adata.obs['hashtag'].map({\n",
    "                    'Hashtag1': 'ATRIP',\n",
    "                    'Hashtag2': 'HC1'\n",
    "                }).fillna('Unknown')\n",
    "            else:  # LBA002\n",
    "                adata.obs['sample'] = adata.obs['hashtag'].map({\n",
    "                    'Hashtag3': 'HC2',\n",
    "                    'Hashtag4': 'HC3'\n",
    "                }).fillna('Unknown')\n",
    "        else:\n",
    "            # No hashtags found\n",
    "            adata.obs['sample'] = sample_id\n",
    "    else:\n",
    "        # LBA003/LBA004 are B-cell purified, so treat them as single samples\n",
    "        adata.obs['sample'] = sample_id\n",
    "    \n",
    "    # Standard metadata\n",
    "    adata.obs['organism'] = 'Homo sapiens'\n",
    "    adata.obs['cell_type'] = 'Unknown'\n",
    "    adata.obs['crispr_type'] = 'None'\n",
    "    adata.obs['cancer_type'] = 'Non-Cancer'\n",
    "    \n",
    "    # Add condition mapping\n",
    "    adata.obs['condition'] = adata.obs['sample'].map({\n",
    "        'ATRIP': 'ATRIP-deficient',\n",
    "        'HC1': 'Healthy Control',\n",
    "        'HC2': 'Healthy Control',\n",
    "        'HC3': 'Healthy Control',\n",
    "        'GSE284526_LBA003': 'B cells',\n",
    "        'GSE284526_LBA004': 'B cells'\n",
    "    }).fillna('Unknown')\n",
    "    \n",
    "    adata.obs['perturbation_name'] = 'None'\n",
    "    \n",
    "    # Refine cell_type\n",
    "    if 'LBA003' in sample_id or 'LBA004' in sample_id:\n",
    "        adata.obs['cell_type'] = 'B cells'\n",
    "    elif 'LBA001' in sample_id or 'LBA002' in sample_id:\n",
    "        adata.obs['cell_type'] = 'PBMCs'\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def harmonize_data(data_dir):\n",
    "    \"\"\"\n",
    "    Harmonize data from the GSE284526 dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the data directory\n",
    "        \n",
    "    Returns:\n",
    "        (gene_adata, protein_adata)\n",
    "    \"\"\"\n",
    "    # 1. Download files if needed\n",
    "    download_files(data_dir)\n",
    "    \n",
    "    # 2. Read and process each sample\n",
    "    samples = ['GSE284526_LBA001', 'GSE284526_LBA002', 'GSE284526_LBA003', 'GSE284526_LBA004']\n",
    "    adatas = []\n",
    "    for prefix in samples:\n",
    "        print(f\"\\nProcessing {prefix}...\")\n",
    "        adata = read_mtx_data(data_dir, prefix)\n",
    "        adata = add_metadata(adata, prefix)\n",
    "        adatas.append(adata)\n",
    "    \n",
    "    # 3. Concatenate all samples\n",
    "    print(\"\\nMerging samples...\")\n",
    "    merged_adata = ad.concat(adatas, join='outer', merge='same')\n",
    "    \n",
    "    # 4. Split into gene-expression and protein-expression data\n",
    "    print(\"Splitting gene expression and protein data...\")\n",
    "    gene_adata, protein_adata = split_gene_protein_data(merged_adata)\n",
    "    \n",
    "    # 5. Filter for overlapping cells (i.e., those that have both gene + protein data)\n",
    "    print(\"Filtering for paired data...\")\n",
    "    common_cells = np.intersect1d(gene_adata.obs_names, protein_adata.obs_names)\n",
    "    print(f\"Found {len(common_cells)} cells with both gene and protein data.\")\n",
    "    \n",
    "    if len(common_cells) > 0:\n",
    "        gene_adata = gene_adata[common_cells].copy()\n",
    "        protein_adata = protein_adata[common_cells].copy()\n",
    "        \n",
    "        # Synchronize metadata columns\n",
    "        for col in gene_adata.obs.columns:\n",
    "            if col in protein_adata.obs.columns:\n",
    "                protein_adata.obs[col] = gene_adata.obs[col]\n",
    "    else:\n",
    "        print(\"Warning: No overlapping cells found. Keeping all cells in separate objects.\")\n",
    "    \n",
    "    # 6. Clean up gene names\n",
    "    print(\"Cleaning gene names...\")\n",
    "    if 'feature_id' in gene_adata.var:\n",
    "        gene_symbols = []\n",
    "        for idx, row in gene_adata.var.iterrows():\n",
    "            if 'original_name' in row and pd.notna(row['original_name']):\n",
    "                gene_symbols.append(row['original_name'])\n",
    "            else:\n",
    "                # Fallback to feature_id\n",
    "                feature_id = row['feature_id']\n",
    "                gene_symbols.append(feature_id if isinstance(feature_id, str) else idx)\n",
    "        \n",
    "        # Store original IDs\n",
    "        gene_adata.var['ensembl_id'] = gene_adata.var['feature_id']\n",
    "        \n",
    "        # Make gene symbols unique\n",
    "        unique_gene_symbols = make_names_unique(gene_symbols)\n",
    "        gene_adata.var_names = unique_gene_symbols\n",
    "    \n",
    "    # 7. Clean up protein names: remove text after first underscore, make unique if needed\n",
    "    print(\"Cleaning protein names...\")\n",
    "    if 'original_name' in protein_adata.var:\n",
    "        \n",
    "        def clean_protein_name(name):\n",
    "            # Remove anything after the first underscore\n",
    "            if \"_\" in name:\n",
    "                return name.split(\"_\", 1)[0]\n",
    "            else:\n",
    "                return name\n",
    "        \n",
    "        # Transform each original_name\n",
    "        protein_raw_names = protein_adata.var['original_name'].tolist()\n",
    "        cleaned_names = [clean_protein_name(n) for n in protein_raw_names]\n",
    "        \n",
    "        # Make them unique\n",
    "        cleaned_unique_names = make_names_unique(cleaned_names)\n",
    "        protein_adata.var_names = cleaned_unique_names\n",
    "    \n",
    "    return gene_adata, protein_adata\n",
    "\n",
    "\n",
    "def main(data_dir):\n",
    "    \"\"\"\n",
    "    Main function: Harmonize data and write outputs to disk.\n",
    "    \"\"\"\n",
    "    # Harmonize\n",
    "    gene_adata, protein_adata = harmonize_data(data_dir)\n",
    "    \n",
    "    # Save .h5ad\n",
    "    gene_output_file = os.path.join(data_dir, \"GSE284526_gene_expression.h5ad\")\n",
    "    protein_output_file = os.path.join(data_dir, \"GSE284526_protein_expression.h5ad\")\n",
    "    \n",
    "    print(f\"\\nSaving gene expression data to {gene_output_file}...\")\n",
    "    gene_adata.write_h5ad(gene_output_file)\n",
    "    \n",
    "    print(f\"Saving protein expression data to {protein_output_file}...\")\n",
    "    protein_adata.write_h5ad(protein_output_file)\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"Done!\\n\")\n",
    "    print(f\"Gene expression data: {gene_adata.shape[0]} cells, {gene_adata.shape[1]} genes\")\n",
    "    print(f\"Protein expression data: {protein_adata.shape[0]} cells, {protein_adata.shape[1]} proteins\")\n",
    "\n",
    "\n",
    "# In a Jupyter Notebook, you can call:\n",
    "main(\"/content/GSE284526\")\n",
    "\n",
    "# If you want to see the in-memory AnnData objects without saving:\n",
    "# gene_adata, protein_adata = harmonize_data(\"/path/to/data_dir\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
