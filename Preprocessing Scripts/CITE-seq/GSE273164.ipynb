{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import anndata\n",
    "\n",
    "# Constants\n",
    "GEO_ACCESSION = \"GSE273164\"\n",
    "GEO_URL = f\"https://www.ncbi.nlm.nih.gov/geo/download/?acc={GEO_ACCESSION}&format=file\"\n",
    "README_URL = f\"https://ftp.ncbi.nlm.nih.gov/geo/series/{GEO_ACCESSION[:5]}nnn/{GEO_ACCESSION}/suppl/{GEO_ACCESSION}_feature_README.txt\"\n",
    "\n",
    "\n",
    "def download_dataset(data_dir: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Download the dataset if it doesn't exist.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Directory to store the dataset\n",
    "\n",
    "    Returns:\n",
    "        Path to the downloaded tar file\n",
    "    \"\"\"\n",
    "    tar_path = data_dir / f\"{GEO_ACCESSION}_RAW.tar\"\n",
    "\n",
    "    if tar_path.exists():\n",
    "        print(f\"Dataset already exists at {tar_path}\")\n",
    "        return tar_path\n",
    "\n",
    "    print(f\"Downloading dataset from {GEO_URL}...\")\n",
    "    urllib.request.urlretrieve(GEO_URL, tar_path)\n",
    "    print(f\"Downloaded dataset to {tar_path}\")\n",
    "\n",
    "    return tar_path\n",
    "\n",
    "\n",
    "def extract_files(tar_path: Path, data_dir: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Extract files from the tar archive.\n",
    "\n",
    "    Args:\n",
    "        tar_path: Path to the tar file\n",
    "        data_dir: Directory to extract the files to\n",
    "\n",
    "    Returns:\n",
    "        Path to the extracted directory\n",
    "    \"\"\"\n",
    "    extract_dir = data_dir / \"extracted\"\n",
    "\n",
    "    if extract_dir.exists():\n",
    "        print(f\"Files already extracted to {extract_dir}\")\n",
    "        return extract_dir\n",
    "\n",
    "    print(f\"Extracting files from {tar_path}...\")\n",
    "    extract_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    with tarfile.open(tar_path) as tar:\n",
    "        tar.extractall(path=extract_dir)\n",
    "\n",
    "    print(f\"Extracted files to {extract_dir}\")\n",
    "    return extract_dir\n",
    "\n",
    "\n",
    "def get_file_paths(extract_dir: Path) -> Dict[str, Dict[str, Path]]:\n",
    "    \"\"\"\n",
    "    Get file paths for each pool.\n",
    "\n",
    "    Args:\n",
    "        extract_dir: Directory containing the extracted files\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping pool IDs to file paths\n",
    "    \"\"\"\n",
    "    file_paths_by_pool = {}\n",
    "\n",
    "    # Find all CSV files\n",
    "    csv_files = list(extract_dir.glob(\"*.csv.gz\"))\n",
    "\n",
    "    # Group files by pool\n",
    "    for file_path in csv_files:\n",
    "        file_name = file_path.name\n",
    "\n",
    "        # Extract pool ID from file name\n",
    "        if \"_RNA_\" in file_name:\n",
    "            pool_id = file_name.split(\"_RNA_\")[0]\n",
    "            file_type = \"rna\"\n",
    "        elif \"_ADT_\" in file_name:\n",
    "            pool_id = file_name.split(\"_ADT_\")[0]\n",
    "            file_type = \"adt\"\n",
    "        elif \"_HTO_\" in file_name:\n",
    "            pool_id = file_name.split(\"_HTO_\")[0]\n",
    "            file_type = \"hto\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if pool_id not in file_paths_by_pool:\n",
    "            file_paths_by_pool[pool_id] = {}\n",
    "\n",
    "        file_paths_by_pool[pool_id][file_type] = file_path\n",
    "\n",
    "    print(f\"Found {len(file_paths_by_pool)} pools:\")\n",
    "    for pool_id, file_paths in file_paths_by_pool.items():\n",
    "        print(f\"  {pool_id}: {', '.join(file_paths.keys())}\")\n",
    "\n",
    "    return file_paths_by_pool\n",
    "\n",
    "\n",
    "def load_adt_feature_metadata(data_dir: Path) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Load ADT feature metadata from the README file.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Directory containing the dataset\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping ADT feature IDs to protein names\n",
    "    \"\"\"\n",
    "    readme_path = data_dir / f\"{GEO_ACCESSION}_feature_README.txt\"\n",
    "\n",
    "    # Download README file if it doesn't exist\n",
    "    if not readme_path.exists():\n",
    "        print(f\"Downloading README file from {README_URL}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(README_URL, readme_path)\n",
    "            print(f\"Downloaded README file to {readme_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"WARNING: {readme_path} does not exist. Skipping ADT feature metadata loading.\")\n",
    "            return {}\n",
    "\n",
    "    # Parse README file\n",
    "    try:\n",
    "        feature_to_protein = {}\n",
    "\n",
    "        with open(readme_path, 'r') as f:\n",
    "            # Skip header\n",
    "            f.readline()\n",
    "\n",
    "            for line in f:\n",
    "                parts = line.strip().split(',')\n",
    "                if len(parts) >= 5 and 'Antibody Capture' in line:\n",
    "                    adt_id = parts[0]\n",
    "                    protein_name = parts[1]\n",
    "                    sequence = parts[4]\n",
    "                    feature_id = f\"{adt_id}-{sequence}\"\n",
    "\n",
    "                    feature_to_protein[adt_id] = protein_name\n",
    "                    feature_to_protein[sequence] = protein_name\n",
    "                    feature_to_protein[feature_id] = protein_name\n",
    "\n",
    "        print(f\"Loaded metadata for {len(feature_to_protein)} ADT features\")\n",
    "        return feature_to_protein\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading ADT feature metadata: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def parse_cell_barcode(barcode: str) -> Tuple[str, str, str]:\n",
    "    \"\"\"\n",
    "    Parse a cell barcode to extract sample ID, perturbation, and cell barcode.\n",
    "\n",
    "    Args:\n",
    "        barcode: Cell barcode string\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (sample_id, perturbation, cell_barcode)\n",
    "    \"\"\"\n",
    "    # Example: PZ-2975_PDX17c-pool1_AAACCCAAGATACAGT-1\n",
    "    parts = barcode.split('_')\n",
    "\n",
    "    if len(parts) >= 3:\n",
    "        sample_id = parts[1].split('-')[0]  # PDX17c\n",
    "        cell_barcode = parts[2]  # AAACCCAAGATACAGT-1\n",
    "\n",
    "        # Determine perturbation\n",
    "        if 'sgGAP45.3' in barcode or 'sgGAP45-3' in barcode:\n",
    "            perturbation = f\"{sample_id}-sgGAP45.3\"\n",
    "        elif 'sgGAP45.4' in barcode or 'sgGAP45-4' in barcode:\n",
    "            perturbation = f\"{sample_id}-sgGAP45.4\"\n",
    "        else:\n",
    "            perturbation = f\"{sample_id}-sgNeg\"\n",
    "\n",
    "        return sample_id, perturbation, cell_barcode\n",
    "\n",
    "    return \"\", \"\", barcode\n",
    "\n",
    "\n",
    "def read_csv_data(file_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a CSV file containing expression data.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "\n",
    "    Returns:\n",
    "        DataFrame containing the expression data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, compression='gzip', index_col=0)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def process_expression_data(\n",
    "    pool_id: str,\n",
    "    rna_path: Optional[Path] = None,\n",
    "    adt_path: Optional[Path] = None,\n",
    "    adt_feature_metadata: Optional[Dict[str, str]] = None\n",
    ") -> Tuple[Optional[anndata.AnnData], Optional[anndata.AnnData]]:\n",
    "    \"\"\"\n",
    "    Process expression data for a single pool.\n",
    "\n",
    "    Args:\n",
    "        pool_id: Pool ID\n",
    "        rna_path: Path to RNA expression data\n",
    "        adt_path: Path to ADT expression data\n",
    "        adt_feature_metadata: Dictionary mapping ADT feature IDs to protein names\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (RNA AnnData, ADT AnnData)\n",
    "    \"\"\"\n",
    "    # Read RNA data\n",
    "    rna_adata = None\n",
    "    if rna_path:\n",
    "        print(f\"Reading RNA data from {rna_path}\")\n",
    "        try:\n",
    "            # Read the data (genes as rows, cells as columns)\n",
    "            rna_df = read_csv_data(rna_path)\n",
    "\n",
    "            if rna_df.empty:\n",
    "                print(\"RNA data is empty\")\n",
    "                return None, None\n",
    "\n",
    "            # Extract cell barcodes and gene names\n",
    "            cell_barcodes = rna_df.columns.tolist()\n",
    "            gene_names = rna_df.index.tolist()\n",
    "\n",
    "            # Create expression matrix (genes x cells)\n",
    "            X = rna_df.values\n",
    "\n",
    "            # Create AnnData object with transposed data (cells x genes)\n",
    "            rna_adata = anndata.AnnData(\n",
    "                X=sparse.csr_matrix(X.T),\n",
    "                obs=pd.DataFrame(index=cell_barcodes),\n",
    "                var=pd.DataFrame(index=gene_names)\n",
    "            )\n",
    "\n",
    "            # Add original barcodes\n",
    "            rna_adata.obs['Barcode'] = cell_barcodes\n",
    "\n",
    "            # Extract metadata from barcodes\n",
    "            sample_ids = []\n",
    "            perturbations = []\n",
    "            cell_ids = []\n",
    "\n",
    "            for barcode in cell_barcodes:\n",
    "                sample_id, perturbation, cell_id = parse_cell_barcode(barcode)\n",
    "                sample_ids.append(sample_id)\n",
    "                perturbations.append(perturbation)\n",
    "                cell_ids.append(cell_id)\n",
    "\n",
    "            rna_adata.obs['sample_id'] = sample_ids\n",
    "            rna_adata.obs['perturbation_name'] = perturbations\n",
    "            rna_adata.obs['cell_id'] = cell_ids\n",
    "\n",
    "            # Add sequencing lane information\n",
    "            rna_adata.obs['Sequencing.Lane'] = pool_id\n",
    "            rna_adata.obs['pool_id'] = pool_id\n",
    "\n",
    "            print(f\"RNA data shape: {rna_adata.shape}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing RNA data: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    # Read ADT data\n",
    "    adt_adata = None\n",
    "    if adt_path:\n",
    "        print(f\"Reading ADT data from {adt_path}\")\n",
    "        try:\n",
    "            # Read the data (proteins as rows, cells as columns)\n",
    "            adt_df = read_csv_data(adt_path)\n",
    "\n",
    "            if adt_df.empty:\n",
    "                print(\"ADT data is empty\")\n",
    "                return rna_adata, None\n",
    "\n",
    "            # Extract cell barcodes and protein names\n",
    "            cell_barcodes = adt_df.columns.tolist()\n",
    "            protein_ids = adt_df.index.tolist()\n",
    "\n",
    "            # Create expression matrix (proteins x cells)\n",
    "            X = adt_df.values\n",
    "\n",
    "            # Create AnnData object with transposed data (cells x proteins)\n",
    "            adt_adata = anndata.AnnData(\n",
    "                X=sparse.csr_matrix(X.T),\n",
    "                obs=pd.DataFrame(index=cell_barcodes),\n",
    "                var=pd.DataFrame(index=protein_ids)\n",
    "            )\n",
    "\n",
    "            # Add original barcodes\n",
    "            adt_adata.obs['Barcode'] = cell_barcodes\n",
    "\n",
    "            # Extract metadata from barcodes\n",
    "            sample_ids = []\n",
    "            perturbations = []\n",
    "            cell_ids = []\n",
    "\n",
    "            for barcode in cell_barcodes:\n",
    "                sample_id, perturbation, cell_id = parse_cell_barcode(barcode)\n",
    "                sample_ids.append(sample_id)\n",
    "                perturbations.append(perturbation)\n",
    "                cell_ids.append(cell_id)\n",
    "\n",
    "            adt_adata.obs['sample_id'] = sample_ids\n",
    "            adt_adata.obs['perturbation_name'] = perturbations\n",
    "            adt_adata.obs['cell_id'] = cell_ids\n",
    "\n",
    "            # Add sequencing lane information\n",
    "            adt_adata.obs['Sequencing.Lane'] = pool_id\n",
    "            adt_adata.obs['pool_id'] = pool_id\n",
    "\n",
    "            # Add protein names if available\n",
    "            if adt_feature_metadata:\n",
    "                protein_names = []\n",
    "                for protein_id in protein_ids:\n",
    "                    if protein_id in adt_feature_metadata:\n",
    "                        protein_names.append(adt_feature_metadata[protein_id])\n",
    "                    else:\n",
    "                        protein_names.append(protein_id)\n",
    "\n",
    "                adt_adata.var['protein_name'] = protein_names\n",
    "\n",
    "            print(f\"ADT data shape: {adt_adata.shape}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing ADT data: {e}\")\n",
    "            return rna_adata, None\n",
    "\n",
    "    return rna_adata, adt_adata\n",
    "\n",
    "\n",
    "def process_pool(\n",
    "    pool_id: str,\n",
    "    file_paths: Dict[str, Path],\n",
    "    adt_feature_metadata: Optional[Dict[str, str]] = None,\n",
    "    output_dir: Optional[Path] = None\n",
    ") -> Tuple[Optional[anndata.AnnData], Optional[anndata.AnnData]]:\n",
    "    \"\"\"\n",
    "    Process data for a single pool.\n",
    "\n",
    "    Args:\n",
    "        pool_id: Pool ID\n",
    "        file_paths: Dictionary mapping file types to file paths\n",
    "        adt_feature_metadata: Dictionary mapping ADT feature IDs to protein names\n",
    "        output_dir: Directory to save intermediate results\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (RNA AnnData, ADT AnnData)\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing pool: {pool_id}\")\n",
    "\n",
    "    try:\n",
    "        # Process expression data\n",
    "        rna_adata, adt_adata = process_expression_data(\n",
    "            pool_id=pool_id,\n",
    "            rna_path=file_paths.get('rna'),\n",
    "            adt_path=file_paths.get('adt'),\n",
    "            adt_feature_metadata=adt_feature_metadata\n",
    "        )\n",
    "\n",
    "        # Check if data was processed successfully\n",
    "        if rna_adata is None and adt_adata is None:\n",
    "            print(f\"Failed to process data for pool {pool_id}\")\n",
    "            return None, None\n",
    "\n",
    "        # Find common barcodes\n",
    "        if rna_adata is not None and adt_adata is not None:\n",
    "            common_barcodes = set(rna_adata.obs_names).intersection(set(adt_adata.obs_names))\n",
    "            print(f\"Found {len(common_barcodes)} common barcodes across RNA and ADT data\")\n",
    "\n",
    "            # Filter data to include only common barcodes\n",
    "            if len(common_barcodes) > 0:\n",
    "                rna_adata = rna_adata[list(common_barcodes)]\n",
    "                adt_adata = adt_adata[list(common_barcodes)]\n",
    "\n",
    "                print(f\"Filtered RNA data shape: {rna_adata.shape}\")\n",
    "                print(f\"Filtered ADT data shape: {adt_adata.shape}\")\n",
    "\n",
    "        # Save intermediate results if output directory is provided\n",
    "        if output_dir is not None:\n",
    "            pool_dir = output_dir / \"pools\"\n",
    "            pool_dir.mkdir(exist_ok=True)\n",
    "\n",
    "            if rna_adata is not None:\n",
    "                rna_output_path = pool_dir / f\"{pool_id}_rna.h5ad\"\n",
    "                print(f\"Saving RNA data to {rna_output_path}\")\n",
    "                rna_adata.write(rna_output_path)\n",
    "\n",
    "            if adt_adata is not None:\n",
    "                adt_output_path = pool_dir / f\"{pool_id}_adt.h5ad\"\n",
    "                print(f\"Saving ADT data to {adt_output_path}\")\n",
    "                adt_adata.write(adt_output_path)\n",
    "\n",
    "        return rna_adata, adt_adata\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing pool {pool_id}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def add_standardized_metadata(adata: anndata.AnnData, data_type: str) -> anndata.AnnData:\n",
    "    \"\"\"\n",
    "    Add standardized metadata to AnnData object.\n",
    "\n",
    "    Args:\n",
    "        adata: AnnData object\n",
    "        data_type: Type of data ('rna' or 'adt')\n",
    "\n",
    "    Returns:\n",
    "        AnnData object with standardized metadata\n",
    "    \"\"\"\n",
    "    # Add organism information\n",
    "    adata.obs['organism'] = 'Homo sapiens'\n",
    "\n",
    "    # Add cell type information\n",
    "    adata.obs['cell_type'] = 'AML'\n",
    "\n",
    "    # Add CRISPR type information\n",
    "    adata.obs['crispr_type'] = 'CRISPR KO'\n",
    "\n",
    "    # Add cancer type information\n",
    "    adata.obs['cancer_type'] = 'Acute Myeloid Leukemia'\n",
    "\n",
    "    # Add condition information based on perturbation\n",
    "    conditions = []\n",
    "    for perturbation in adata.obs['perturbation_name']:\n",
    "        if 'sgGAP45' in perturbation:\n",
    "            conditions.append('ARHGAP45 KO')\n",
    "        else:\n",
    "            conditions.append('Control')\n",
    "\n",
    "    adata.obs['condition'] = conditions\n",
    "\n",
    "    # Convert categorical columns\n",
    "    for col in ['organism', 'cell_type', 'crispr_type', 'cancer_type', 'condition', 'perturbation_name']:\n",
    "        adata.obs[col] = adata.obs[col].astype('category')\n",
    "\n",
    "    # Add label column for visualization\n",
    "    adata.obs['Label'] = adata.obs['perturbation_name']\n",
    "\n",
    "    return adata\n",
    "\n",
    "\n",
    "def combine_pools(\n",
    "    rna_adatas: List[anndata.AnnData],\n",
    "    adt_adatas: List[anndata.AnnData],\n",
    "    output_dir: Path\n",
    ") -> Tuple[anndata.AnnData, anndata.AnnData]:\n",
    "    \"\"\"\n",
    "    Combine data from multiple pools.\n",
    "\n",
    "    Args:\n",
    "        rna_adatas: List of RNA AnnData objects\n",
    "        adt_adatas: List of ADT AnnData objects\n",
    "        output_dir: Directory to save intermediate results\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (combined RNA AnnData, combined ADT AnnData)\n",
    "    \"\"\"\n",
    "    print(\"\\nCombining data from all pools...\")\n",
    "\n",
    "    # Combine RNA data\n",
    "    combined_rna = anndata.concat(\n",
    "        rna_adatas,\n",
    "        join='outer',\n",
    "        fill_value=0,\n",
    "        index_unique='-'\n",
    "    )\n",
    "\n",
    "    # Combine ADT data\n",
    "    combined_adt = anndata.concat(\n",
    "        adt_adatas,\n",
    "        join='outer',\n",
    "        fill_value=0,\n",
    "        index_unique='-'\n",
    "    )\n",
    "\n",
    "    print(f\"Combined RNA data shape: {combined_rna.shape}\")\n",
    "    print(f\"Combined ADT data shape: {combined_adt.shape}\")\n",
    "\n",
    "    # Save intermediate results\n",
    "    rna_output_path = output_dir / f\"{GEO_ACCESSION}_rna.h5ad\"\n",
    "    adt_output_path = output_dir / f\"{GEO_ACCESSION}_adt.h5ad\"\n",
    "\n",
    "    print(f\"Saving combined RNA data to {rna_output_path}\")\n",
    "    combined_rna.write(rna_output_path)\n",
    "\n",
    "    print(f\"Saving combined ADT data to {adt_output_path}\")\n",
    "    combined_adt.write(adt_output_path)\n",
    "\n",
    "    return combined_rna, combined_adt\n",
    "\n",
    "\n",
    "def harmonize_data(\n",
    "    rna_adata: anndata.AnnData,\n",
    "    adt_adata: anndata.AnnData,\n",
    "    output_dir: Path\n",
    ") -> Tuple[anndata.AnnData, anndata.AnnData]:\n",
    "    \"\"\"\n",
    "    Harmonize data by adding standardized metadata.\n",
    "\n",
    "    Args:\n",
    "        rna_adata: RNA AnnData object\n",
    "        adt_adata: ADT AnnData object\n",
    "        output_dir: Directory to save intermediate results\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (harmonized RNA AnnData, harmonized ADT AnnData)\n",
    "    \"\"\"\n",
    "    print(\"\\nHarmonizing data...\")\n",
    "\n",
    "    # Add standardized metadata\n",
    "    rna_adata = add_standardized_metadata(rna_adata, 'rna')\n",
    "    adt_adata = add_standardized_metadata(adt_adata, 'adt')\n",
    "\n",
    "    # Save intermediate results\n",
    "    rna_output_path = output_dir / f\"{GEO_ACCESSION}_rna_updated.h5ad\"\n",
    "    adt_output_path = output_dir / f\"{GEO_ACCESSION}_adt_updated.h5ad\"\n",
    "\n",
    "    print(f\"Saving harmonized RNA data to {rna_output_path}\")\n",
    "    rna_adata.write(rna_output_path)\n",
    "\n",
    "    print(f\"Saving harmonized ADT data to {adt_output_path}\")\n",
    "    adt_adata.write(adt_output_path)\n",
    "\n",
    "    return rna_adata, adt_adata\n",
    "\n",
    "\n",
    "def filter_paired_data(\n",
    "    rna_adata: anndata.AnnData,\n",
    "    adt_adata: anndata.AnnData,\n",
    "    output_dir: Path\n",
    ") -> Tuple[anndata.AnnData, anndata.AnnData]:\n",
    "    \"\"\"\n",
    "    Filter data to include only cells with both RNA and ADT data.\n",
    "\n",
    "    Args:\n",
    "        rna_adata: RNA AnnData object\n",
    "        adt_adata: ADT AnnData object\n",
    "        output_dir: Directory to save final results\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (filtered RNA AnnData, filtered ADT AnnData)\n",
    "    \"\"\"\n",
    "    print(\"\\nFiltering paired data...\")\n",
    "\n",
    "    # Find common barcodes\n",
    "    common_barcodes = set(rna_adata.obs_names).intersection(set(adt_adata.obs_names))\n",
    "    print(f\"Found {len(common_barcodes)} common barcodes across RNA and ADT data\")\n",
    "\n",
    "    # Filter data to include only common barcodes\n",
    "    if len(common_barcodes) > 0:\n",
    "        rna_adata = rna_adata[list(common_barcodes)]\n",
    "        adt_adata = adt_adata[list(common_barcodes)]\n",
    "\n",
    "        print(f\"Filtered RNA data shape: {rna_adata.shape}\")\n",
    "        print(f\"Filtered ADT data shape: {adt_adata.shape}\")\n",
    "\n",
    "    # Save final results\n",
    "    rna_output_path = output_dir / f\"{GEO_ACCESSION}_rna_final.h5ad\"\n",
    "    adt_output_path = output_dir / f\"{GEO_ACCESSION}_adt_final.h5ad\"\n",
    "\n",
    "    print(f\"Saving final RNA data to {rna_output_path}\")\n",
    "    rna_adata.write(rna_output_path)\n",
    "\n",
    "    print(f\"Saving final ADT data to {adt_output_path}\")\n",
    "    adt_adata.write(adt_output_path)\n",
    "\n",
    "    return rna_adata, adt_adata\n",
    "\n",
    "\n",
    "def check_gene_symbols(rna_adata: anndata.AnnData) -> anndata.AnnData:\n",
    "    \"\"\"\n",
    "    Check if var_names are gene symbols and fix if needed.\n",
    "\n",
    "    Args:\n",
    "        rna_adata: RNA AnnData object\n",
    "\n",
    "    Returns:\n",
    "        RNA AnnData object with gene symbols as var_names\n",
    "    \"\"\"\n",
    "    print(\"\\nChecking gene symbols...\")\n",
    "\n",
    "    var_names = rna_adata.var_names.tolist()\n",
    "\n",
    "    # Check if var_names contain ENSEMBL IDs\n",
    "    if any(name.startswith('ENSG') for name in var_names[:100]):\n",
    "        print(\"var_names contain ENSEMBL IDs. Converting to gene symbols...\")\n",
    "\n",
    "        # Try to extract gene symbols from var_names\n",
    "        gene_symbols = []\n",
    "        for name in var_names:\n",
    "            if '|' in name:\n",
    "                # Format might be ENSEMBL|SYMBOL\n",
    "                parts = name.split('|')\n",
    "                if len(parts) > 1:\n",
    "                    gene_symbols.append(parts[1])\n",
    "                else:\n",
    "                    gene_symbols.append(name)\n",
    "            else:\n",
    "                gene_symbols.append(name)\n",
    "\n",
    "        # Check for duplicate gene symbols\n",
    "        if len(set(gene_symbols)) < len(gene_symbols):\n",
    "            print(\"Warning: Duplicate gene symbols found. Adding suffix to make them unique.\")\n",
    "\n",
    "            # Add suffix to duplicate gene symbols\n",
    "            symbol_count = {}\n",
    "            unique_symbols = []\n",
    "\n",
    "            for symbol in gene_symbols:\n",
    "                if symbol in symbol_count:\n",
    "                    symbol_count[symbol] += 1\n",
    "                    unique_symbols.append(f\"{symbol}_{symbol_count[symbol]}\")\n",
    "                else:\n",
    "                    symbol_count[symbol] = 0\n",
    "                    unique_symbols.append(symbol)\n",
    "\n",
    "            gene_symbols = unique_symbols\n",
    "\n",
    "        # Update var_names\n",
    "        rna_adata.var_names = pd.Index(gene_symbols)\n",
    "        print(f\"Updated var_names to gene symbols. Example: {rna_adata.var_names[:5].tolist()}\")\n",
    "    else:\n",
    "        print(f\"var_names already appear to be gene symbols. Example: {var_names[:5]}\")\n",
    "\n",
    "    return rna_adata\n",
    "\n",
    "\n",
    "def main(data_dir: Union[str, Path]) -> None:\n",
    "    \"\"\"\n",
    "    Main function to process the dataset.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Directory containing the dataset\n",
    "    \"\"\"\n",
    "    # Convert to Path object\n",
    "    data_dir = Path(data_dir)\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Create output directory\n",
    "    output_dir = data_dir / \"processed\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Download and extract dataset\n",
    "    tar_path = download_dataset(data_dir)\n",
    "    extract_dir = extract_files(tar_path, data_dir)\n",
    "\n",
    "    # Get file paths for each pool\n",
    "    file_paths_by_pool = get_file_paths(extract_dir)\n",
    "\n",
    "    # Load ADT feature metadata\n",
    "    adt_feature_metadata = load_adt_feature_metadata(data_dir)\n",
    "\n",
    "    # Process each pool\n",
    "    rna_adatas = []\n",
    "    adt_adatas = []\n",
    "\n",
    "    for pool_id, file_paths in file_paths_by_pool.items():\n",
    "        rna_adata, adt_adata = process_pool(\n",
    "            pool_id,\n",
    "            file_paths,\n",
    "            adt_feature_metadata=adt_feature_metadata,\n",
    "            output_dir=output_dir\n",
    "        )\n",
    "\n",
    "        if rna_adata is not None:\n",
    "            rna_adatas.append(rna_adata)\n",
    "\n",
    "        if adt_adata is not None:\n",
    "            adt_adatas.append(adt_adata)\n",
    "\n",
    "    # Combine data from all pools\n",
    "    if rna_adatas and adt_adatas:\n",
    "        combined_rna, combined_adt = combine_pools(rna_adatas, adt_adatas, output_dir)\n",
    "\n",
    "        # Check gene symbols\n",
    "        combined_rna = check_gene_symbols(combined_rna)\n",
    "\n",
    "        # Harmonize data\n",
    "        harmonized_rna, harmonized_adt = harmonize_data(combined_rna, combined_adt, output_dir)\n",
    "\n",
    "        # Filter paired data\n",
    "        final_rna, final_adt = filter_paired_data(harmonized_rna, harmonized_adt, output_dir)\n",
    "\n",
    "        print(\"\\nProcessing complete!\")\n",
    "        print(f\"Final RNA data shape: {final_rna.shape}\")\n",
    "        print(f\"Final ADT data shape: {final_adt.shape}\")\n",
    "    else:\n",
    "        print(\"No data was processed successfully.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# You can now simply call main() in your Jupyter notebook with the desired\n",
    "# data directory. By default, you can just pass in something like the current\n",
    "# directory or an absolute path:\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# Example usage in a Jupyter Notebook:\n",
    "data_dir = \"./GSE273164_data\"  # Change to your preferred folder\n",
    "main(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
