{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import anndata as ad\n",
    "\n",
    "# URLs for downloading the data\n",
    "GEO_URL_BASE = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE277nnn/GSE277081/suppl/\"\n",
    "FILES_TO_DOWNLOAD = [\n",
    "    \"GSE277081_barcodes-Aarm.tsv.gz\",\n",
    "    \"GSE277081_barcodes-Aflu.tsv.gz\",\n",
    "    \"GSE277081_barcodes-Barm.tsv.gz\",\n",
    "    \"GSE277081_barcodes-Bflu.tsv.gz\",\n",
    "    \"GSE277081_features-Aarm.tsv.gz\",\n",
    "    \"GSE277081_features-Aflu.tsv.gz\",\n",
    "    \"GSE277081_features-Barm.tsv.gz\",\n",
    "    \"GSE277081_features-Bflu.tsv.gz\",\n",
    "    \"GSE277081_matrix-Aarm.mtx.gz\",\n",
    "    \"GSE277081_matrix-Aflu.mtx.gz\",\n",
    "    \"GSE277081_matrix-Barm.mtx.gz\",\n",
    "    \"GSE277081_matrix-Bflu.mtx.gz\"\n",
    "]\n",
    "\n",
    "def download_data(data_dir):\n",
    "    \"\"\"\n",
    "    Download the dataset files if they don't exist.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (Path): Directory to download the data to\n",
    "    \"\"\"\n",
    "    raw_data_dir = data_dir / \"raw_data\"\n",
    "    raw_data_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    for file_name in FILES_TO_DOWNLOAD:\n",
    "        file_path = raw_data_dir / file_name\n",
    "        if not file_path.exists():\n",
    "            url = f\"{GEO_URL_BASE}{file_name}\"\n",
    "            print(f\"Downloading {url} to {file_path}\")\n",
    "            urllib.request.urlretrieve(url, file_path)\n",
    "        else:\n",
    "            print(f\"File {file_path} already exists, skipping download\")\n",
    "    \n",
    "    return raw_data_dir\n",
    "\n",
    "def read_10x_mtx(matrix_file, features_file, barcodes_file):\n",
    "    \"\"\"\n",
    "    Read 10x data from mtx, features, and barcodes files.\n",
    "    \n",
    "    Args:\n",
    "        matrix_file (str): Path to the matrix file\n",
    "        features_file (str): Path to the features file\n",
    "        barcodes_file (str): Path to the barcodes file\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (matrix, features_df, barcodes)\n",
    "    \"\"\"\n",
    "    # Read the matrix\n",
    "    with gzip.open(matrix_file, 'rt') as f:\n",
    "        # Skip header lines\n",
    "        while True:\n",
    "            header = f.readline()\n",
    "            if not header.startswith('%'):\n",
    "                break\n",
    "        \n",
    "        # Parse dimensions\n",
    "        dims = header.strip().split()\n",
    "        n_features, n_barcodes, n_entries = int(dims[0]), int(dims[1]), int(dims[2])\n",
    "        \n",
    "        # Read the data\n",
    "        data, row_indices, col_indices = [], [], []\n",
    "        for i in range(n_entries):\n",
    "            line = f.readline().strip().split()\n",
    "            row_indices.append(int(line[0]) - 1)  # 1-based to 0-based indexing\n",
    "            col_indices.append(int(line[1]) - 1)  # 1-based to 0-based indexing\n",
    "            data.append(int(line[2]))\n",
    "    \n",
    "    # Create sparse matrix\n",
    "    matrix = sp.csr_matrix((data, (row_indices, col_indices)), shape=(n_features, n_barcodes))\n",
    "    \n",
    "    # Read features\n",
    "    feature_ids = []\n",
    "    feature_names = []\n",
    "    feature_types = []\n",
    "    with gzip.open(features_file, 'rt') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            feature_ids.append(parts[0])\n",
    "            feature_names.append(parts[1])  # Use gene symbol as feature name\n",
    "            feature_types.append(parts[2])\n",
    "    \n",
    "    features_df = pd.DataFrame({\n",
    "        'feature_id': feature_ids,\n",
    "        'feature_name': feature_names,\n",
    "        'feature_type': feature_types\n",
    "    })\n",
    "    \n",
    "    # Read barcodes\n",
    "    barcodes = []\n",
    "    with gzip.open(barcodes_file, 'rt') as f:\n",
    "        for line in f:\n",
    "            barcodes.append(line.strip())\n",
    "    \n",
    "    return matrix, features_df, barcodes\n",
    "\n",
    "def process_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    Process the GSE277081 dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (Path): Directory containing the data\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (gene_expression_adata, protein_expression_adata)\n",
    "    \"\"\"\n",
    "    raw_data_dir = download_data(data_dir)\n",
    "    \n",
    "    # Process each sample\n",
    "    samples = ['Aarm', 'Aflu', 'Barm', 'Bflu']\n",
    "    gene_adatas = []\n",
    "    protein_adatas = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        print(f\"Processing sample {sample}\")\n",
    "        \n",
    "        # File paths\n",
    "        matrix_file = raw_data_dir / f\"GSE277081_matrix-{sample}.mtx.gz\"\n",
    "        features_file = raw_data_dir / f\"GSE277081_features-{sample}.tsv.gz\"\n",
    "        barcodes_file = raw_data_dir / f\"GSE277081_barcodes-{sample}.tsv.gz\"\n",
    "        \n",
    "        # Read the data\n",
    "        matrix, features_df, barcodes = read_10x_mtx(matrix_file, features_file, barcodes_file)\n",
    "        \n",
    "        # Split gene expression and protein expression\n",
    "        gene_mask = features_df['feature_type'] == 'Gene Expression'\n",
    "        protein_mask = features_df['feature_type'] == 'Antibody Capture'\n",
    "        \n",
    "        # Create gene expression AnnData\n",
    "        if gene_mask.any():\n",
    "            gene_indices = np.where(gene_mask)[0]\n",
    "            gene_matrix = matrix[gene_indices, :]\n",
    "            gene_features = features_df.loc[gene_mask, 'feature_name'].values\n",
    "            gene_ids = features_df.loc[gene_mask, 'feature_id'].values\n",
    "            \n",
    "            # Check for duplicate gene names\n",
    "            gene_name_counts = pd.Series(gene_features).value_counts()\n",
    "            duplicated_genes = gene_name_counts[gene_name_counts > 1].index.tolist()\n",
    "            \n",
    "            if duplicated_genes:\n",
    "                print(f\"Found {len(duplicated_genes)} duplicated gene names. Appending unique identifiers.\")\n",
    "                for gene in duplicated_genes:\n",
    "                    dup_indices = np.where(gene_features == gene)[0]\n",
    "                    for i, idx in enumerate(dup_indices):\n",
    "                        gene_features[idx] = f\"{gene}_{i+1}\"\n",
    "            \n",
    "            # Create var DataFrame with gene IDs and names\n",
    "            var_df = pd.DataFrame({\n",
    "                'gene_id': gene_ids,\n",
    "                'gene_name': gene_features\n",
    "            }, index=gene_features)\n",
    "            \n",
    "            gene_adata = ad.AnnData(\n",
    "                X=gene_matrix.T,\n",
    "                obs=pd.DataFrame(index=barcodes),\n",
    "                var=var_df\n",
    "            )\n",
    "            \n",
    "            # Add sample metadata\n",
    "            gene_adata.obs['sample'] = sample\n",
    "            gene_adata.obs['replicate'] = sample[0]  # A or B\n",
    "            gene_adata.obs['condition'] = 'LCMV Armstrong' if 'arm' in sample.lower() else 'Influenza PR8'\n",
    "            \n",
    "            gene_adatas.append(gene_adata)\n",
    "        \n",
    "        # Create protein expression AnnData\n",
    "        if protein_mask.any():\n",
    "            protein_indices = np.where(protein_mask)[0]\n",
    "            protein_matrix = matrix[protein_indices, :]\n",
    "            protein_features = features_df.loc[protein_mask, 'feature_name'].values\n",
    "            protein_ids = features_df.loc[protein_mask, 'feature_id'].values\n",
    "            \n",
    "            # Create var DataFrame with protein IDs and names\n",
    "            var_df = pd.DataFrame({\n",
    "                'protein_id': protein_ids,\n",
    "                'protein_name': protein_features\n",
    "            }, index=protein_features)\n",
    "            \n",
    "            protein_adata = ad.AnnData(\n",
    "                X=protein_matrix.T,\n",
    "                obs=pd.DataFrame(index=barcodes),\n",
    "                var=var_df\n",
    "            )\n",
    "            \n",
    "            # Add sample metadata\n",
    "            protein_adata.obs['sample'] = sample\n",
    "            protein_adata.obs['replicate'] = sample[0]  # A or B\n",
    "            protein_adata.obs['condition'] = 'LCMV Armstrong' if 'arm' in sample.lower() else 'Influenza PR8'\n",
    "            \n",
    "            protein_adatas.append(protein_adata)\n",
    "    \n",
    "    # Combine all samples\n",
    "    print(\"Combining all samples\")\n",
    "    \n",
    "    # Make cell barcodes unique by adding sample prefix\n",
    "    for i, adata in enumerate(gene_adatas):\n",
    "        sample = samples[i]\n",
    "        adata.obs.index = [f\"{sample}_{bc}\" for bc in adata.obs.index]\n",
    "    \n",
    "    for i, adata in enumerate(protein_adatas):\n",
    "        sample = samples[i]\n",
    "        adata.obs.index = [f\"{sample}_{bc}\" for bc in adata.obs.index]\n",
    "    \n",
    "    # Concatenate the data\n",
    "    gene_adata = ad.concat(gene_adatas, join='outer')\n",
    "    protein_adata = ad.concat(protein_adatas, join='outer')\n",
    "    \n",
    "    # Find common barcodes between gene and protein data\n",
    "    common_barcodes = np.intersect1d(gene_adata.obs.index, protein_adata.obs.index)\n",
    "    print(f\"Found {len(common_barcodes)} common barcodes between gene and protein data\")\n",
    "    \n",
    "    # Subset to common barcodes\n",
    "    gene_adata = gene_adata[gene_adata.obs.index.isin(common_barcodes)].copy()\n",
    "    protein_adata = protein_adata[protein_adata.obs.index.isin(common_barcodes)].copy()\n",
    "    \n",
    "    # Ensure the same order of cells in both datasets\n",
    "    gene_adata = gene_adata[protein_adata.obs.index].copy()\n",
    "    \n",
    "    # Extract additional metadata from protein expression\n",
    "    extract_metadata_from_proteins(gene_adata, protein_adata)\n",
    "    \n",
    "    # Harmonize metadata\n",
    "    harmonize_metadata(gene_adata, protein_adata)\n",
    "    \n",
    "    return gene_adata, protein_adata\n",
    "\n",
    "def extract_metadata_from_proteins(gene_adata, protein_adata):\n",
    "    \"\"\"\n",
    "    Extract additional metadata from protein expression data.\n",
    "    \n",
    "    Args:\n",
    "        gene_adata (AnnData): Gene expression data\n",
    "        protein_adata (AnnData): Protein expression data\n",
    "    \"\"\"\n",
    "    # Extract metadata from protein expression\n",
    "    # These are based on the protein markers in the dataset\n",
    "    metadata_markers = {\n",
    "        'CD103': 'tissue_residency',\n",
    "        'CD69': 'activation',\n",
    "        'LY6C': 'effector_memory',\n",
    "        'CD127': 'memory',\n",
    "        'CD62L': 'central_memory',\n",
    "        'KLRG1': 'terminal_effector',\n",
    "        'CX3CR1': 'migration',\n",
    "        'IV Ab': 'intravascular',\n",
    "        'HOST': 'host_origin',\n",
    "        'DONOR': 'donor_origin'\n",
    "    }\n",
    "    \n",
    "    # Add protein expression as metadata\n",
    "    for protein, metadata_name in metadata_markers.items():\n",
    "        if protein in protein_adata.var_names:\n",
    "            protein_idx = protein_adata.var_names.get_loc(protein)\n",
    "            # Extract the column from the sparse matrix\n",
    "            if sp.issparse(protein_adata.X):\n",
    "                values = protein_adata.X[:, protein_idx].toarray().flatten()\n",
    "            else:\n",
    "                values = protein_adata.X[:, protein_idx]\n",
    "            \n",
    "            gene_adata.obs[metadata_name] = values\n",
    "            protein_adata.obs[metadata_name] = values\n",
    "\n",
    "def harmonize_metadata(gene_adata, protein_adata):\n",
    "    \"\"\"\n",
    "    Harmonize metadata for both gene and protein expression data.\n",
    "    \n",
    "    Args:\n",
    "        gene_adata (AnnData): Gene expression data\n",
    "        protein_adata (AnnData): Protein expression data\n",
    "    \"\"\"\n",
    "    # Add standard metadata fields\n",
    "    for adata in [gene_adata, protein_adata]:\n",
    "        # Organism\n",
    "        adata.obs['organism'] = 'Mus musculus'\n",
    "        \n",
    "        # Cell type - all cells are CD8+ T cells\n",
    "        adata.obs['cell_type'] = 'CD8+ T cell'\n",
    "        \n",
    "        # CRISPR type - not applicable for this dataset\n",
    "        adata.obs['crispr_type'] = 'None'\n",
    "        \n",
    "        # Cancer type - not applicable for this dataset\n",
    "        adata.obs['cancer_type'] = 'Non-Cancer'\n",
    "        \n",
    "        # Condition - already set, but let's add more details\n",
    "        adata.obs['condition'] = adata.obs['condition'].astype(str) + ' infection'\n",
    "        \n",
    "        # Perturbation name - not applicable for this dataset\n",
    "        adata.obs['perturbation_name'] = 'None'\n",
    "        \n",
    "        # Add tissue information based on hashtag oligos if available\n",
    "        if 'tissue_residency' in adata.obs:\n",
    "            # Simplify to binary tissue residency status\n",
    "            adata.obs['tissue_resident'] = (adata.obs['tissue_residency'] > adata.obs['tissue_residency'].median()).astype(str)\n",
    "        \n",
    "        # Convert categorical columns\n",
    "        for col in ['organism', 'cell_type', 'crispr_type', 'cancer_type', 'condition', 'perturbation_name', 'sample', 'replicate']:\n",
    "            if col in adata.obs:\n",
    "                adata.obs[col] = adata.obs[col].astype('category')\n",
    "\n",
    "def save_anndata(adata, output_file):\n",
    "    \"\"\"\n",
    "    Save AnnData object to h5ad file.\n",
    "    \n",
    "    Args:\n",
    "        adata (AnnData): AnnData object to save\n",
    "        output_file (Path): Output file path\n",
    "    \"\"\"\n",
    "    print(f\"Saving {output_file}\")\n",
    "    adata.write_h5ad(output_file, compression='gzip')\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for Jupyter Notebook.\"\"\"\n",
    "    # Set the data root to the current working directory\n",
    "    data_root = Path.cwd()\n",
    "    print(f\"Using data root path: {data_root}\")\n",
    "    \n",
    "    # Process the dataset\n",
    "    gene_adata, protein_adata = process_dataset(data_root)\n",
    "    \n",
    "    # Print summary of the data\n",
    "    print(\"\\nGene expression data summary:\")\n",
    "    print(f\"Number of cells: {gene_adata.n_obs}\")\n",
    "    print(f\"Number of genes: {gene_adata.n_vars}\")\n",
    "    print(f\"Metadata columns: {list(gene_adata.obs.columns)}\")\n",
    "    \n",
    "    print(\"\\nProtein expression data summary:\")\n",
    "    print(f\"Number of cells: {protein_adata.n_obs}\")\n",
    "    print(f\"Number of proteins: {protein_adata.n_vars}\")\n",
    "    print(f\"Metadata columns: {list(protein_adata.obs.columns)}\")\n",
    "    \n",
    "    # Save the results\n",
    "    save_anndata(gene_adata, data_root / \"GSE277081_gene_expression_harmonized.h5ad\")\n",
    "    save_anndata(protein_adata, data_root / \"GSE277081_protein_expression_harmonized.h5ad\")\n",
    "    \n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "# Run the main function directly in the notebook\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
