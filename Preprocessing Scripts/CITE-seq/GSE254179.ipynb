{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import gzip\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def download_dataset(output_dir):\n",
    "    \"\"\"\n",
    "    Download the GSE254179 dataset if not already present.\n",
    "    \n",
    "    Args:\n",
    "        output_dir (str): Directory to save the downloaded data\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the extracted data directory\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    tar_file = output_dir / \"GSE254179_RAW.tar\"\n",
    "    extract_dir = output_dir / \"GSE254179\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Download the dataset if it doesn't exist\n",
    "    if not tar_file.exists():\n",
    "        print(f\"Downloading GSE254179 dataset to {tar_file}...\")\n",
    "        url = \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE254179&format=file\"\n",
    "        urllib.request.urlretrieve(url, tar_file)\n",
    "        print(\"Download complete.\")\n",
    "    else:\n",
    "        print(f\"Dataset already downloaded at {tar_file}\")\n",
    "    \n",
    "    # Extract the dataset if it hasn't been extracted\n",
    "    if not extract_dir.exists() or not any(extract_dir.iterdir()):\n",
    "        print(f\"Extracting dataset to {extract_dir}...\")\n",
    "        os.makedirs(extract_dir, exist_ok=True)\n",
    "        with tarfile.open(tar_file, 'r') as tar:\n",
    "            tar.extractall(path=extract_dir)\n",
    "        print(\"Extraction complete.\")\n",
    "    else:\n",
    "        print(f\"Dataset already extracted at {extract_dir}\")\n",
    "    \n",
    "    return extract_dir\n",
    "\n",
    "def find_paired_data(data_dir):\n",
    "    \"\"\"\n",
    "    Find paired gene expression and protein expression data files.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Directory containing the dataset files\n",
    "    \n",
    "    Returns:\n",
    "        list: List of tuples containing (gene_file, cite_file, feature_ref_file, sample_id)\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    gene_expr_files = []\n",
    "    cite_seq_files = []\n",
    "    feature_ref_files = {}\n",
    "    \n",
    "    # Pattern to match sample identifiers\n",
    "    pattern = re.compile(r'GSM\\d+_(.+?)_(?:GEX|Cite|feature_reference)')\n",
    "    \n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith('_filtered_feature_bc_matrix.h5'):\n",
    "            if 'GEX' in file:\n",
    "                gene_expr_files.append(file)\n",
    "            elif 'Cite' in file:\n",
    "                cite_seq_files.append(file)\n",
    "        elif file.endswith('_feature_reference.csv.gz'):\n",
    "            # Extract the sample identifier\n",
    "            match = pattern.search(file)\n",
    "            if match:\n",
    "                sample_id = match.group(1)\n",
    "                feature_ref_files[sample_id] = file\n",
    "    \n",
    "    # Find paired samples\n",
    "    paired_samples = []\n",
    "    for gene_file in gene_expr_files:\n",
    "        gene_match = pattern.search(gene_file)\n",
    "        if gene_match:\n",
    "            gene_sample_id = gene_match.group(1)\n",
    "            for cite_file in cite_seq_files:\n",
    "                cite_match = pattern.search(cite_file)\n",
    "                if cite_match and cite_match.group(1) == gene_sample_id:\n",
    "                    feature_ref = feature_ref_files.get(gene_sample_id, None)\n",
    "                    paired_samples.append((\n",
    "                        str(data_dir / gene_file),\n",
    "                        str(data_dir / cite_file),\n",
    "                        str(data_dir / feature_ref) if feature_ref else None,\n",
    "                        gene_sample_id\n",
    "                    ))\n",
    "    \n",
    "    return paired_samples\n",
    "\n",
    "def read_10x_h5(file_path):\n",
    "    \"\"\"\n",
    "    Read a 10x Genomics h5 file and return an AnnData object.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the h5 file\n",
    "    \n",
    "    Returns:\n",
    "        anndata.AnnData: AnnData object containing the data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try using scanpy's read_10x_h5 function first\n",
    "        adata = sc.read_10x_h5(file_path)\n",
    "        print(f\"  Successfully read {file_path} using scanpy.read_10x_h5\")\n",
    "        \n",
    "        # Add feature metadata if not already present\n",
    "        if 'feature_types' not in adata.var:\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                if 'matrix' in f and 'features' in f['matrix'] and 'feature_type' in f['matrix']['features']:\n",
    "                    feature_types = f['matrix']['features']['feature_type'][:]\n",
    "                    feature_types = [ft.decode('utf-8') if isinstance(ft, bytes) else ft for ft in feature_types]\n",
    "                    adata.var['feature_type'] = feature_types\n",
    "        \n",
    "        return adata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error using scanpy.read_10x_h5: {e}\")\n",
    "        print(\"  Falling back to manual h5 reading...\")\n",
    "        \n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            # Read barcodes\n",
    "            barcodes = f['matrix']['barcodes'][:]\n",
    "            barcodes = [bc.decode('utf-8') if isinstance(bc, bytes) else bc for bc in barcodes]\n",
    "            \n",
    "            # Read features\n",
    "            feature_ids = f['matrix']['features']['id'][:]\n",
    "            feature_ids = [id.decode('utf-8') if isinstance(id, bytes) else id for id in feature_ids]\n",
    "            \n",
    "            feature_names = f['matrix']['features']['name'][:]\n",
    "            feature_names = [name.decode('utf-8') if isinstance(name, bytes) else name for name in feature_names]\n",
    "            \n",
    "            feature_types = f['matrix']['features']['feature_type'][:]\n",
    "            feature_types = [ft.decode('utf-8') if isinstance(ft, bytes) else ft for ft in feature_types]\n",
    "            \n",
    "            # Read genome if available\n",
    "            if 'genome' in f['matrix']['features']:\n",
    "                genome = f['matrix']['features']['genome'][:]\n",
    "                genome = [g.decode('utf-8') if isinstance(g, bytes) else g for g in genome]\n",
    "            else:\n",
    "                genome = ['Unknown'] * len(feature_ids)\n",
    "            \n",
    "            # Read sparse matrix data\n",
    "            data = f['matrix']['data'][:]\n",
    "            indices = f['matrix']['indices'][:]\n",
    "            indptr = f['matrix']['indptr'][:]\n",
    "            shape = f['matrix']['shape'][:]\n",
    "            \n",
    "            # Create sparse matrix - transpose to match scanpy's convention\n",
    "            matrix = sparse.csr_matrix((data, indices, indptr), shape=(shape[1], shape[0])).T\n",
    "            \n",
    "            # Create feature metadata\n",
    "            var = pd.DataFrame({\n",
    "                'feature_id': feature_ids,\n",
    "                'feature_name': feature_names,\n",
    "                'feature_type': feature_types,\n",
    "                'genome': genome\n",
    "            })\n",
    "            var.index = var['feature_name']\n",
    "            \n",
    "            # Create AnnData object\n",
    "            adata = ad.AnnData(X=matrix, var=var)\n",
    "            adata.obs_names = barcodes\n",
    "            \n",
    "            return adata\n",
    "\n",
    "def read_feature_reference(file_path):\n",
    "    \"\"\"\n",
    "    Read a feature reference file and return a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the feature reference file\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing the feature reference data\n",
    "    \"\"\"\n",
    "    if file_path is None:\n",
    "        return None\n",
    "    \n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        # Check if the file uses semicolons as separators\n",
    "        first_line = f.readline()\n",
    "        f.seek(0)\n",
    "        \n",
    "        if ';' in first_line:\n",
    "            sep = ';'\n",
    "        else:\n",
    "            sep = ','\n",
    "        \n",
    "        feature_ref = pd.read_csv(f, sep=sep)\n",
    "        \n",
    "        # Clean up column names if they contain separators\n",
    "        if any(';' in col for col in feature_ref.columns):\n",
    "            feature_ref.columns = [col.split(';')[0] for col in feature_ref.columns]\n",
    "        \n",
    "        return feature_ref\n",
    "\n",
    "def process_paired_data(gene_file, cite_file, feature_ref_file, sample_id):\n",
    "    \"\"\"\n",
    "    Process paired gene expression and protein expression data.\n",
    "    \n",
    "    Args:\n",
    "        gene_file (str): Path to the gene expression h5 file\n",
    "        cite_file (str): Path to the CITE-seq h5 file\n",
    "        feature_ref_file (str): Path to the feature reference file\n",
    "        sample_id (str): Sample identifier\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (gene_adata, protein_adata) - AnnData objects for gene and protein expression\n",
    "    \"\"\"\n",
    "    print(f\"Processing sample: {sample_id}\")\n",
    "    \n",
    "    # Read gene expression data\n",
    "    gene_adata = read_10x_h5(gene_file)\n",
    "    print(f\"  Gene expression data: {gene_adata.shape[0]} cells, {gene_adata.shape[1]} genes\")\n",
    "    \n",
    "    # Read protein expression data\n",
    "    protein_adata = read_10x_h5(cite_file)\n",
    "    \n",
    "    # Read feature reference data\n",
    "    feature_ref = read_feature_reference(feature_ref_file)\n",
    "    if feature_ref is not None:\n",
    "        print(f\"  Feature reference data: {feature_ref.shape[0]} features\")\n",
    "        \n",
    "        # If protein_adata has no features, create it from the feature reference\n",
    "        if protein_adata.shape[1] == 0 and feature_ref is not None:\n",
    "            print(\"  Creating protein expression data from feature reference\")\n",
    "            \n",
    "            # Create a new AnnData object with the correct features\n",
    "            with h5py.File(cite_file, 'r') as f:\n",
    "                # Read barcodes\n",
    "                barcodes = f['matrix']['barcodes'][:]\n",
    "                barcodes = [bc.decode('utf-8') if isinstance(bc, bytes) else bc for bc in barcodes]\n",
    "                \n",
    "                # Read sparse matrix data\n",
    "                data = f['matrix']['data'][:]\n",
    "                indices = f['matrix']['indices'][:]\n",
    "                indptr = f['matrix']['indptr'][:]\n",
    "                shape = f['matrix']['shape'][:]\n",
    "                \n",
    "                # Create sparse matrix with the correct shape\n",
    "                n_cells = len(barcodes)\n",
    "                n_features = len(feature_ref)\n",
    "                matrix = sparse.csr_matrix((data, indices, indptr), shape=(n_cells, n_features))\n",
    "                \n",
    "                # Create feature metadata from feature reference\n",
    "                var = pd.DataFrame({\n",
    "                    'feature_id': feature_ref['id'].values,\n",
    "                    'feature_name': feature_ref['name'].values,\n",
    "                    'feature_type': feature_ref['feature_type'].values if 'feature_type' in feature_ref.columns else ['Antibody Capture'] * len(feature_ref)\n",
    "                })\n",
    "                var.index = var['feature_name']\n",
    "                \n",
    "                # Create AnnData object\n",
    "                protein_adata = ad.AnnData(X=matrix, var=var)\n",
    "                protein_adata.obs_names = barcodes\n",
    "    \n",
    "    print(f\"  Protein expression data: {protein_adata.shape[0]} cells, {protein_adata.shape[1]} proteins\")\n",
    "    \n",
    "    # Find common barcodes\n",
    "    common_barcodes = set(gene_adata.obs_names).intersection(set(protein_adata.obs_names))\n",
    "    print(f\"  Common barcodes: {len(common_barcodes)}\")\n",
    "    \n",
    "    # Filter to keep only common barcodes\n",
    "    gene_adata = gene_adata[list(common_barcodes)].copy()\n",
    "    protein_adata = protein_adata[list(common_barcodes)].copy()\n",
    "    \n",
    "    # Add sample_id to obs\n",
    "    gene_adata.obs['sample_id'] = sample_id\n",
    "    protein_adata.obs['sample_id'] = sample_id\n",
    "    \n",
    "    # Add metadata based on sample_id\n",
    "    add_metadata(gene_adata, sample_id)\n",
    "    add_metadata(protein_adata, sample_id)\n",
    "    \n",
    "    return gene_adata, protein_adata\n",
    "\n",
    "def add_metadata(adata, sample_id):\n",
    "    \"\"\"\n",
    "    Add standardized metadata to the AnnData object based on the sample ID.\n",
    "    \n",
    "    Args:\n",
    "        adata (anndata.AnnData): AnnData object to add metadata to\n",
    "        sample_id (str): Sample identifier\n",
    "    \"\"\"\n",
    "    # Set organism\n",
    "    adata.obs['organism'] = 'Homo sapiens'\n",
    "    \n",
    "    # Set cell_type based on sample_id\n",
    "    if 'Covid_T' in sample_id:\n",
    "        adata.obs['cell_type'] = 'T Cells'\n",
    "        adata.obs['condition'] = 'SARS-CoV-2 specific'\n",
    "        adata.obs['perturbation_name'] = 'SARS-CoV-2'\n",
    "    elif 'CMV' in sample_id:\n",
    "        adata.obs['cell_type'] = 'T Cells'\n",
    "        adata.obs['condition'] = 'CMV specific'\n",
    "        adata.obs['perturbation_name'] = 'CMV'\n",
    "    elif 'EBV' in sample_id:\n",
    "        adata.obs['cell_type'] = 'T Cells'\n",
    "        adata.obs['condition'] = 'EBV specific'\n",
    "        adata.obs['perturbation_name'] = 'EBV'\n",
    "    elif 'plasmablasts' in sample_id:\n",
    "        adata.obs['cell_type'] = 'Plasmablasts'\n",
    "        adata.obs['condition'] = 'MIS-C'\n",
    "        adata.obs['perturbation_name'] = 'SARS-CoV-2'\n",
    "    elif 'Pool' in sample_id:\n",
    "        if 'PosMP' in sample_id:\n",
    "            adata.obs['cell_type'] = 'Mixed Immune Cells'\n",
    "            adata.obs['condition'] = 'Post-Methylprednisolone'\n",
    "            adata.obs['perturbation_name'] = 'SARS-CoV-2 + Methylprednisolone'\n",
    "        elif 'PreMP' in sample_id:\n",
    "            adata.obs['cell_type'] = 'Mixed Immune Cells'\n",
    "            adata.obs['condition'] = 'Pre-Methylprednisolone'\n",
    "            adata.obs['perturbation_name'] = 'SARS-CoV-2'\n",
    "        elif 'Pool1' in sample_id or 'Pool2' in sample_id or 'Pool3' in sample_id:\n",
    "            adata.obs['cell_type'] = 'Mixed Immune Cells'\n",
    "            adata.obs['condition'] = 'MIS-C'\n",
    "            adata.obs['perturbation_name'] = 'SARS-CoV-2'\n",
    "        elif 'Pool4' in sample_id:\n",
    "            adata.obs['cell_type'] = 'Mixed Immune Cells'\n",
    "            adata.obs['condition'] = 'Post-SARS-CoV-2'\n",
    "            adata.obs['perturbation_name'] = 'SARS-CoV-2'\n",
    "    else:\n",
    "        adata.obs['cell_type'] = 'Unknown'\n",
    "        adata.obs['condition'] = 'Unknown'\n",
    "        adata.obs['perturbation_name'] = 'Unknown'\n",
    "    \n",
    "    # Set cancer_type (all non-cancer in this dataset)\n",
    "    adata.obs['cancer_type'] = 'Non-Cancer'\n",
    "    \n",
    "    # Set CRISPR type (not applicable for this dataset)\n",
    "    adata.obs['crispr_type'] = 'None'\n",
    "\n",
    "def harmonize_gene_names(adata):\n",
    "    \"\"\"\n",
    "    Ensure gene names are based on gene symbols.\n",
    "    \n",
    "    Args:\n",
    "        adata (anndata.AnnData): AnnData object to harmonize gene names\n",
    "    \n",
    "    Returns:\n",
    "        anndata.AnnData: AnnData object with harmonized gene names\n",
    "    \"\"\"\n",
    "    # Check if we have ENSEMBL IDs as feature_ids and gene symbols as feature_names\n",
    "    if 'feature_id' in adata.var and 'feature_name' in adata.var:\n",
    "        if adata.var['feature_id'].iloc[0].startswith('ENSG'):\n",
    "            adata.var_names = adata.var['feature_name']\n",
    "            print(\"  Using gene symbols as var_names\")\n",
    "    elif 'gene_ids' in adata.var and 'gene_symbols' in adata.var:\n",
    "        if adata.var['gene_ids'].iloc[0].startswith('ENSG'):\n",
    "            adata.var_names = adata.var['gene_symbols']\n",
    "            print(\"  Using gene symbols as var_names\")\n",
    "    \n",
    "    if adata.var_names.duplicated().any():\n",
    "        print(f\"  Found {adata.var_names.duplicated().sum()} duplicate gene names\")\n",
    "        if 'feature_id' in adata.var:\n",
    "            adata.var_names = adata.var_names + '_' + adata.var['feature_id']\n",
    "            adata.var_names = adata.var_names.map(lambda x: x.split('_ENSG')[0] + '_' + x.split('ENSG')[1] if 'ENSG' in x else x)\n",
    "        elif 'gene_ids' in adata.var:\n",
    "            adata.var_names = adata.var_names + '_' + adata.var['gene_ids']\n",
    "            adata.var_names = adata.var_names.map(lambda x: x.split('_ENSG')[0] + '_' + x.split('ENSG')[1] if 'ENSG' in x else x)\n",
    "        else:\n",
    "            adata.var_names = make_index_unique(adata.var_names)\n",
    "        \n",
    "        if adata.var_names.duplicated().any():\n",
    "            print(f\"  Still have {adata.var_names.duplicated().sum()} duplicate gene names after first attempt\")\n",
    "            adata.var_names = make_index_unique(adata.var_names)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def make_index_unique(index):\n",
    "    \"\"\"\n",
    "    Make a pandas Index unique by appending a suffix to duplicates.\n",
    "    \n",
    "    Args:\n",
    "        index (pandas.Index): Index to make unique\n",
    "    \n",
    "    Returns:\n",
    "        pandas.Index: Unique index\n",
    "    \"\"\"\n",
    "    counts = {}\n",
    "    new_index = []\n",
    "    \n",
    "    for idx in index:\n",
    "        if idx in counts:\n",
    "            counts[idx] += 1\n",
    "            new_index.append(f\"{idx}_{counts[idx]}\")\n",
    "        else:\n",
    "            counts[idx] = 0\n",
    "            new_index.append(idx)\n",
    "    \n",
    "    return pd.Index(new_index)\n",
    "\n",
    "def main(data_dir=None):\n",
    "    \"\"\"\n",
    "    Main function to process the GSE254179 dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str, optional): Directory containing the dataset files.\n",
    "            If None, the dataset will be downloaded to the current working directory.\n",
    "    \"\"\"\n",
    "    if data_dir is None:\n",
    "        data_dir = os.getcwd()\n",
    "    \n",
    "    # Download the dataset if needed\n",
    "    data_dir = download_dataset(data_dir)\n",
    "    \n",
    "    # Find paired data\n",
    "    paired_samples = find_paired_data(data_dir)\n",
    "    print(f\"Found {len(paired_samples)} paired samples\")\n",
    "    \n",
    "    if not paired_samples:\n",
    "        print(\"No paired samples found. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Process each paired sample\n",
    "    for gene_file, cite_file, feature_ref_file, sample_id in paired_samples:\n",
    "        gene_adata, protein_adata = process_paired_data(gene_file, cite_file, feature_ref_file, sample_id)\n",
    "        \n",
    "        # Harmonize gene names\n",
    "        gene_adata = harmonize_gene_names(gene_adata)\n",
    "        \n",
    "        # Save the harmonized data\n",
    "        output_dir = os.path.join(os.path.dirname(str(data_dir)), \"harmonized\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        gene_output_file = os.path.join(output_dir, f\"{sample_id}_gene_expression.h5ad\")\n",
    "        protein_output_file = os.path.join(output_dir, f\"{sample_id}_protein_expression.h5ad\")\n",
    "        \n",
    "        print(f\"Saving gene expression data to {gene_output_file}\")\n",
    "        gene_adata.write_h5ad(gene_output_file)\n",
    "        \n",
    "        print(f\"Saving protein expression data to {protein_output_file}\")\n",
    "        protein_adata.write_h5ad(protein_output_file)\n",
    "        \n",
    "        print(f\"Processed {sample_id} successfully\")\n",
    "\n",
    "# For Jupyter, simply call main() in a separate cell or at the end of this cell.\n",
    "# If you want to specify a data directory, pass it as an argument (e.g., main('/path/to/data'))\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
