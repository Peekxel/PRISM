{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import gzip\n",
    "import tarfile\n",
    "import re\n",
    "import urllib.request\n",
    "from typing import Dict, List, Tuple, Set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "from anndata import AnnData\n",
    "\n",
    "# Constants\n",
    "GEO_ACCESSION = \"GSE253865\"\n",
    "DOWNLOAD_URL = f\"https://www.ncbi.nlm.nih.gov/geo/download/?acc={GEO_ACCESSION}&format=file\"\n",
    "TAR_FILENAME = f\"{GEO_ACCESSION}_RAW.tar\"\n",
    "\n",
    "\n",
    "def download_data(data_dir: str) -> str:\n",
    "    \"\"\"\n",
    "    Download the dataset if not already present.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory to save the data.\n",
    "        \n",
    "    Returns:\n",
    "        Path to the downloaded tar file.\n",
    "    \"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    tar_path = os.path.join(data_dir, TAR_FILENAME)\n",
    "    \n",
    "    # Check if files are already extracted\n",
    "    if glob.glob(os.path.join(data_dir, \"GSM*\")):\n",
    "        print(\"Files already extracted, skipping download and extraction.\")\n",
    "        return tar_path\n",
    "    \n",
    "    if not os.path.exists(tar_path):\n",
    "        print(f\"Downloading {GEO_ACCESSION} dataset...\")\n",
    "        urllib.request.urlretrieve(DOWNLOAD_URL, tar_path)\n",
    "        print(f\"Download complete: {tar_path}\")\n",
    "    else:\n",
    "        print(f\"Dataset already downloaded: {tar_path}\")\n",
    "    \n",
    "    # Extract if not already extracted\n",
    "    if not glob.glob(os.path.join(data_dir, \"GSM*\")):\n",
    "        print(\"Extracting tar file...\")\n",
    "        try:\n",
    "            with tarfile.open(tar_path, 'r') as tar:\n",
    "                tar.extractall(path=data_dir)\n",
    "            print(\"Extraction complete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting tar file: {e}\")\n",
    "            print(\"Continuing with existing files...\")\n",
    "    \n",
    "    return tar_path\n",
    "\n",
    "\n",
    "def get_sample_files(data_dir: str) -> Dict[str, Dict[str, List[str]]]:\n",
    "    \"\"\"\n",
    "    Get all sample files organized by sample type and file type.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the data files.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of sample files organized by sample type and file type.\n",
    "    \"\"\"\n",
    "    sample_files = {\n",
    "        \"cell\": {\"barcodes\": [], \"features\": [], \"matrix\": []},\n",
    "        \"nucleus\": {\"barcodes\": [], \"features\": [], \"matrix\": []},\n",
    "        \"CITE\": {\"barcodes\": [], \"features\": [], \"matrix\": []}\n",
    "    }\n",
    "    \n",
    "    for file_path in glob.glob(os.path.join(data_dir, \"GSM*\")):\n",
    "        file_name = os.path.basename(file_path)\n",
    "        \n",
    "        if \"_cell_\" in file_name:\n",
    "            sample_type = \"cell\"\n",
    "        elif \"_nucleus_\" in file_name:\n",
    "            sample_type = \"nucleus\"\n",
    "        elif \"_CITE_\" in file_name:\n",
    "            sample_type = \"CITE\"\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if \"barcodes\" in file_name:\n",
    "            sample_files[sample_type][\"barcodes\"].append(file_path)\n",
    "        elif \"features\" in file_name:\n",
    "            sample_files[sample_type][\"features\"].append(file_path)\n",
    "        elif \"matrix\" in file_name:\n",
    "            sample_files[sample_type][\"matrix\"].append(file_path)\n",
    "    \n",
    "    # Sort files to ensure a consistent order\n",
    "    for s_type in sample_files:\n",
    "        for f_type in sample_files[s_type]:\n",
    "            sample_files[s_type][f_type].sort()\n",
    "    \n",
    "    return sample_files\n",
    "\n",
    "\n",
    "def extract_sample_metadata(file_path: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Extract sample metadata from a file path.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the file.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of sample metadata.\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    # Extract GSM accession\n",
    "    gsm_match = re.search(r'(GSM\\d+)', file_name)\n",
    "    gsm_accession = gsm_match.group(1) if gsm_match else \"Unknown\"\n",
    "    \n",
    "    # Extract sample ID\n",
    "    sample_id_match = re.search(r'_(cell|nucleus|CITE)_([A-Za-z0-9]+)', file_name)\n",
    "    sample_id = sample_id_match.group(2) if sample_id_match else \"Unknown\"\n",
    "    \n",
    "    # Extract sample type\n",
    "    sample_type_match = re.search(r'_(cell|nucleus|CITE)_', file_name)\n",
    "    sample_type = sample_type_match.group(1) if sample_type_match else \"Unknown\"\n",
    "    \n",
    "    # Extract patient ID\n",
    "    patient_id = \"Unknown\"\n",
    "    if sample_id.startswith(\"KDP\"):\n",
    "        patient_id = f\"NB00{sample_id[3:]}\" if len(sample_id) > 3 else \"Unknown\"\n",
    "    elif sample_id.startswith(\"CS\"):\n",
    "        patient_id = \"NB003\"\n",
    "    elif sample_id.startswith(\"NBO\"):\n",
    "        patient_id = sample_id\n",
    "    \n",
    "    return {\n",
    "        \"gsm_accession\": gsm_accession,\n",
    "        \"sample_id\": sample_id,\n",
    "        \"sample_type\": sample_type,\n",
    "        \"patient_id\": patient_id\n",
    "    }\n",
    "\n",
    "\n",
    "def load_10x_data(matrix_file: str, features_file: str, barcodes_file: str) -> Tuple[sparse.csr_matrix, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load 10x data from matrix, features, and barcodes files.\n",
    "    \n",
    "    Args:\n",
    "        matrix_file: Path to matrix.mtx.gz file.\n",
    "        features_file: Path to features.tsv.gz file.\n",
    "        barcodes_file: Path to barcodes.tsv.gz file.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (matrix, features, barcodes).\n",
    "    \"\"\"\n",
    "    # Load matrix\n",
    "    matrix = sc.read_mtx(matrix_file).X.T\n",
    "    \n",
    "    # Load features\n",
    "    with gzip.open(features_file, 'rt') as f:\n",
    "        features_df = pd.read_csv(f, sep='\\t', header=None)\n",
    "        if features_df.shape[1] == 3:\n",
    "            features_df.columns = ['id', 'name', 'feature_type']\n",
    "        else:\n",
    "            features_df.columns = ['id', 'name']\n",
    "            features_df['feature_type'] = 'Gene Expression'\n",
    "    \n",
    "    # Load barcodes\n",
    "    with gzip.open(barcodes_file, 'rt') as f:\n",
    "        barcodes_df = pd.read_csv(f, sep='\\t', header=None)\n",
    "        barcodes_df.columns = ['barcode']\n",
    "    \n",
    "    # Extract sample metadata\n",
    "    sample_metadata = extract_sample_metadata(matrix_file)\n",
    "    \n",
    "    # Add sample metadata to barcodes\n",
    "    for key, value in sample_metadata.items():\n",
    "        barcodes_df[key] = value\n",
    "    \n",
    "    # Create full barcode with sample ID\n",
    "    barcodes_df['full_barcode'] = barcodes_df['barcode'] + '_' + barcodes_df['sample_id']\n",
    "    \n",
    "    return matrix, features_df, barcodes_df\n",
    "\n",
    "\n",
    "def process_cite_seq_data(data_dir: str, sample_files: Dict[str, Dict[str, List[str]]]) -> Tuple[AnnData, AnnData]:\n",
    "    \"\"\"\n",
    "    Process CITE-seq data to create gene expression and protein expression AnnData objects.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the data files.\n",
    "        sample_files: Dictionary of sample files organized by sample type and file type.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (gene_expression_adata, protein_expression_adata).\n",
    "    \"\"\"\n",
    "    # Get CITE-seq files\n",
    "    barcodes_files = sample_files[\"CITE\"][\"barcodes\"]\n",
    "    features_files = sample_files[\"CITE\"][\"features\"]\n",
    "    matrix_files = sample_files[\"CITE\"][\"matrix\"]\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    gene_matrices = []\n",
    "    protein_matrices = []\n",
    "    gene_features_list = []\n",
    "    protein_features_list = []\n",
    "    barcodes_list = []\n",
    "    \n",
    "    # Process each CITE-seq sample\n",
    "    for i, (matrix_file, features_file, barcodes_file) in enumerate(zip(matrix_files, features_files, barcodes_files)):\n",
    "        print(f\"Processing CITE-seq sample {i+1}/{len(matrix_files)}: {os.path.basename(matrix_file)}\")\n",
    "        \n",
    "        # Load data\n",
    "        matrix, features_df, barcodes_df = load_10x_data(matrix_file, features_file, barcodes_file)\n",
    "        \n",
    "        # Split gene expression and protein expression\n",
    "        gene_mask = (features_df['feature_type'] == 'Gene Expression').values\n",
    "        protein_mask = (features_df['feature_type'] == 'Antibody Capture').values\n",
    "        \n",
    "        gene_matrix = matrix[:, gene_mask]\n",
    "        protein_matrix = matrix[:, protein_mask]\n",
    "        \n",
    "        gene_features = features_df[gene_mask].copy()\n",
    "        protein_features = features_df[protein_mask].copy()\n",
    "        \n",
    "        # Store\n",
    "        gene_matrices.append(gene_matrix)\n",
    "        protein_matrices.append(protein_matrix)\n",
    "        gene_features_list.append(gene_features)\n",
    "        protein_features_list.append(protein_features)\n",
    "        barcodes_list.append(barcodes_df)\n",
    "    \n",
    "    # Find common genes and proteins across all samples\n",
    "    gene_feature_sets = [set(df['name']) for df in gene_features_list]\n",
    "    common_genes = set.intersection(*gene_feature_sets)\n",
    "    print(f\"Number of common genes across CITE-seq samples: {len(common_genes)}\")\n",
    "    \n",
    "    protein_feature_sets = [set(df['name']) for df in protein_features_list]\n",
    "    common_proteins = set.intersection(*protein_feature_sets)\n",
    "    print(f\"Number of common proteins across CITE-seq samples: {len(common_proteins)}\")\n",
    "    \n",
    "    # Create a unified gene feature DataFrame with common genes\n",
    "    unified_gene_features = gene_features_list[0][gene_features_list[0]['name'].isin(common_genes)].copy()\n",
    "    unified_gene_features = unified_gene_features.drop_duplicates(subset=['name']).reset_index(drop=True)\n",
    "    \n",
    "    # Create a unified protein feature DataFrame with common proteins\n",
    "    unified_protein_features = protein_features_list[0][protein_features_list[0]['name'].isin(common_proteins)].copy()\n",
    "    unified_protein_features = unified_protein_features.drop_duplicates(subset=['name']).reset_index(drop=True)\n",
    "    \n",
    "    # Concatenate all barcodes and remove duplicates\n",
    "    all_barcodes = pd.concat(barcodes_list, axis=0)\n",
    "    all_barcodes = all_barcodes.drop_duplicates(subset=['full_barcode']).reset_index(drop=True)\n",
    "    \n",
    "    # Create AnnData objects for gene and protein expression\n",
    "    gene_adata = create_anndata_from_samples(\n",
    "        matrices=gene_matrices,\n",
    "        features_list=gene_features_list,\n",
    "        barcodes_list=barcodes_list,\n",
    "        common_features=common_genes,\n",
    "        unified_features=unified_gene_features,\n",
    "        all_barcodes=all_barcodes,\n",
    "        feature_type='gene'\n",
    "    )\n",
    "    \n",
    "    protein_adata = create_anndata_from_samples(\n",
    "        matrices=protein_matrices,\n",
    "        features_list=protein_features_list,\n",
    "        barcodes_list=barcodes_list,\n",
    "        common_features=common_proteins,\n",
    "        unified_features=unified_protein_features,\n",
    "        all_barcodes=all_barcodes,\n",
    "        feature_type='protein'\n",
    "    )\n",
    "    \n",
    "    # Ensure only paired data (common barcodes across gene and protein)\n",
    "    common_barcodes = list(set(gene_adata.obs_names).intersection(set(protein_adata.obs_names)))\n",
    "    gene_adata = gene_adata[common_barcodes, :]\n",
    "    protein_adata = protein_adata[common_barcodes, :]\n",
    "    \n",
    "    print(f\"Final gene expression data shape: {gene_adata.shape}\")\n",
    "    print(f\"Final protein expression data shape: {protein_adata.shape}\")\n",
    "    \n",
    "    return gene_adata, protein_adata\n",
    "\n",
    "\n",
    "def create_anndata_from_samples(\n",
    "    matrices: List[sparse.csr_matrix],\n",
    "    features_list: List[pd.DataFrame],\n",
    "    barcodes_list: List[pd.DataFrame],\n",
    "    common_features: Set[str],\n",
    "    unified_features: pd.DataFrame,\n",
    "    all_barcodes: pd.DataFrame,\n",
    "    feature_type: str\n",
    ") -> AnnData:\n",
    "    \"\"\"\n",
    "    Create an AnnData object from multiple samples using an efficient approach.\n",
    "    \n",
    "    Args:\n",
    "        matrices: List of matrices for each sample.\n",
    "        features_list: List of feature DataFrames for each sample.\n",
    "        barcodes_list: List of barcode DataFrames for each sample.\n",
    "        common_features: Set of common features across all samples.\n",
    "        unified_features: Unified feature DataFrame with just the common features.\n",
    "        all_barcodes: Concatenated barcode DataFrame for all samples.\n",
    "        feature_type: 'gene' or 'protein'.\n",
    "        \n",
    "    Returns:\n",
    "        AnnData object with all samples concatenated.\n",
    "    \"\"\"\n",
    "    print(f\"  Creating {feature_type} AnnData object from {len(matrices)} samples.\")\n",
    "    \n",
    "    # Create a mapping from barcode to row index\n",
    "    barcode_to_idx = {bc: i for i, bc in enumerate(all_barcodes['full_barcode'])}\n",
    "    \n",
    "    # Create a mapping from feature name to column index\n",
    "    feature_to_idx = {feature: i for i, feature in enumerate(unified_features['name'])}\n",
    "    \n",
    "    # Final shape\n",
    "    n_cells = len(all_barcodes)\n",
    "    n_features = len(unified_features)\n",
    "    \n",
    "    # Prepare arrays for constructing the sparse matrix\n",
    "    data = []\n",
    "    row_indices = []\n",
    "    col_indices = []\n",
    "    \n",
    "    # Process each sample\n",
    "    for sample_idx, (matrix, features_df, barcodes_df) in enumerate(zip(matrices, features_list, barcodes_list)):\n",
    "        print(f\"  Processing sample {sample_idx+1}/{len(matrices)}...\")\n",
    "        \n",
    "        # Create mappings for this sample\n",
    "        feature_name_to_idx = {name: i for i, name in enumerate(features_df['name'])}\n",
    "        barcode_to_global_idx = {\n",
    "            bc: barcode_to_idx[full_bc]\n",
    "            for bc, full_bc in zip(barcodes_df['barcode'], barcodes_df['full_barcode'])\n",
    "            if full_bc in barcode_to_idx\n",
    "        }\n",
    "        \n",
    "        if not barcode_to_global_idx:\n",
    "            continue\n",
    "        \n",
    "        # Find common features for this sample\n",
    "        feature_indices = np.array([feature_name_to_idx.get(name, -1) for name in common_features])\n",
    "        valid_feature_mask = feature_indices >= 0\n",
    "        feature_indices = feature_indices[valid_feature_mask]\n",
    "        \n",
    "        # Corresponding unified indices\n",
    "        unified_indices = np.array([feature_to_idx.get(name, -1) for name in common_features])\n",
    "        unified_indices = unified_indices[valid_feature_mask]\n",
    "        \n",
    "        # Get the valid barcodes\n",
    "        valid_barcodes = [bc for bc in barcodes_df['barcode'] if bc in barcode_to_global_idx]\n",
    "        barcode_to_local_idx = {bc: i for i, bc in enumerate(barcodes_df['barcode'])}\n",
    "        cell_indices = np.array([barcode_to_local_idx.get(bc, -1) for bc in valid_barcodes])\n",
    "        \n",
    "        if len(cell_indices) == 0 or len(feature_indices) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Extract submatrix with only these cells and features\n",
    "        submatrix = matrix[cell_indices, :][:, feature_indices]\n",
    "        \n",
    "        # Convert to COO for easy iteration\n",
    "        coo = submatrix.tocoo()\n",
    "        \n",
    "        # Map local row/col to global\n",
    "        for i, j, v in zip(coo.row, coo.col, coo.data):\n",
    "            global_row = barcode_to_global_idx[valid_barcodes[i]]\n",
    "            global_col = unified_indices[j]\n",
    "            \n",
    "            data.append(v)\n",
    "            row_indices.append(global_row)\n",
    "            col_indices.append(global_col)\n",
    "    \n",
    "    # Construct the final sparse matrix\n",
    "    X = sparse.csr_matrix((data, (row_indices, col_indices)), shape=(n_cells, n_features))\n",
    "    \n",
    "    # Create AnnData object\n",
    "    adata = AnnData(X=X)\n",
    "    adata.obs_names = all_barcodes['full_barcode'].values\n",
    "    adata.var_names = unified_features['name'].values\n",
    "    \n",
    "    # Add feature metadata\n",
    "    if feature_type == 'gene':\n",
    "        adata.var['gene_id'] = unified_features['id'].values\n",
    "        adata.var['feature_type'] = unified_features['feature_type'].values\n",
    "    else:\n",
    "        adata.var['protein_id'] = unified_features['id'].values\n",
    "        adata.var['feature_type'] = unified_features['feature_type'].values\n",
    "    \n",
    "    # Add cell metadata\n",
    "    for col in all_barcodes.columns:\n",
    "        if col != 'full_barcode':\n",
    "            adata.obs[col] = all_barcodes[col].values\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def harmonize_metadata(adata: AnnData, data_type: str) -> AnnData:\n",
    "    \"\"\"\n",
    "    Harmonize metadata according to a specified format, and clean protein var_names.\n",
    "    \n",
    "    Args:\n",
    "        adata: AnnData object to harmonize.\n",
    "        data_type: 'gene' or 'protein'.\n",
    "        \n",
    "    Returns:\n",
    "        Harmonized AnnData object.\n",
    "    \"\"\"\n",
    "    # Add some relevant metadata fields\n",
    "    adata.obs['organism'] = 'Homo sapiens'\n",
    "    adata.obs['cell_type'] = 'Neuroblastoma'  \n",
    "    adata.obs['crispr_type'] = 'None'  \n",
    "    adata.obs['cancer_type'] = 'Neuroblastoma'\n",
    "    adata.obs['condition'] = 'Control'  \n",
    "    adata.obs['perturbation_name'] = 'None'  \n",
    "    \n",
    "    # Additional metadata\n",
    "    adata.obs['data_type'] = data_type\n",
    "    adata.obs['study_accession'] = GEO_ACCESSION\n",
    "    \n",
    "    # If it's gene data, ensure var_names are gene symbols if possible\n",
    "    if data_type == 'gene':\n",
    "        # Heuristic check if the var names look like Ensembl IDs\n",
    "        if all(name.startswith('ENSG') for name in adata.var_names):\n",
    "            # If so, we assume `adata.var['name']` has the gene symbols:\n",
    "            adata.var_names = adata.var['name'].values\n",
    "        \n",
    "        # Remove duplicated gene names if any\n",
    "        if adata.var_names.duplicated().any():\n",
    "            print(f\"Found {adata.var_names.duplicated().sum()} duplicate gene names, removing duplicates.\")\n",
    "            adata = adata[:, ~adata.var_names.duplicated()].copy()\n",
    "    \n",
    "    elif data_type == 'protein':\n",
    "        # Remove suffixes (underscore + everything after)\n",
    "        new_names = [re.sub(r\"_.*$\", \"\", n) for n in adata.var_names]\n",
    "        adata.var_names = new_names\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def main(data_dir: str = None):\n",
    "    \"\"\"\n",
    "    Main function to process and harmonize the dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory to save and process the data.\n",
    "    \"\"\"\n",
    "    if data_dir is None:\n",
    "        data_dir = os.path.join(os.getcwd(), GEO_ACCESSION)\n",
    "    \n",
    "    # 1. Download data (if not present)\n",
    "    download_data(data_dir)\n",
    "    \n",
    "    # 2. Identify and group sample files\n",
    "    sample_files = get_sample_files(data_dir)\n",
    "    \n",
    "    # 3. Process CITE-seq data (if available)\n",
    "    if sample_files[\"CITE\"][\"barcodes\"]:\n",
    "        print(\"Processing CITE-seq data...\")\n",
    "        gene_adata, protein_adata = process_cite_seq_data(data_dir, sample_files)\n",
    "        \n",
    "        # 4. Harmonize metadata\n",
    "        gene_adata = harmonize_metadata(gene_adata, 'gene')\n",
    "        protein_adata = harmonize_metadata(protein_adata, 'protein')\n",
    "        \n",
    "        # 5. Save outputs\n",
    "        gene_output_path = os.path.join(data_dir, f\"{GEO_ACCESSION}_gene_expression.h5ad\")\n",
    "        protein_output_path = os.path.join(data_dir, f\"{GEO_ACCESSION}_protein_expression.h5ad\")\n",
    "        \n",
    "        print(f\"Saving gene expression data to: {gene_output_path}\")\n",
    "        gene_adata.write(gene_output_path, compression='gzip')\n",
    "        \n",
    "        print(f\"Saving protein expression data to: {protein_output_path}\")\n",
    "        protein_adata.write(protein_output_path, compression='gzip')\n",
    "        \n",
    "        print(\"Processing complete!\")\n",
    "        print(f\"Gene expression data shape: {gene_adata.shape}\")\n",
    "        print(f\"Protein expression data shape: {protein_adata.shape}\")\n",
    "    else:\n",
    "        print(\"No CITE-seq data found.\")\n",
    "\n",
    "\n",
    "# In a Jupyter notebook, run all cells to define these functions,\n",
    "# then simply call main() to use the default directory, or specify a path:\n",
    "main(\"/content/GSE253865\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
