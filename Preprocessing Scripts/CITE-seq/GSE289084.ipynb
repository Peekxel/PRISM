{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import anndata as ad\n",
    "\n",
    "# URLs for the dataset files\n",
    "URLS = {\n",
    "    \"barcodes\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE289nnn/GSE289084/suppl/GSE289084_pbmc_barcodes.tsv.gz\",\n",
    "    \"features\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE289nnn/GSE289084/suppl/GSE289084_pbmc_features.tsv.gz\",\n",
    "    \"features_adt\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE289nnn/GSE289084/suppl/GSE289084_pbmc_features_adt.tsv.gz\",\n",
    "    \"matrix\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE289nnn/GSE289084/suppl/GSE289084_pbmc_matrix.tsv.gz\",\n",
    "    \"matrix_adt\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE289nnn/GSE289084/suppl/GSE289084_pbmc_matrix_adt.tsv.gz\",\n",
    "    \"readme\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE289nnn/GSE289084/suppl/GSE289084_Readme_CITESeq_Ab.xlsx\"\n",
    "}\n",
    "\n",
    "def download_file(url, output_path):\n",
    "    \"\"\"Download a file from a URL to the specified output path.\"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        print(f\"Downloading {url} to {output_path}\")\n",
    "        urllib.request.urlretrieve(url, output_path)\n",
    "    else:\n",
    "        print(f\"File already exists: {output_path}\")\n",
    "\n",
    "def download_dataset(data_dir):\n",
    "    \"\"\"Download all dataset files to the specified directory.\"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    for name, url in URLS.items():\n",
    "        output_path = os.path.join(data_dir, os.path.basename(url))\n",
    "        download_file(url, output_path)\n",
    "    \n",
    "    return {name: os.path.join(data_dir, os.path.basename(url)) for name, url in URLS.items()}\n",
    "\n",
    "def parse_barcodes(file_path):\n",
    "    \"\"\"Parse cell barcodes from a gzipped TSV file.\"\"\"\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        barcodes = [line.strip() for line in f]\n",
    "    return barcodes\n",
    "\n",
    "def parse_features(file_path):\n",
    "    \"\"\"Parse gene features from a gzipped TSV file.\"\"\"\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        features = [line.strip() for line in f]\n",
    "    return features\n",
    "\n",
    "def process_chunk(chunk, feature_to_idx, data, row_indices, col_indices):\n",
    "    \"\"\"Process a chunk of lines from the matrix file.\"\"\"\n",
    "    for line in chunk:\n",
    "        parts = line.strip().split('\\t')\n",
    "        feature = parts[0].strip('\"')\n",
    "        \n",
    "        # Skip if feature is not in our features list\n",
    "        if feature not in feature_to_idx:\n",
    "            continue\n",
    "        \n",
    "        feature_idx = feature_to_idx[feature]\n",
    "        \n",
    "        # Process each cell's expression value\n",
    "        for j, val in enumerate(parts[1:]):\n",
    "            try:\n",
    "                val = int(val)\n",
    "                if val > 0:  # Only store non-zero values\n",
    "                    data.append(val)\n",
    "                    row_indices.append(feature_idx)\n",
    "                    col_indices.append(j)\n",
    "            except ValueError:\n",
    "                pass  # Skip non-integer values\n",
    "\n",
    "def parse_matrix_tsv_in_chunks(matrix_path, features_path, barcodes_path, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Parse a matrix from a TSV file in chunks to minimize memory usage.\n",
    "    Returns a sparse matrix in CSR format.\n",
    "    \"\"\"\n",
    "    print(f\"Parsing matrix from {matrix_path}\")\n",
    "    \n",
    "    # Load features and barcodes\n",
    "    features = parse_features(features_path)\n",
    "    barcodes = parse_barcodes(barcodes_path)\n",
    "    \n",
    "    # Create feature index mapping\n",
    "    feature_to_idx = {f: i for i, f in enumerate(features)}\n",
    "    \n",
    "    # Initialize lists for sparse matrix construction\n",
    "    data = []\n",
    "    row_indices = []\n",
    "    col_indices = []\n",
    "    \n",
    "    # Read the matrix file\n",
    "    with gzip.open(matrix_path, 'rt') as f:\n",
    "        # Read header to get cell barcodes\n",
    "        header = f.readline().strip().split('\\t')\n",
    "        header = [h.strip('\"') for h in header[1:]]  # Skip first column and remove quotes\n",
    "        \n",
    "        # Process each line (gene) in chunks\n",
    "        chunk = []\n",
    "        for i, line in enumerate(f):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Processed {i} rows\")\n",
    "            \n",
    "            chunk.append(line)\n",
    "            \n",
    "            if len(chunk) >= chunk_size:\n",
    "                process_chunk(chunk, feature_to_idx, data, row_indices, col_indices)\n",
    "                chunk = []\n",
    "        \n",
    "        # Process any remaining lines\n",
    "        if chunk:\n",
    "            process_chunk(chunk, feature_to_idx, data, row_indices, col_indices)\n",
    "    \n",
    "    # Create a sparse matrix\n",
    "    matrix = sp.csr_matrix((data, (row_indices, col_indices)), \n",
    "                          shape=(len(features), len(header)))\n",
    "    \n",
    "    return matrix, features, header\n",
    "\n",
    "def extract_metadata_from_barcodes(barcodes):\n",
    "    \"\"\"Extract metadata from cell barcodes.\"\"\"\n",
    "    metadata = {}\n",
    "    \n",
    "    # Extract sample IDs and time points\n",
    "    for barcode in barcodes:\n",
    "        parts = barcode.split('-')\n",
    "        sample_id = parts[0]\n",
    "        \n",
    "        # Extract patient ID and time point\n",
    "        if sample_id.startswith('M'):\n",
    "            patient_id = sample_id.split('_')[0]\n",
    "            \n",
    "            # Determine time point (W0 or W6)\n",
    "            if 'week0' in sample_id or '_S1' in sample_id:\n",
    "                time_point = 'W0'\n",
    "            elif 'week6' in sample_id:\n",
    "                time_point = 'W6'\n",
    "            else:\n",
    "                time_point = 'Unknown'\n",
    "            \n",
    "            metadata[barcode] = {\n",
    "                'patient_id': patient_id,\n",
    "                'time_point': time_point,\n",
    "                'sample_id': sample_id\n",
    "            }\n",
    "        else:\n",
    "            metadata[barcode] = {\n",
    "                'patient_id': 'Unknown',\n",
    "                'time_point': 'Unknown',\n",
    "                'sample_id': sample_id\n",
    "            }\n",
    "    \n",
    "    return pd.DataFrame.from_dict(metadata, orient='index')\n",
    "\n",
    "def process_dataset(data_dir):\n",
    "    \"\"\"Process the GSE289084 dataset and return AnnData objects.\"\"\"\n",
    "    # Download the dataset if needed\n",
    "    file_paths = download_dataset(data_dir)\n",
    "    \n",
    "    # Parse matrices\n",
    "    print(\"Parsing gene expression matrix...\")\n",
    "    gene_matrix, gene_features, gene_barcodes = parse_matrix_tsv_in_chunks(\n",
    "        file_paths['matrix'], file_paths['features'], file_paths['barcodes']\n",
    "    )\n",
    "    \n",
    "    print(\"Parsing protein expression matrix...\")\n",
    "    protein_matrix, protein_features, protein_barcodes = parse_matrix_tsv_in_chunks(\n",
    "        file_paths['matrix_adt'], file_paths['features_adt'], file_paths['barcodes']\n",
    "    )\n",
    "    \n",
    "    # Extract metadata from barcodes\n",
    "    print(\"Extracting metadata from barcodes...\")\n",
    "    metadata = extract_metadata_from_barcodes(gene_barcodes)\n",
    "    \n",
    "    # Read the README file to get antibody information\n",
    "    print(\"Reading antibody information...\")\n",
    "    antibody_info = pd.read_excel(file_paths['readme'])\n",
    "    \n",
    "    # Clean up antibody info\n",
    "    antibody_info = antibody_info.iloc[1:, :]  # Skip the header row\n",
    "    antibody_info.columns = ['Category', 'Barcode_ID', 'Target', 'Clone', 'Species', \n",
    "                            'Barcode', 'Reference', 'Company']\n",
    "    \n",
    "    # Create AnnData objects\n",
    "    print(\"Creating AnnData objects...\")\n",
    "    adata_gene = ad.AnnData(gene_matrix.T, obs=metadata)\n",
    "    adata_gene.var_names = gene_features\n",
    "    \n",
    "    adata_protein = ad.AnnData(protein_matrix.T, obs=metadata)\n",
    "    adata_protein.var_names = protein_features\n",
    "    \n",
    "    # Add antibody information to protein AnnData\n",
    "    protein_var_df = pd.DataFrame(index=protein_features)\n",
    "    for _, row in antibody_info.iterrows():\n",
    "        if row['Target'] in protein_features:\n",
    "            for col in antibody_info.columns:\n",
    "                protein_var_df.loc[row['Target'], col] = row[col]\n",
    "    \n",
    "    adata_protein.var = protein_var_df\n",
    "    \n",
    "    # Ensure we only keep cells that have both gene and protein data\n",
    "    common_barcodes = list(set(gene_barcodes).intersection(set(protein_barcodes)))\n",
    "    print(f\"Found {len(common_barcodes)} cells with both gene and protein data\")\n",
    "    \n",
    "    adata_gene = adata_gene[common_barcodes, :]\n",
    "    adata_protein = adata_protein[common_barcodes, :]\n",
    "    \n",
    "    return adata_gene, adata_protein\n",
    "\n",
    "def update_metadata(adata):\n",
    "    \"\"\"Update metadata of an AnnData object with additional annotations.\"\"\"\n",
    "    adata.obs['organism'] = 'Homo sapiens'\n",
    "    adata.obs['cell_type'] = 'PBMC'\n",
    "    adata.obs['crispr_type'] = 'None'\n",
    "    adata.obs['cancer_type'] = 'Melanoma'\n",
    "    adata.obs['condition'] = adata.obs['time_point'].map({\n",
    "        'W0': 'Baseline',\n",
    "        'W6': 'Post-treatment',\n",
    "        'Unknown': 'Unknown'\n",
    "    })\n",
    "    adata.obs['perturbation_name'] = 'nivolumab + ipilimumab'\n",
    "    \n",
    "    # Add dataset information in the uns attribute\n",
    "    adata.uns['dataset_id'] = 'GSE289084'\n",
    "    adata.uns['dataset_name'] = 'MELANFÎ± clinical study'\n",
    "    adata.uns['dataset_description'] = (\n",
    "        'CITE-seq PBMC from 8 advanced melanoma patients taken at baseline (Week 0, W0) '\n",
    "        'and 6 weeks after the initiation of treatment (Week 6, W6) with nivolumab (1mg/kg) '\n",
    "        '+ ipilimumab (3mg/kg).'\n",
    "    )\n",
    "    return adata\n",
    "\n",
    "def harmonize_data(adata_gene, adata_protein):\n",
    "    \"\"\"Harmonize the data into a multimodal AnnData object with RNA as the main modality.\"\"\"\n",
    "    adata = adata_gene.copy()\n",
    "    \n",
    "    # Add protein data as a separate modality\n",
    "    adata.obsm['protein_expression'] = adata_protein.X\n",
    "    \n",
    "    # Add protein feature information\n",
    "    adata.uns['protein_features'] = adata_protein.var_names.tolist()\n",
    "    if hasattr(adata_protein, 'var') and not adata_protein.var.empty:\n",
    "        adata.uns['protein_var'] = adata_protein.var\n",
    "    \n",
    "    # The metadata has already been updated for adata_gene; add any additional fields if needed.\n",
    "    return adata\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to process the dataset and save the results.\"\"\"\n",
    "    # Set the data directory (relative to the current working directory)\n",
    "    data_dir = os.path.join(os.getcwd(), 'GSE289084')\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Processing GSE289084 dataset in {data_dir}\")\n",
    "    \n",
    "    # Process the dataset\n",
    "    adata_gene, adata_protein = process_dataset(data_dir)\n",
    "    \n",
    "    # Update metadata for both gene and protein AnnData objects\n",
    "    adata_gene = update_metadata(adata_gene)\n",
    "    adata_protein = update_metadata(adata_protein)\n",
    "    \n",
    "    # Harmonize the data into a multimodal AnnData object\n",
    "    adata_harmonized = harmonize_data(adata_gene, adata_protein)\n",
    "    \n",
    "    # Save the results\n",
    "    harmonized_path = os.path.join(data_dir, 'GSE289084_harmonized.h5ad')\n",
    "    gene_output_path = os.path.join(data_dir, 'GSE289084_gene_expression.h5ad')\n",
    "    protein_output_path = os.path.join(data_dir, 'GSE289084_protein_expression.h5ad')\n",
    "    \n",
    "    print(f\"Saving harmonized data to {harmonized_path}\")\n",
    "    adata_harmonized.write(harmonized_path)\n",
    "    \n",
    "    print(f\"Saving gene expression data to {gene_output_path}\")\n",
    "    adata_gene.write(gene_output_path)\n",
    "    \n",
    "    print(f\"Saving protein expression data to {protein_output_path}\")\n",
    "    adata_protein.write(protein_output_path)\n",
    "    \n",
    "    print(\"Processing complete!\")\n",
    "\n",
    "# Run the main function directly in the notebook\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
