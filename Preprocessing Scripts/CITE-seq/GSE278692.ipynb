{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "\n",
    "# If you need rpy2 for reading .rds files, uncomment the following:\n",
    "# import rpy2.robjects as robjects\n",
    "# from rpy2.robjects import pandas2ri\n",
    "# from rpy2.robjects.packages import importr\n",
    "# pandas2ri.activate()\n",
    "# base = importr('base')\n",
    "\n",
    "GEO_ACCESSION = 'GSE278692'\n",
    "DATASET_TYPES = ['CRC', 'HNSCC']\n",
    "\n",
    "FILE_URLS = {\n",
    "    'CRC_RNACounts': f'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE278nnn/{GEO_ACCESSION}/suppl/{GEO_ACCESSION}_CRC_CD8TIL_RNACounts.rds.gz',\n",
    "    'HNSCC_RNACounts': f'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE278nnn/{GEO_ACCESSION}/suppl/{GEO_ACCESSION}_HNSCC_CD8TIL_RNACounts.rds.gz',\n",
    "    'CRC_ADTCounts': f'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE278nnn/{GEO_ACCESSION}/suppl/{GEO_ACCESSION}_CRC_CD8TIL_ADTCounts.rds.gz',\n",
    "    'HNSCC_ADTCounts': f'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE278nnn/{GEO_ACCESSION}/suppl/{GEO_ACCESSION}_HNSCC_CD8TIL_ADTCounts.rds.gz',\n",
    "    'CRC_metadata': f'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE278nnn/{GEO_ACCESSION}/suppl/{GEO_ACCESSION}_CRC_CD8TIL_metadata.csv.gz',\n",
    "    'HNSCC_metadata': f'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE278nnn/{GEO_ACCESSION}/suppl/{GEO_ACCESSION}_HNSCC_CD8TIL_metadata.csv.gz',\n",
    "    'feature_reference': f'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE278nnn/{GEO_ACCESSION}/suppl/{GEO_ACCESSION}_feature_reference.csv.gz'\n",
    "}\n",
    "\n",
    "CELL_TYPE_MAP = {\n",
    "    'DP': 'CD39+CD103+ Double Positive CD8+ T cells',\n",
    "    'DN': 'CD39-CD103- Double Negative CD8+ T cells',\n",
    "    'SP39': 'CD39+ Single Positive CD8+ T cells',\n",
    "    'SP103': 'CD103+ Single Positive CD8+ T cells'\n",
    "}\n",
    "\n",
    "STUDY_INFO = {\n",
    "    'geo_accession': GEO_ACCESSION,\n",
    "    'title': 'IL-12 drives the expression of the inhibitory receptor NKG2A on human tumor-reactive CD8 T cells',\n",
    "    'organism': 'Homo sapiens',\n",
    "    'experiment_type': 'Expression profiling by high throughput sequencing'\n",
    "}\n",
    "\n",
    "\n",
    "def robust_download(url, output_path, max_retries=3, chunk_size=8192):\n",
    "    \"\"\"\n",
    "    Download a file from `url` to `output_path` in a more robust way, \n",
    "    retrying up to `max_retries` times if the download fails.\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"File already exists: {output_path}\")\n",
    "        return\n",
    "\n",
    "    attempts = 0\n",
    "    while attempts < max_retries:\n",
    "        attempts += 1\n",
    "        try:\n",
    "            print(f\"Downloading (attempt {attempts}/{max_retries}): {url}\")\n",
    "            with requests.get(url, stream=True, timeout=30) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(output_path, \"wb\") as f:\n",
    "                    for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                        if chunk:  # filter out keep-alive new chunks\n",
    "                            f.write(chunk)\n",
    "            # If we get here, download succeeded\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Download failed: {e}\")\n",
    "            if attempts == max_retries:\n",
    "                raise RuntimeError(f\"Failed to download {url} after {max_retries} attempts\")\n",
    "\n",
    "    # If it's a gzipped file, automatically decompress it (unless it's .h5ad.gz)\n",
    "    if output_path.endswith('.gz') and not output_path.endswith('.h5ad.gz'):\n",
    "        decompressed_path = output_path[:-3]  # remove .gz\n",
    "        print(f\"Decompressing {output_path} -> {decompressed_path}\")\n",
    "        with gzip.open(output_path, 'rb') as f_in:\n",
    "            with open(decompressed_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        print(f\"Decompressed to {decompressed_path}\")\n",
    "\n",
    "\n",
    "def download_dataset(data_dir):\n",
    "    \"\"\"Download the GSE278692 dataset files (if not already present).\"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    for name, url in FILE_URLS.items():\n",
    "        out_path = os.path.join(data_dir, os.path.basename(url))\n",
    "        robust_download(url, out_path)\n",
    "\n",
    "\n",
    "def extract_rds_matrix(rds_path):\n",
    "    \"\"\"\n",
    "    Extract a matrix from an RDS file using rpy2.\n",
    "    Note: Requires rpy2 and a working R installation.\n",
    "    \"\"\"\n",
    "    import rpy2.robjects as robjects\n",
    "\n",
    "    # Load the RDS file\n",
    "    rds_obj = robjects.r['readRDS'](rds_path)\n",
    "    \n",
    "    # Extract dimensions\n",
    "    dims = robjects.r['dim'](rds_obj)\n",
    "    n_features, n_cells = dims[0], dims[1]\n",
    "    \n",
    "    # Extract row/column names\n",
    "    features = list(robjects.r['rownames'](rds_obj))\n",
    "    barcodes = list(robjects.r['colnames'](rds_obj))\n",
    "    \n",
    "    # R function to extract the sparse components\n",
    "    robjects.r('''\n",
    "    extract_sparse_matrix <- function(mat) {\n",
    "        list(\n",
    "            i = mat@i,\n",
    "            p = mat@p,\n",
    "            x = mat@x,\n",
    "            dim = dim(mat)\n",
    "        )\n",
    "    }\n",
    "    ''')\n",
    "    sparse_components = robjects.r['extract_sparse_matrix'](rds_obj)\n",
    "    i = np.array(sparse_components.rx2('i'))\n",
    "    p = np.array(sparse_components.rx2('p'))\n",
    "    x = np.array(sparse_components.rx2('x'))\n",
    "    \n",
    "    # Construct scipy CSC matrix\n",
    "    matrix = sparse.csc_matrix((x, i, p), shape=(n_features, n_cells))\n",
    "    return matrix, features, barcodes\n",
    "\n",
    "\n",
    "def process_dataset(data_dir, dataset_type):\n",
    "    \"\"\"Process and return (gene_adata, protein_adata) for the specified dataset_type.\"\"\"\n",
    "    print(f\"Processing {dataset_type} dataset...\")\n",
    "\n",
    "    rna_path = os.path.join(data_dir, f\"{GEO_ACCESSION}_{dataset_type}_CD8TIL_RNACounts.rds\")\n",
    "    adt_path = os.path.join(data_dir, f\"{GEO_ACCESSION}_{dataset_type}_CD8TIL_ADTCounts.rds\")\n",
    "    metadata_path = os.path.join(data_dir, f\"{GEO_ACCESSION}_{dataset_type}_CD8TIL_metadata.csv\")\n",
    "\n",
    "    # Make sure decompressed versions exist if only .gz was downloaded\n",
    "    for fp in [rna_path, adt_path, metadata_path]:\n",
    "        gz_fp = fp + \".gz\"\n",
    "        if not os.path.exists(fp) and os.path.exists(gz_fp):\n",
    "            print(f\"Decompressing {gz_fp}\")\n",
    "            try:\n",
    "                with gzip.open(gz_fp, 'rb') as f_in, open(fp, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Failed to decompress {gz_fp}: {e}\")\n",
    "\n",
    "    # Load metadata\n",
    "    if not os.path.exists(metadata_path):\n",
    "        print(f\"Warning: metadata not found at {metadata_path}\")\n",
    "        metadata = pd.DataFrame()\n",
    "    else:\n",
    "        metadata = pd.read_csv(metadata_path)\n",
    "        print(f\"Loaded metadata with {len(metadata)} entries.\")\n",
    "\n",
    "    # Extract RNA data\n",
    "    gene_adata = None\n",
    "    if os.path.exists(rna_path):\n",
    "        try:\n",
    "            rna_matrix, rna_features, rna_barcodes = extract_rds_matrix(rna_path)\n",
    "            print(f\"RNA data shape: {rna_matrix.shape}\")\n",
    "            gene_adata = ad.AnnData(\n",
    "                X=rna_matrix.T, \n",
    "                var=pd.DataFrame(index=rna_features)\n",
    "            )\n",
    "            gene_adata.var['gene_symbol'] = rna_features\n",
    "            gene_adata.obs_names = rna_barcodes\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting RNA from {rna_path}: {e}\")\n",
    "\n",
    "    # Extract ADT data\n",
    "    protein_adata = None\n",
    "    if os.path.exists(adt_path):\n",
    "        try:\n",
    "            adt_matrix, adt_features, adt_barcodes = extract_rds_matrix(adt_path)\n",
    "            print(f\"ADT data shape: {adt_matrix.shape}\")\n",
    "            # Build an AnnData for proteins\n",
    "            protein_var = pd.DataFrame(index=adt_features)\n",
    "            protein_var['feature_type'] = 'Antibody Capture'\n",
    "            protein_var['target'] = adt_features\n",
    "\n",
    "            protein_adata = ad.AnnData(\n",
    "                X=adt_matrix.T,\n",
    "                var=protein_var\n",
    "            )\n",
    "            protein_adata.obs_names = adt_barcodes\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting ADT from {adt_path}: {e}\")\n",
    "\n",
    "    # Harmonize the metadata into gene_adata\n",
    "    if gene_adata is not None and not metadata.empty:\n",
    "        if 'barcode' in metadata.columns:\n",
    "            metadata_indexed = metadata.set_index('barcode')\n",
    "            common_cells = set(gene_adata.obs_names).intersection(metadata_indexed.index)\n",
    "            print(f\"{len(common_cells)} common cells between gene data and metadata.\")\n",
    "            # Subset gene_adata to common cells\n",
    "            gene_adata = gene_adata[list(common_cells)].copy()\n",
    "            # Build harmonized metadata\n",
    "            harmonized_metadata = pd.DataFrame(index=gene_adata.obs_names)\n",
    "            harmonized_metadata['barcode'] = gene_adata.obs_names\n",
    "            harmonized_metadata['organism'] = 'Homo sapiens'\n",
    "            harmonized_metadata['cancer_type'] = (\n",
    "                'Colorectal Cancer' if dataset_type=='CRC' else 'Head and Neck Squamous Cell Carcinoma'\n",
    "            )\n",
    "            # Transfer columns from metadata\n",
    "            for col in metadata_indexed.columns:\n",
    "                if col in ['barcode']:\n",
    "                    continue\n",
    "                # fill from metadata, ensuring order\n",
    "                harmonized_metadata[col] = metadata_indexed.loc[gene_adata.obs_names, col].values\n",
    "\n",
    "            # Add cell_type from subgroup (if present)\n",
    "            if 'subgroup' in harmonized_metadata.columns:\n",
    "                harmonized_metadata['cell_type'] = (\n",
    "                    harmonized_metadata['subgroup']\n",
    "                    .map(lambda x: CELL_TYPE_MAP.get(str(x), 'CD8+ T cells') if pd.notna(x) else 'CD8+ T cells')\n",
    "                )\n",
    "            else:\n",
    "                harmonized_metadata['cell_type'] = 'CD8+ T cells'\n",
    "\n",
    "            # Additional required columns\n",
    "            if 'patient' in harmonized_metadata.columns:\n",
    "                harmonized_metadata['condition'] = harmonized_metadata['patient']\n",
    "            else:\n",
    "                harmonized_metadata['condition'] = '0'\n",
    "\n",
    "            harmonized_metadata['perturbation_name'] = 'None'\n",
    "            harmonized_metadata['crispr_type'] = 'None'\n",
    "\n",
    "            gene_adata.obs = harmonized_metadata\n",
    "\n",
    "    # If both gene & protein exist, align them\n",
    "    if gene_adata is not None and protein_adata is not None:\n",
    "        common_cells = set(gene_adata.obs_names).intersection(protein_adata.obs_names)\n",
    "        print(f\"{len(common_cells)} cells intersect gene and protein data.\")\n",
    "        gene_adata = gene_adata[list(common_cells)].copy()\n",
    "        protein_adata = protein_adata[list(common_cells)].copy()\n",
    "        # copy metadata\n",
    "        protein_adata.obs = gene_adata.obs.copy()\n",
    "\n",
    "    return gene_adata, protein_adata\n",
    "\n",
    "\n",
    "def run_harmonization(data_dir, no_download=False):\n",
    "    \"\"\"Complete harmonization workflow.\"\"\"\n",
    "    if not no_download:\n",
    "        download_dataset(data_dir)\n",
    "\n",
    "    gene_adatas, protein_adatas = {}, {}\n",
    "\n",
    "    for ds_type in DATASET_TYPES:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"Processing: {ds_type}\")\n",
    "        print(\"=\"*80)\n",
    "        g_adata, p_adata = process_dataset(data_dir, ds_type)\n",
    "        gene_adatas[ds_type] = g_adata\n",
    "        protein_adatas[ds_type] = p_adata\n",
    "\n",
    "    # Saving results\n",
    "    output_dir = os.path.join(data_dir, 'harmonized')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Saving individual datasets\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for ds_type in DATASET_TYPES:\n",
    "        g_adata = gene_adatas[ds_type]\n",
    "        p_adata = protein_adatas[ds_type]\n",
    "        if g_adata is not None:\n",
    "            g_fp = os.path.join(output_dir, f\"{GEO_ACCESSION}_{ds_type}_gene_expression.h5ad\")\n",
    "            print(f\"Saving gene expression for {ds_type} -> {g_fp}\")\n",
    "            g_adata.write_h5ad(g_fp)\n",
    "        if p_adata is not None:\n",
    "            p_fp = os.path.join(output_dir, f\"{GEO_ACCESSION}_{ds_type}_protein_expression.h5ad\")\n",
    "            print(f\"Saving protein expression for {ds_type} -> {p_fp}\")\n",
    "            p_adata.write_h5ad(p_fp)\n",
    "\n",
    "    # Combine across CRC / HNSCC\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Creating combined datasets\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Combine gene expression\n",
    "    valid_g_adatas = []\n",
    "    for ds_type in DATASET_TYPES:\n",
    "        g_adata = gene_adatas[ds_type]\n",
    "        if g_adata is not None:\n",
    "            # Make obs names unique per dataset\n",
    "            g_adata.obs['dataset_type'] = ds_type\n",
    "            g_adata.obs_names = [f\"{ds_type}_{x}\" for x in g_adata.obs_names]\n",
    "            g_adata.obs['barcode'] = g_adata.obs_names\n",
    "            if len(set(g_adata.var_names)) < len(g_adata.var_names):\n",
    "                g_adata.var_names_make_unique()\n",
    "            valid_g_adatas.append(g_adata)\n",
    "    if valid_g_adatas:\n",
    "        print(\"Combining gene expression AnnData objects...\")\n",
    "        combined_g_adata = ad.concat(valid_g_adatas, join='outer', merge='same')\n",
    "        combined_g_adata.uns['study_info'] = STUDY_INFO\n",
    "        combined_g_fp = os.path.join(output_dir, f\"{GEO_ACCESSION}_combined_gene_expression.h5ad\")\n",
    "        print(f\"Writing combined gene expression -> {combined_g_fp}\")\n",
    "        combined_g_adata.write_h5ad(combined_g_fp)\n",
    "    else:\n",
    "        combined_g_adata = None\n",
    "\n",
    "    # Combine protein\n",
    "    valid_p_adatas = []\n",
    "    for ds_type in DATASET_TYPES:\n",
    "        p_adata = protein_adatas[ds_type]\n",
    "        if p_adata is not None:\n",
    "            p_adata.obs['dataset_type'] = ds_type\n",
    "            p_adata.obs_names = [f\"{ds_type}_{x}\" for x in p_adata.obs_names]\n",
    "            p_adata.obs['barcode'] = p_adata.obs_names\n",
    "            if len(set(p_adata.var_names)) < len(p_adata.var_names):\n",
    "                p_adata.var_names_make_unique()\n",
    "            valid_p_adatas.append(p_adata)\n",
    "    if valid_p_adatas:\n",
    "        print(\"Combining protein AnnData objects...\")\n",
    "        combined_p_adata = ad.concat(valid_p_adatas, join='outer', merge='same')\n",
    "        combined_p_adata.uns['study_info'] = STUDY_INFO\n",
    "        combined_p_fp = os.path.join(output_dir, f\"{GEO_ACCESSION}_combined_protein_expression.h5ad\")\n",
    "        print(f\"Writing combined protein expression -> {combined_p_fp}\")\n",
    "        combined_p_adata.write_h5ad(combined_p_fp)\n",
    "    else:\n",
    "        combined_p_adata = None\n",
    "\n",
    "    # Final summary\n",
    "    print(\"\\nHarmonization complete! Results saved in:\", output_dir)\n",
    "    for ds_type in DATASET_TYPES:\n",
    "        g_adata = gene_adatas[ds_type]\n",
    "        p_adata = protein_adatas[ds_type]\n",
    "        if g_adata is not None:\n",
    "            print(f\"{ds_type} gene: {g_adata.shape}\")\n",
    "        if p_adata is not None:\n",
    "            print(f\"{ds_type} protein: {p_adata.shape}\")\n",
    "    if combined_g_adata is not None:\n",
    "        print(\"Combined gene:\", combined_g_adata.shape)\n",
    "    if combined_p_adata is not None:\n",
    "        print(\"Combined protein:\", combined_p_adata.shape)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Usage within Jupyter:\n",
    "# Set data_dir to desired path, then run `run_harmonization(data_dir, no_download=False)`.\n",
    "data_dir = \"./data_GSE278692\"\n",
    "run_harmonization(data_dir, no_download=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
