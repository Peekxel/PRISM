{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "from scipy.io import mmread\n",
    "\n",
    "def clean_protein_names(protein_names):\n",
    "    \"\"\"\n",
    "    Clean protein names to follow conventional naming by removing:\n",
    "    1. Prefixes like 'Hu.', 'HuMs.', etc.\n",
    "    2. Clone information after '_' (e.g., '_M5E2')\n",
    "    3. Special cases for isotypes and CMO markers\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    protein_names : list\n",
    "        List of protein names to clean\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        Cleaned protein names\n",
    "    \"\"\"\n",
    "    cleaned_names = []\n",
    "    \n",
    "    for name in protein_names:\n",
    "        # Handle CMO markers (Cell Multiplexing Oligos) - keep as is\n",
    "        if name.startswith('CMO'):\n",
    "            cleaned_names.append(name)\n",
    "            continue\n",
    "            \n",
    "        # Handle isotypes - extract just the isotype name\n",
    "        if name.startswith('Isotype_'):\n",
    "            isotype = name.split('_', 1)[1].split('.')[0]\n",
    "            cleaned_names.append(f\"Isotype_{isotype}\")\n",
    "            continue\n",
    "            \n",
    "        # Remove species prefixes (Hu., HuMs., HuMsRt., etc.)\n",
    "        if '.' in name:\n",
    "            parts = name.split('.')\n",
    "            name = parts[-1]\n",
    "            \n",
    "        # Remove clone information after '_'\n",
    "        if '_' in name:\n",
    "            name = name.split('_')[0]\n",
    "            \n",
    "        # Special case for TCR variants\n",
    "        if name.startswith('TCR'):\n",
    "            name = name.replace('.', '')\n",
    "            \n",
    "        # Special case for HLA\n",
    "        if name.startswith('HLA'):\n",
    "            name = name.replace('.', '-')\n",
    "            \n",
    "        # Special case for integrin\n",
    "        if name == 'integrinb7':\n",
    "            name = 'ITGB7'  # conventional name for integrin beta-7\n",
    "            \n",
    "        cleaned_names.append(name)\n",
    "    \n",
    "    return cleaned_names\n",
    "\n",
    "def download_data(accession, output_dir):\n",
    "    \"\"\"\n",
    "    Download GEO dataset if not already present.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    accession : str\n",
    "        GEO accession number\n",
    "    output_dir : str\n",
    "        Directory to save downloaded data\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    tar_file = os.path.join(output_dir, f\"{accession}_RAW.tar\")\n",
    "    \n",
    "    if not os.path.exists(tar_file):\n",
    "        print(f\"Downloading {accession} dataset...\")\n",
    "        url = f\"https://www.ncbi.nlm.nih.gov/geo/download/?acc={accession}&format=file\"\n",
    "        urllib.request.urlretrieve(url, tar_file)\n",
    "        print(f\"Download complete: {tar_file}\")\n",
    "    else:\n",
    "        print(f\"Using existing download: {tar_file}\")\n",
    "    \n",
    "    # Extract if not already extracted\n",
    "    expected_file = os.path.join(output_dir, \"GSM7866650_4h_barcodes.tsv.gz\")\n",
    "    if not os.path.exists(expected_file):\n",
    "        print(f\"Extracting {tar_file}...\")\n",
    "        with tarfile.open(tar_file) as tar:\n",
    "            tar.extractall(path=output_dir)\n",
    "        print(\"Extraction complete\")\n",
    "    else:\n",
    "        print(\"Files already extracted\")\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "def read_mtx_data(base_path, prefix):\n",
    "    \"\"\"\n",
    "    Read 10x data in MTX format.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_path : str\n",
    "        Base directory containing the files\n",
    "    prefix : str\n",
    "        Prefix for the files (e.g., \"GSM7866650_4h\")\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple of (matrix, features, barcodes, timepoint)\n",
    "    \"\"\"\n",
    "    print(f\"Reading {prefix} data...\")\n",
    "    \n",
    "    # File paths\n",
    "    matrix_file = os.path.join(base_path, f\"{prefix}_matrix.mtx.gz\")\n",
    "    features_file = os.path.join(base_path, f\"{prefix}_features.tsv.gz\")\n",
    "    barcodes_file = os.path.join(base_path, f\"{prefix}_barcodes.tsv.gz\")\n",
    "    \n",
    "    # Read the matrix\n",
    "    with gzip.open(matrix_file, 'rb') as f:\n",
    "        matrix = sparse.csr_matrix(mmread(f).T)\n",
    "    \n",
    "    # Read features (genes/proteins)\n",
    "    features = pd.read_csv(features_file, sep='\\t', header=None)\n",
    "    features.columns = ['id', 'name', 'feature_type']\n",
    "    \n",
    "    # Read cell barcodes\n",
    "    barcodes = pd.read_csv(barcodes_file, sep='\\t', header=None)\n",
    "    barcodes.columns = ['barcode']\n",
    "    \n",
    "    # Extract timepoint from prefix\n",
    "    timepoint = prefix.split('_')[1]  # Extract '4h' or '24h'\n",
    "    \n",
    "    # Make barcodes unique by adding timepoint suffix\n",
    "    barcodes['unique_barcode'] = barcodes['barcode'] + \"_\" + timepoint\n",
    "    \n",
    "    return matrix, features, barcodes, timepoint\n",
    "\n",
    "def create_anndata(matrix, features, barcodes, timepoint, feature_type):\n",
    "    \"\"\"\n",
    "    Create AnnData object for either gene or protein data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    matrix : scipy.sparse.csr_matrix\n",
    "        Expression matrix\n",
    "    features : pandas.DataFrame\n",
    "        Feature metadata\n",
    "    barcodes : pandas.DataFrame\n",
    "        Cell barcodes\n",
    "    timepoint : str\n",
    "        Timepoint ('4h' or '24h')\n",
    "    feature_type : str\n",
    "        'Gene Expression' or 'Antibody Capture'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    AnnData object\n",
    "    \"\"\"\n",
    "    # Filter features by type\n",
    "    type_indices = features[features['feature_type'] == feature_type].index\n",
    "    type_features = features.iloc[type_indices].reset_index(drop=True)\n",
    "    \n",
    "    # Subset matrix\n",
    "    type_matrix = matrix[:, type_indices]\n",
    "    \n",
    "    # Handle feature names\n",
    "    feature_names = type_features['name'].values\n",
    "    if len(feature_names) != len(set(feature_names)):\n",
    "        print(f\"Found duplicate {feature_type} names, making them unique...\")\n",
    "        if feature_type == 'Gene Expression':\n",
    "            feature_names = [f\"{name}_{id_}\" for name, id_ in zip(type_features['name'], type_features['id'])]\n",
    "        else:  # Antibody Capture - will use clean_protein_names later\n",
    "            # Just append indices for now to ensure uniqueness\n",
    "            feature_names = [f\"{name}_{i}\" for i, name in enumerate(feature_names)]\n",
    "    \n",
    "    # Create AnnData object with unique indices\n",
    "    adata = ad.AnnData(\n",
    "        X=type_matrix,\n",
    "        obs=pd.DataFrame(index=barcodes['unique_barcode']),\n",
    "        var=pd.DataFrame(index=feature_names)\n",
    "    )\n",
    "    \n",
    "    # Add metadata\n",
    "    adata.obs['original_barcode'] = barcodes['barcode'].values\n",
    "    adata.obs['timepoint'] = timepoint\n",
    "    adata.var['feature_id'] = type_features['id'].values\n",
    "    adata.var['feature_type'] = feature_type\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def clean_protein_adata_names(protein_adata):\n",
    "    \"\"\"\n",
    "    Update protein names in an AnnData object to use conventional naming.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    protein_adata : AnnData\n",
    "        AnnData object with protein expression data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    AnnData\n",
    "        AnnData object with updated protein names\n",
    "    \"\"\"\n",
    "    # Get current protein names (strip any previously added indices)\n",
    "    protein_names = [name.split('_')[0] if '_' in name and name.split('_')[-1].isdigit() \n",
    "                    else name for name in protein_adata.var_names.tolist()]\n",
    "    \n",
    "    # Clean the names\n",
    "    cleaned_names = clean_protein_names(protein_names)\n",
    "    \n",
    "    # Create a mapping dictionary to track which original names map to which cleaned names\n",
    "    name_mapping = {}\n",
    "    \n",
    "    # Handle duplicates to ensure uniqueness\n",
    "    unique_cleaned_names = []\n",
    "    name_counts = {}\n",
    "    \n",
    "    for i, name in enumerate(cleaned_names):\n",
    "        if name in name_counts:\n",
    "            name_counts[name] += 1\n",
    "            unique_name = f\"{name}_{name_counts[name]}\"\n",
    "        else:\n",
    "            name_counts[name] = 0\n",
    "            unique_name = name\n",
    "        \n",
    "        unique_cleaned_names.append(unique_name)\n",
    "        name_mapping[protein_adata.var_names[i]] = unique_name\n",
    "    \n",
    "    # Create a new var DataFrame with updated index\n",
    "    new_var = protein_adata.var.copy()\n",
    "    new_var.index = [name_mapping[name] for name in protein_adata.var_names]\n",
    "    \n",
    "    # Create a new AnnData object with updated var names\n",
    "    cleaned_adata = ad.AnnData(\n",
    "        X=protein_adata.X.copy(),\n",
    "        obs=protein_adata.obs.copy(),\n",
    "        var=new_var,\n",
    "        uns=protein_adata.uns.copy(),\n",
    "        obsm=protein_adata.obsm.copy() if protein_adata.obsm is not None else None,\n",
    "        varm=protein_adata.varm.copy() if protein_adata.varm is not None else None\n",
    "    )\n",
    "    \n",
    "    return cleaned_adata\n",
    "\n",
    "def harmonize_data(adata, data_type):\n",
    "    \"\"\"\n",
    "    Harmonize data according to required standards.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : AnnData\n",
    "        AnnData object to harmonize\n",
    "    data_type : str\n",
    "        Type of data ('gene' or 'protein')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Harmonized AnnData object\n",
    "    \"\"\"\n",
    "    print(f\"Harmonizing {data_type} data...\")\n",
    "    \n",
    "    # Add required metadata fields\n",
    "    adata.obs['organism'] = 'Homo sapiens'\n",
    "    adata.obs['cell_type'] = 'PBMC'  # All cells are PBMCs\n",
    "    adata.obs['crispr_type'] = 'None'  # No CRISPR perturbation in this dataset\n",
    "    adata.obs['cancer_type'] = 'Non-Cancer'  # These are healthy donor PBMCs\n",
    "    \n",
    "    # Extract condition from timepoint\n",
    "    timepoint_map = {\n",
    "        '4h': 'ICI_treatment_4h',\n",
    "        '24h': 'ICI_treatment_24h'\n",
    "    }\n",
    "    adata.obs['condition'] = adata.obs['timepoint'].map(timepoint_map)\n",
    "    \n",
    "    # Set perturbation_name to immune checkpoint inhibitors\n",
    "    adata.obs['perturbation_name'] = 'Immune Checkpoint Inhibitors'\n",
    "    \n",
    "    # Convert to categorical\n",
    "    for col in ['organism', 'cell_type', 'crispr_type', 'cancer_type', 'condition', 'perturbation_name']:\n",
    "        adata.obs[col] = adata.obs[col].astype('category')\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def process_dataset(data_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process the GSE246317 dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dir : str\n",
    "        Directory containing the data files\n",
    "    output_dir : str\n",
    "        Directory to save the processed data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple of (gene_adata, protein_adata)\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Read 4h data\n",
    "    matrix_4h, features_4h, barcodes_4h, timepoint_4h = read_mtx_data(data_dir, \"GSM7866650_4h\")\n",
    "    \n",
    "    # Read 24h data\n",
    "    matrix_24h, features_24h, barcodes_24h, timepoint_24h = read_mtx_data(data_dir, \"GSM7866653_24h\")\n",
    "    \n",
    "    # Create AnnData objects for 4h gene expression and protein\n",
    "    gene_adata_4h = create_anndata(matrix_4h, features_4h, barcodes_4h, timepoint_4h, 'Gene Expression')\n",
    "    protein_adata_4h = create_anndata(matrix_4h, features_4h, barcodes_4h, timepoint_4h, 'Antibody Capture')\n",
    "    \n",
    "    # Create AnnData objects for 24h gene expression and protein\n",
    "    gene_adata_24h = create_anndata(matrix_24h, features_24h, barcodes_24h, timepoint_24h, 'Gene Expression')\n",
    "    protein_adata_24h = create_anndata(matrix_24h, features_24h, barcodes_24h, timepoint_24h, 'Antibody Capture')\n",
    "    \n",
    "    print(f\"Gene expression data (4h): {gene_adata_4h.shape[0]} cells, {gene_adata_4h.shape[1]} genes\")\n",
    "    print(f\"Protein data (4h): {protein_adata_4h.shape[0]} cells, {protein_adata_4h.shape[1]} proteins\")\n",
    "    print(f\"Gene expression data (24h): {gene_adata_24h.shape[0]} cells, {gene_adata_24h.shape[1]} genes\")\n",
    "    print(f\"Protein data (24h): {protein_adata_24h.shape[0]} cells, {protein_adata_24h.shape[1]} proteins\")\n",
    "    \n",
    "    # Verify indices are unique\n",
    "    assert len(gene_adata_4h.obs.index) == len(set(gene_adata_4h.obs.index)), \"4h gene indices not unique\"\n",
    "    assert len(protein_adata_4h.obs.index) == len(set(protein_adata_4h.obs.index)), \"4h protein indices not unique\"\n",
    "    assert len(gene_adata_24h.obs.index) == len(set(gene_adata_24h.obs.index)), \"24h gene indices not unique\"\n",
    "    assert len(protein_adata_24h.obs.index) == len(set(protein_adata_24h.obs.index)), \"24h protein indices not unique\"\n",
    "    \n",
    "    # Concatenate gene data\n",
    "    gene_adata = ad.concat(\n",
    "        [gene_adata_4h, gene_adata_24h],\n",
    "        join='outer',  # Use outer join to include all genes\n",
    "        merge='first'  # Keep first occurrence of overlapping variables\n",
    "    )\n",
    "    \n",
    "    # Concatenate protein data\n",
    "    protein_adata = ad.concat(\n",
    "        [protein_adata_4h, protein_adata_24h],\n",
    "        join='outer',  # Use outer join to include all proteins\n",
    "        merge='first'  # Keep first occurrence of overlapping variables\n",
    "    )\n",
    "    \n",
    "    # Verify indices are unique after concatenation\n",
    "    assert len(gene_adata.obs.index) == len(set(gene_adata.obs.index)), \"Concatenated gene indices not unique\"\n",
    "    assert len(protein_adata.obs.index) == len(set(protein_adata.obs.index)), \"Concatenated protein indices not unique\"\n",
    "    \n",
    "    # Clean protein names to conventional format\n",
    "    protein_adata = clean_protein_adata_names(protein_adata)\n",
    "    \n",
    "    # Verify that all cells have both gene and protein data\n",
    "    common_cells = set(gene_adata.obs.index).intersection(set(protein_adata.obs.index))\n",
    "    print(f\"Common cells between gene and protein data: {len(common_cells)}\")\n",
    "    \n",
    "    # Subset both datasets to common cells\n",
    "    gene_adata = gene_adata[list(common_cells)].copy()\n",
    "    protein_adata = protein_adata[list(common_cells)].copy()\n",
    "    \n",
    "    # Sort both datasets by the same cell order\n",
    "    cell_order = sorted(common_cells)\n",
    "    gene_adata = gene_adata[cell_order].copy()\n",
    "    protein_adata = protein_adata[cell_order].copy()\n",
    "    \n",
    "    # Verify alignment\n",
    "    assert (gene_adata.obs.index == protein_adata.obs.index).all(), \"Indices not aligned after sorting\"\n",
    "    \n",
    "    # Harmonize data\n",
    "    gene_adata = harmonize_data(gene_adata, 'gene')\n",
    "    protein_adata = harmonize_data(protein_adata, 'protein')\n",
    "    \n",
    "    # Add protein data as a layer in gene_adata\n",
    "    gene_adata.obsm['protein_expression'] = protein_adata.X.copy()\n",
    "    \n",
    "    # Store protein names\n",
    "    gene_adata.uns['protein_names'] = protein_adata.var_names.tolist()\n",
    "    \n",
    "    # Save\n",
    "    gene_output_file = os.path.join(output_dir, \"GSE246317_gene_expression.h5ad\")\n",
    "    protein_output_file = os.path.join(output_dir, \"GSE246317_protein_expression.h5ad\")\n",
    "    \n",
    "    print(f\"Saving gene expression data to {gene_output_file}\")\n",
    "    gene_adata.write(gene_output_file)\n",
    "    \n",
    "    print(f\"Saving protein expression data to {protein_output_file}\")\n",
    "    protein_adata.write(protein_output_file)\n",
    "    \n",
    "    print(\"Processing complete!\")\n",
    "    \n",
    "    return gene_adata, protein_adata\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for Jupyter Notebook environment\"\"\"\n",
    "    # Use current working directory as base\n",
    "    script_dir = os.getcwd()\n",
    "    data_dir = os.path.join(script_dir, \"GSE246317\")\n",
    "    output_dir = os.path.join(script_dir, \"processed\")\n",
    "    \n",
    "    # Download and extract data if needed\n",
    "    download_data(\"GSE246317\", data_dir)\n",
    "    \n",
    "    # Process the dataset\n",
    "    gene_adata, protein_adata = process_dataset(data_dir, output_dir)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Gene expression data: {gene_adata.shape[0]} cells, {gene_adata.shape[1]} genes\")\n",
    "    print(f\"Protein expression data: {protein_adata.shape[0]} cells, {protein_adata.shape[1]} proteins\")\n",
    "    \n",
    "    # Print summary of harmonized metadata\n",
    "    print(\"\\nHarmonized metadata summary:\")\n",
    "    for col in ['organism', 'cell_type', 'crispr_type', 'cancer_type', 'condition', 'perturbation_name']:\n",
    "        print(f\"{col}: {gene_adata.obs[col].unique()}\")\n",
    "    \n",
    "    print(f\"\\nOutput files:\")\n",
    "    print(f\"- {os.path.join(output_dir, 'GSE246317_gene_expression.h5ad')}\")\n",
    "    print(f\"- {os.path.join(output_dir, 'GSE246317_protein_expression.h5ad')}\")\n",
    "\n",
    "# Call main directly to run the pipeline in Jupyter Notebook\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
