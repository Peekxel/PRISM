{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import scipy.io\n",
    "import anndata as ad\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "\n",
    "class GSE280853Harmonizer:\n",
    "    \"\"\"Class to harmonize the GSE280853 dataset.\"\"\"\n",
    "    \n",
    "    # GEO accession number\n",
    "    GEO_ACCESSION = \"GSE280853\"\n",
    "    \n",
    "    # URLs for the dataset files\n",
    "    BASE_URL = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE280nnn/GSE280853/suppl/\"\n",
    "    FILES = [\n",
    "        \"GSE280853_sampleAB_feature_reference.csv.gz\",\n",
    "        \"GSE280853_sampleA_barcodes.tsv.gz\",\n",
    "        \"GSE280853_sampleA_features.tsv.gz\",\n",
    "        \"GSE280853_sampleA_matrix.mtx.gz\",\n",
    "        \"GSE280853_sampleB_barcodes.tsv.gz\",\n",
    "        \"GSE280853_sampleB_features.tsv.gz\",\n",
    "        \"GSE280853_sampleB_matrix.mtx.gz\"\n",
    "    ]\n",
    "    \n",
    "    # Sample information\n",
    "    SAMPLE_INFO = {\n",
    "        \"A\": {\n",
    "            \"title\": \"P14, ICD-humanized mouse PD1\",\n",
    "            \"condition\": \"ICD-humanized mouse PD1\",\n",
    "            \"perturbation_name\": \"ICD-humanized mouse PD1\"\n",
    "        },\n",
    "        \"B\": {\n",
    "            \"title\": \"P14, mouse PD1\",\n",
    "            \"condition\": \"wild-type mouse PD1\",\n",
    "            \"perturbation_name\": \"wild-type mouse PD1\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def __init__(self, data_dir: str):\n",
    "        \"\"\"\n",
    "        Initialize the harmonizer.\n",
    "        \n",
    "        Args:\n",
    "            data_dir: Path to the directory where the data is or will be stored.\n",
    "        \"\"\"\n",
    "        self.data_dir = os.path.abspath(data_dir)\n",
    "        os.makedirs(self.data_dir, exist_ok=True)\n",
    "        \n",
    "    def download_files(self) -> None:\n",
    "        \"\"\"Download the dataset files if they don't exist.\"\"\"\n",
    "        for file_name in self.FILES:\n",
    "            file_path = os.path.join(self.data_dir, file_name)\n",
    "            \n",
    "            # Skip if file already exists\n",
    "            if os.path.exists(file_path):\n",
    "                print(f\"File {file_name} already exists. Skipping download.\")\n",
    "                continue\n",
    "            \n",
    "            # Download the file\n",
    "            url = f\"{self.BASE_URL}{file_name}\"\n",
    "            print(f\"Downloading {url}...\")\n",
    "            \n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            total_size = int(response.headers.get('content-length', 0))\n",
    "            block_size = 1024  # 1 Kibibyte\n",
    "            \n",
    "            with open(file_path, 'wb') as f, tqdm(\n",
    "                desc=file_name,\n",
    "                total=total_size,\n",
    "                unit='iB',\n",
    "                unit_scale=True,\n",
    "                unit_divisor=1024,\n",
    "            ) as bar:\n",
    "                for data in response.iter_content(block_size):\n",
    "                    size = f.write(data)\n",
    "                    bar.update(size)\n",
    "    \n",
    "    def extract_files(self) -> None:\n",
    "        \"\"\"Extract the gzipped files.\"\"\"\n",
    "        for file_name in self.FILES:\n",
    "            gz_file_path = os.path.join(self.data_dir, file_name)\n",
    "            out_file_path = os.path.join(self.data_dir, file_name[:-3])  # Remove .gz extension\n",
    "            \n",
    "            # Skip if the extracted file already exists\n",
    "            if os.path.exists(out_file_path):\n",
    "                print(f\"File {out_file_path} already exists. Skipping extraction.\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Extracting {gz_file_path}...\")\n",
    "            with gzip.open(gz_file_path, 'rb') as f_in:\n",
    "                with open(out_file_path, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "    \n",
    "    def read_10x_mtx(self, sample: str) -> Tuple[sp.csr_matrix, pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Read a 10x dataset in MTX format.\n",
    "        \n",
    "        Args:\n",
    "            sample: Sample identifier ('A' or 'B').\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "                - Sparse matrix of expression values\n",
    "                - DataFrame of features\n",
    "                - DataFrame of barcodes\n",
    "        \"\"\"\n",
    "        # File paths\n",
    "        matrix_file = os.path.join(self.data_dir, f\"{self.GEO_ACCESSION}_sample{sample}_matrix.mtx\")\n",
    "        features_file = os.path.join(self.data_dir, f\"{self.GEO_ACCESSION}_sample{sample}_features.tsv\")\n",
    "        barcodes_file = os.path.join(self.data_dir, f\"{self.GEO_ACCESSION}_sample{sample}_barcodes.tsv\")\n",
    "        \n",
    "        # Read the matrix\n",
    "        matrix = scipy.io.mmread(matrix_file).T.tocsr()\n",
    "        \n",
    "        # Read features and barcodes\n",
    "        features = pd.read_csv(features_file, sep='\\t', header=None)\n",
    "        features.columns = ['gene_id', 'gene_name', 'feature_type']\n",
    "        \n",
    "        barcodes = pd.read_csv(barcodes_file, sep='\\t', header=None)\n",
    "        barcodes.columns = ['barcode']\n",
    "        \n",
    "        return matrix, features, barcodes\n",
    "    \n",
    "    def create_anndata(self, sample: str) -> Tuple[ad.AnnData, ad.AnnData]:\n",
    "        \"\"\"\n",
    "        Create AnnData objects for gene expression and protein data.\n",
    "        \n",
    "        Args:\n",
    "            sample: Sample identifier ('A' or 'B').\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "                - AnnData object for gene expression\n",
    "                - AnnData object for protein data\n",
    "        \"\"\"\n",
    "        # Read the data\n",
    "        matrix, features, barcodes = self.read_10x_mtx(sample)\n",
    "        \n",
    "        # Split gene expression and protein data\n",
    "        gene_indices = features[features['feature_type'] == 'Gene Expression'].index\n",
    "        protein_indices = features[features['feature_type'] == 'Antibody Capture'].index\n",
    "        \n",
    "        gene_matrix = matrix[:, gene_indices]\n",
    "        protein_matrix = matrix[:, protein_indices]\n",
    "        \n",
    "        gene_features = features.iloc[gene_indices]\n",
    "        protein_features = features.iloc[protein_indices]\n",
    "        \n",
    "        # Create unique gene names to avoid duplicates\n",
    "        gene_names = gene_features['gene_name'].values\n",
    "        gene_ids = gene_features['gene_id'].values\n",
    "        \n",
    "        # Create a dictionary to track duplicates\n",
    "        gene_name_count = {}\n",
    "        unique_gene_names = []\n",
    "        \n",
    "        for i, name in enumerate(gene_names):\n",
    "            if name in gene_name_count:\n",
    "                gene_name_count[name] += 1\n",
    "                unique_name = f\"{name}_{gene_ids[i]}\"\n",
    "                unique_gene_names.append(unique_name)\n",
    "            else:\n",
    "                gene_name_count[name] = 1\n",
    "                unique_gene_names.append(name)\n",
    "        \n",
    "        # Create AnnData objects\n",
    "        gene_adata = ad.AnnData(\n",
    "            X=gene_matrix,\n",
    "            obs=pd.DataFrame(index=barcodes['barcode']),\n",
    "            var=pd.DataFrame(index=unique_gene_names)\n",
    "        )\n",
    "        \n",
    "        # Do the same for protein features\n",
    "        protein_names = protein_features['gene_name'].values\n",
    "        protein_ids = protein_features['gene_id'].values\n",
    "        \n",
    "        protein_name_count = {}\n",
    "        unique_protein_names = []\n",
    "        \n",
    "        for i, name in enumerate(protein_names):\n",
    "            if name in protein_name_count:\n",
    "                protein_name_count[name] += 1\n",
    "                unique_name = f\"{name}_{protein_ids[i]}\"\n",
    "                unique_protein_names.append(unique_name)\n",
    "            else:\n",
    "                protein_name_count[name] = 1\n",
    "                unique_protein_names.append(name)\n",
    "        \n",
    "        protein_adata = ad.AnnData(\n",
    "            X=protein_matrix,\n",
    "            obs=pd.DataFrame(index=barcodes['barcode']),\n",
    "            var=pd.DataFrame(index=unique_protein_names)\n",
    "        )\n",
    "        \n",
    "        # Add gene_id as a var attribute\n",
    "        gene_adata.var['gene_id'] = gene_features['gene_id'].values\n",
    "        protein_adata.var['protein_id'] = protein_features['gene_id'].values\n",
    "        \n",
    "        # Add sample information\n",
    "        gene_adata.obs['sample'] = sample\n",
    "        protein_adata.obs['sample'] = sample\n",
    "        \n",
    "        # Add standardized metadata\n",
    "        for adata in [gene_adata, protein_adata]:\n",
    "            adata.obs['organism'] = 'Mus musculus'\n",
    "            adata.obs['cell_type'] = 'P14 CD8 T cell'\n",
    "            adata.obs['crispr_type'] = 'None'\n",
    "            adata.obs['cancer_type'] = 'Melanoma'\n",
    "            adata.obs['condition'] = self.SAMPLE_INFO[sample]['condition']\n",
    "            adata.obs['perturbation_name'] = self.SAMPLE_INFO[sample]['perturbation_name']\n",
    "        \n",
    "        return gene_adata, protein_adata\n",
    "    \n",
    "    def harmonize(self) -> Tuple[ad.AnnData, ad.AnnData]:\n",
    "        \"\"\"\n",
    "        Harmonize the dataset.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "                - AnnData object for gene expression\n",
    "                - AnnData object for protein data\n",
    "        \"\"\"\n",
    "        # Download and extract files if needed\n",
    "        self.download_files()\n",
    "        self.extract_files()\n",
    "        \n",
    "        # Process each sample\n",
    "        gene_adatas = []\n",
    "        protein_adatas = []\n",
    "        \n",
    "        for sample in ['A', 'B']:\n",
    "            gene_adata, protein_adata = self.create_anndata(sample)\n",
    "            gene_adatas.append(gene_adata)\n",
    "            protein_adatas.append(protein_adata)\n",
    "        \n",
    "        # Combine the samples\n",
    "        combined_gene_adata = ad.concat(gene_adatas, join='outer')\n",
    "        combined_protein_adata = ad.concat(protein_adatas, join='outer')\n",
    "        \n",
    "        # Store original gene names in a column for reference\n",
    "        combined_gene_adata.var['original_gene_name'] = combined_gene_adata.var_names\n",
    "        combined_protein_adata.var['original_protein_name'] = combined_protein_adata.var_names\n",
    "        \n",
    "        # Ensure all required metadata fields are present\n",
    "        required_fields = ['organism', 'cell_type', 'crispr_type', 'cancer_type', 'condition', 'perturbation_name']\n",
    "        for field in required_fields:\n",
    "            assert field in combined_gene_adata.obs.columns, f\"Missing required field: {field}\"\n",
    "            assert field in combined_protein_adata.obs.columns, f\"Missing required field: {field}\"\n",
    "        \n",
    "        return combined_gene_adata, combined_protein_adata\n",
    "    \n",
    "    def save_harmonized_data(self, output_dir: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Save the harmonized data to h5ad files.\n",
    "        \n",
    "        Args:\n",
    "            output_dir: Directory to save the output files. If None, uses the data_dir.\n",
    "        \"\"\"\n",
    "        if output_dir is None:\n",
    "            output_dir = self.data_dir\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Harmonize the data\n",
    "        gene_adata, protein_adata = self.harmonize()\n",
    "        \n",
    "        # Save the data\n",
    "        gene_output_path = os.path.join(output_dir, f\"{self.GEO_ACCESSION}_gene_expression.h5ad\")\n",
    "        protein_output_path = os.path.join(output_dir, f\"{self.GEO_ACCESSION}_protein_expression.h5ad\")\n",
    "        \n",
    "        print(f\"Saving gene expression data to {gene_output_path}...\")\n",
    "        gene_adata.write(gene_output_path, compression='gzip')\n",
    "        \n",
    "        print(f\"Saving protein expression data to {protein_output_path}...\")\n",
    "        protein_adata.write(protein_output_path, compression='gzip')\n",
    "        \n",
    "        print(\"Harmonization complete!\")\n",
    "\n",
    "\n",
    "def run_harmonization(data_dir: str = '/content/GSE280853', output_dir: Optional[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Helper function to run the harmonization process in a Jupyter Notebook.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory where the data is or will be stored.\n",
    "        output_dir: Directory to save the output files. If None, uses the data_dir.\n",
    "    \"\"\"\n",
    "    harmonizer = GSE280853Harmonizer(data_dir)\n",
    "    harmonizer.save_harmonized_data(output_dir)\n",
    "\n",
    "\n",
    "# Run the harmonization process with default directories.\n",
    "# You can modify 'data_dir' and 'output_dir' as needed.\n",
    "run_harmonization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
