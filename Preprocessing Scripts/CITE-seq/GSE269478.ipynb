{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import anndata as ad\n",
    "import urllib.request\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# URLs for downloading the dataset files\n",
    "URLS = {\n",
    "    'matrix': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE269nnn/GSE269478/suppl/GSE269478_mono_RNA_protein_15.mtx.gz',\n",
    "    'obs': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE269nnn/GSE269478/suppl/GSE269478_mono_RNA_protein_obs.txt.gz',\n",
    "    'var': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE269nnn/GSE269478/suppl/GSE269478_mono_RNA_protein_var.txt.gz',\n",
    "    'readme': 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE269nnn/GSE269478/suppl/GSE269478_readme.txt'\n",
    "}\n",
    "\n",
    "def download_files(data_dir):\n",
    "    \"\"\"\n",
    "    Download dataset files if they don't exist.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (Path): Directory to save the downloaded files.\n",
    "    \"\"\"\n",
    "    data_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    for name, url in URLS.items():\n",
    "        file_path = data_dir / os.path.basename(url)\n",
    "        if not file_path.exists():\n",
    "            print(f\"Downloading {name} file from {url}...\")\n",
    "            urllib.request.urlretrieve(url, file_path)\n",
    "            print(f\"Downloaded {file_path}\")\n",
    "        else:\n",
    "            print(f\"File {file_path} already exists, skipping download.\")\n",
    "\n",
    "def read_mtx_file(file_path):\n",
    "    \"\"\"\n",
    "    Read a gzipped MTX file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (Path): Path to the gzipped MTX file.\n",
    "        \n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: Sparse matrix from the MTX file.\n",
    "    \"\"\"\n",
    "    print(f\"Reading matrix file {file_path}...\")\n",
    "    return scipy.io.mmread(gzip.open(file_path, 'rb')).T.tocsr()\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    \"\"\"\n",
    "    Read a gzipped text file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (Path): Path to the gzipped text file.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing the file contents.\n",
    "    \"\"\"\n",
    "    print(f\"Reading text file {file_path}...\")\n",
    "    return pd.read_csv(gzip.open(file_path, 'rt'), sep='\\t')\n",
    "\n",
    "def extract_sample_info(cell_ids):\n",
    "    \"\"\"\n",
    "    Extract sample information from cell IDs.\n",
    "    \n",
    "    Args:\n",
    "        cell_ids (pandas.Index): Cell IDs from the dataset.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with extracted sample information.\n",
    "    \"\"\"\n",
    "    # Extract sample IDs from cell IDs (e.g., RPM211A_AAACCCAAGTTCCGGC-1 -> RPM211A)\n",
    "    sample_ids = [re.match(r'([^_]+)', cell_id).group(1) for cell_id in cell_ids]\n",
    "    \n",
    "    # Extract subject IDs (e.g., RPM211A -> RPM211)\n",
    "    subject_ids = [re.match(r'([A-Z]+\\d+)', sample_id).group(1) for sample_id in sample_ids]\n",
    "    \n",
    "    # Extract library information (e.g., RPM211A -> A)\n",
    "    library_ids = [sample_id.replace(subject_id, '') for sample_id, subject_id in zip(sample_ids, subject_ids)]\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'sample_id': sample_ids,\n",
    "        'subject_id': subject_ids,\n",
    "        'library_id': library_ids\n",
    "    }, index=cell_ids)\n",
    "\n",
    "def process_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    Process the GSE269478 dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (Path): Directory containing the dataset files.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (gene_adata, protein_adata) - AnnData objects for gene expression and protein data.\n",
    "    \"\"\"\n",
    "    # Read matrix and metadata\n",
    "    matrix = read_mtx_file(data_dir / 'GSE269478_mono_RNA_protein_15.mtx.gz')\n",
    "    obs_df = read_txt_file(data_dir / 'GSE269478_mono_RNA_protein_obs.txt.gz')\n",
    "    var_df = read_txt_file(data_dir / 'GSE269478_mono_RNA_protein_var.txt.gz')\n",
    "    \n",
    "    print(f\"Matrix shape: {matrix.shape}\")\n",
    "    print(f\"Observations: {obs_df.shape}\")\n",
    "    print(f\"Variables: {var_df.shape}\")\n",
    "    \n",
    "    # Set index\n",
    "    obs_df.set_index('cell_id', inplace=True)\n",
    "    var_df.set_index('gene', inplace=True)\n",
    "    \n",
    "    # Merge sample info\n",
    "    sample_info = extract_sample_info(obs_df.index)\n",
    "    obs_df = pd.concat([obs_df, sample_info], axis=1)\n",
    "    \n",
    "    # Create AnnData\n",
    "    adata = ad.AnnData(X=matrix, obs=obs_df, var=var_df)\n",
    "    \n",
    "    # Split out gene expression vs protein\n",
    "    gene_mask = var_df['feature_type'] == 'Gene Expression'\n",
    "    protein_mask = var_df['feature_type'] == 'Antibody Capture'\n",
    "    \n",
    "    gene_adata = adata[:, gene_mask].copy()\n",
    "    protein_adata = adata[:, protein_mask].copy()\n",
    "    \n",
    "    print(f\"Gene expression data shape: {gene_adata.shape}\")\n",
    "    print(f\"Protein data shape: {protein_adata.shape}\")\n",
    "    \n",
    "    # Check for duplicate gene names and make unique if needed\n",
    "    if gene_adata.var_names.duplicated().any():\n",
    "        print(f\"Found {gene_adata.var_names.duplicated().sum()} duplicate gene names. Making them unique.\")\n",
    "        gene_adata.var_names_make_unique()\n",
    "    \n",
    "    # Add harmonized metadata\n",
    "    for cur_adata in [gene_adata, protein_adata]:\n",
    "        cur_adata.obs['organism'] = 'Homo sapiens'\n",
    "        cur_adata.obs['cell_type'] = 'Monocytes'\n",
    "        cur_adata.obs['crispr_type'] = 'None'\n",
    "        cur_adata.obs['cancer_type'] = 'Non-Cancer'\n",
    "        cur_adata.obs['condition'] = 'Cardiovascular Disease Risk Study'\n",
    "        cur_adata.obs['perturbation_name'] = 'None'\n",
    "    \n",
    "    # Ensure both have the same cells\n",
    "    common_cells = gene_adata.obs_names.intersection(protein_adata.obs_names)\n",
    "    print(f\"Common cells between gene and protein data: {len(common_cells)}\")\n",
    "    \n",
    "    gene_adata = gene_adata[common_cells].copy()\n",
    "    protein_adata = protein_adata[common_cells].copy()\n",
    "    \n",
    "    print(f\"Final gene expression data shape: {gene_adata.shape}\")\n",
    "    print(f\"Final protein data shape: {protein_adata.shape}\")\n",
    "    \n",
    "    # Remove everything after the first dash (including -ADT) to keep just the leftmost part.\n",
    "    # e.g. \"CD102-ICAM-2-ADT\" -> \"CD102\"\n",
    "    cleaned_protein_names = []\n",
    "    for name in protein_adata.var_names:\n",
    "        # 1) Remove the trailing \"-ADT\" if present\n",
    "        name_no_adt = re.sub(r'-ADT$', '', name)\n",
    "        # 2) Keep only the substring before the first dash\n",
    "        main_part = name_no_adt.split('-', 1)[0]\n",
    "        cleaned_protein_names.append(main_part)\n",
    "    \n",
    "    # Overwrite var_names and store an extra column\n",
    "    protein_adata.var_names = cleaned_protein_names\n",
    "    protein_adata.var['protein_name'] = protein_adata.var_names\n",
    "    \n",
    "    # Optionally, add gene names in gene_adata.var\n",
    "    gene_adata.var['gene_name'] = gene_adata.var_names\n",
    "    \n",
    "    return gene_adata, protein_adata\n",
    "\n",
    "def main(data_dir=None):\n",
    "    \"\"\"\n",
    "    Main function to process the dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str, optional): Path to the data directory. Defaults to None.\n",
    "    \"\"\"\n",
    "    if data_dir is None:\n",
    "        data_dir = Path('GSE269478')\n",
    "    else:\n",
    "        data_dir = Path(data_dir)\n",
    "    \n",
    "    # Download files if not present\n",
    "    download_files(data_dir)\n",
    "    \n",
    "    # Process dataset\n",
    "    gene_adata, protein_adata = process_dataset(data_dir)\n",
    "    \n",
    "    # Save the processed data\n",
    "    output_dir = data_dir / 'processed'\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    gene_output_path = output_dir / 'GSE269478_gene_expression.h5ad'\n",
    "    protein_output_path = output_dir / 'GSE269478_protein_expression.h5ad'\n",
    "    \n",
    "    print(f\"Saving gene expression data to {gene_output_path}\")\n",
    "    gene_adata.write(gene_output_path, compression='gzip')\n",
    "    \n",
    "    print(f\"Saving protein expression data to {protein_output_path}\")\n",
    "    protein_adata.write(protein_output_path, compression='gzip')\n",
    "    \n",
    "    print(\"Processing complete!\")\n",
    "\n",
    "# If you're using a Jupyter notebook, just call main() in a cell:\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
