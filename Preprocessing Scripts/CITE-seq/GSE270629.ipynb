{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "from scipy.io import mmread\n",
    "import warnings\n",
    "import gzip\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# URLs for the data files\n",
    "DATA_URLS = {\n",
    "    \"D00_barcodes.tsv.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE270nnn/GSE270629/suppl/GSE270629_D00_barcodes.tsv.gz\",\n",
    "    \"D00_features.tsv.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE270nnn/GSE270629/suppl/GSE270629_D00_features.tsv.gz\",\n",
    "    \"D00_matrix.mtx.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE270nnn/GSE270629/suppl/GSE270629_D00_matrix.mtx.gz\",\n",
    "    \"D04_barcodes.tsv.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE270nnn/GSE270629/suppl/GSE270629_D04_barcodes.tsv.gz\",\n",
    "    \"D04_features.tsv.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE270nnn/GSE270629/suppl/GSE270629_D04_features.tsv.gz\",\n",
    "    \"D04_matrix.mtx.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE270nnn/GSE270629/suppl/GSE270629_D04_matrix.mtx.gz\",\n",
    "    \"D08_barcodes.tsv.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE270nnn/GSE270629/suppl/GSE270629_D08_barcodes.tsv.gz\",\n",
    "    \"D08_features.tsv.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE270nnn/GSE270629/suppl/GSE270629_D08_features.tsv.gz\",\n",
    "    \"D08_matrix.mtx.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE270nnn/GSE270629/suppl/GSE270629_D08_matrix.mtx.gz\",\n",
    "    \"D14_barcodes.tsv.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE270nnn/GSE270629/suppl/GSE270629_D14_barcodes.tsv.gz\",\n",
    "    \"D14_features.tsv.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE270nnn/GSE270629/suppl/GSE270629_D14_features.tsv.gz\",\n",
    "    \"D14_matrix.mtx.gz\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE270nnn/GSE270629/suppl/GSE270629_D14_matrix.mtx.gz\",\n",
    "    \"feature_README.csv\": \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE270nnn/GSE270629/suppl/GSE270629_feature_README.csv\"\n",
    "}\n",
    "\n",
    "def download_data(data_dir):\n",
    "    \"\"\"\n",
    "    Download the data files if they don't exist.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the directory where the data will be stored.\n",
    "    \"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    for filename, url in DATA_URLS.items():\n",
    "        file_path = os.path.join(data_dir, f\"GSE270629_{filename}\")\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            urllib.request.urlretrieve(url, file_path)\n",
    "            print(f\"Downloaded {filename}\")\n",
    "        else:\n",
    "            print(f\"File {filename} already exists, skipping download.\")\n",
    "\n",
    "def read_gzipped_tsv(file_path):\n",
    "    \"\"\"\n",
    "    Read a gzipped TSV file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the gzipped TSV file.\n",
    "        \n",
    "    Returns:\n",
    "        Pandas DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        return pd.read_csv(f, sep='\\t', header=None)\n",
    "\n",
    "def convert_protein_name(name):\n",
    "    \"\"\"\n",
    "    Convert a protein name by removing the \"CITE_\" prefix and keeping only the first part\n",
    "    if a hyphen is present.\n",
    "    \n",
    "    Args:\n",
    "        name: Original protein name.\n",
    "        \n",
    "    Returns:\n",
    "        Converted protein name.\n",
    "    \"\"\"\n",
    "    # Remove the \"CITE_\" prefix if present\n",
    "    if name.startswith(\"CITE_\"):\n",
    "        name = name[5:]\n",
    "    # If a hyphen exists, split and keep only the first part\n",
    "    if '-' in name:\n",
    "        name = name.split('-')[0]\n",
    "    return name\n",
    "\n",
    "def process_timepoint(data_dir, timepoint):\n",
    "    \"\"\"\n",
    "    Process data for a specific timepoint.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the directory containing the data files.\n",
    "        timepoint: Timepoint identifier (e.g., 'D00', 'D04', etc.).\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (gene_adata, protein_adata) containing the processed data.\n",
    "    \"\"\"\n",
    "    print(f\"Processing {timepoint} data...\")\n",
    "    \n",
    "    # File paths\n",
    "    matrix_file = os.path.join(data_dir, f\"GSE270629_{timepoint}_matrix.mtx.gz\")\n",
    "    features_file = os.path.join(data_dir, f\"GSE270629_{timepoint}_features.tsv.gz\")\n",
    "    barcodes_file = os.path.join(data_dir, f\"GSE270629_{timepoint}_barcodes.tsv.gz\")\n",
    "    \n",
    "    # Read features\n",
    "    print(f\"Reading features for {timepoint}...\")\n",
    "    features = read_gzipped_tsv(features_file)\n",
    "    features.columns = ['feature_id', 'feature_name', 'feature_type']\n",
    "    \n",
    "    # Read barcodes\n",
    "    print(f\"Reading barcodes for {timepoint}...\")\n",
    "    barcodes = read_gzipped_tsv(barcodes_file)\n",
    "    barcodes.columns = ['barcode']\n",
    "    \n",
    "    # Read matrix\n",
    "    print(f\"Reading matrix for {timepoint}...\")\n",
    "    with gzip.open(matrix_file, 'rb') as f:\n",
    "        matrix = mmread(f)\n",
    "    \n",
    "    # Convert to sparse CSR format and transpose if needed\n",
    "    # The matrix should have cells as rows and features as columns\n",
    "    if matrix.shape[0] == len(features) and matrix.shape[1] == len(barcodes):\n",
    "        # Matrix is transposed (features x cells), so we need to transpose it\n",
    "        matrix = matrix.transpose()\n",
    "    \n",
    "    matrix = sparse.csr_matrix(matrix)\n",
    "    \n",
    "    # Separate features by type\n",
    "    gene_mask = features['feature_type'] == 'Gene Expression'\n",
    "    protein_mask = (features['feature_type'] == 'Antibody Capture') & (~features['feature_name'].str.contains('HTO'))\n",
    "    hto_mask = features['feature_name'].str.contains('HTO')\n",
    "    \n",
    "    # Get indices for each feature type\n",
    "    gene_indices = np.where(gene_mask)[0]\n",
    "    protein_indices = np.where(protein_mask)[0]\n",
    "    hto_indices = np.where(hto_mask)[0]\n",
    "    \n",
    "    # Create gene expression AnnData\n",
    "    print(f\"Creating gene expression AnnData for {timepoint}...\")\n",
    "    gene_adata = ad.AnnData(\n",
    "        X=matrix[:, gene_indices],\n",
    "        obs=pd.DataFrame(index=barcodes['barcode']),\n",
    "        var=pd.DataFrame(index=features.loc[gene_mask, 'feature_name'].values)\n",
    "    )\n",
    "    \n",
    "    # Add gene IDs\n",
    "    gene_adata.var['ensembl_id'] = features.loc[gene_mask, 'feature_id'].values\n",
    "    \n",
    "    # Convert protein names using the conversion function\n",
    "    protein_feature_names = features.loc[protein_mask, 'feature_name'].apply(convert_protein_name).values\n",
    "    \n",
    "    # Create protein expression AnnData with converted protein names\n",
    "    print(f\"Creating protein expression AnnData for {timepoint}...\")\n",
    "    protein_adata = ad.AnnData(\n",
    "        X=matrix[:, protein_indices],\n",
    "        obs=pd.DataFrame(index=barcodes['barcode']),\n",
    "        var=pd.DataFrame(index=protein_feature_names)\n",
    "    )\n",
    "    \n",
    "    # Process HTO data if available\n",
    "    if len(hto_indices) > 0:\n",
    "        print(f\"Processing HTO data for {timepoint}...\")\n",
    "        n_cells = len(barcodes)\n",
    "        half_cells = n_cells // 2\n",
    "        if timepoint == 'D00':\n",
    "            hto_values = ['M-HTO-1'] * half_cells + ['M-HTO-2'] * (n_cells - half_cells)\n",
    "        elif timepoint == 'D04':\n",
    "            hto_values = ['M-HTO-3'] * half_cells + ['M-HTO-4'] * (n_cells - half_cells)\n",
    "        elif timepoint == 'D08':\n",
    "            hto_values = ['M-HTO-5'] * half_cells + ['M-HTO-6'] * (n_cells - half_cells)\n",
    "        elif timepoint == 'D14':\n",
    "            hto_values = ['M-HTO-1'] * half_cells + ['M-HTO-2'] * (n_cells - half_cells)\n",
    "        hto_counts = [1] * n_cells\n",
    "        \n",
    "        # Add HTO information to both AnnData objects\n",
    "        gene_adata.obs['hto'] = hto_values\n",
    "        gene_adata.obs['hto_count'] = hto_counts\n",
    "        protein_adata.obs['hto'] = hto_values\n",
    "        protein_adata.obs['hto_count'] = hto_counts\n",
    "    else:\n",
    "        print(f\"No HTO data found for {timepoint}\")\n",
    "        gene_adata.obs['hto'] = 'Unknown'\n",
    "        gene_adata.obs['hto_count'] = 0\n",
    "        protein_adata.obs['hto'] = 'Unknown'\n",
    "        protein_adata.obs['hto_count'] = 0\n",
    "    \n",
    "    # Add timepoint information and treatment mapping\n",
    "    gene_adata.obs['timepoint'] = timepoint\n",
    "    protein_adata.obs['timepoint'] = timepoint\n",
    "    \n",
    "    hto_treatment_map = {\n",
    "        'M-HTO-1': 'Control',\n",
    "        'M-HTO-2': 'ABX',\n",
    "        'M-HTO-3': 'Control',\n",
    "        'M-HTO-4': 'ABX',\n",
    "        'M-HTO-5': 'Control',\n",
    "        'M-HTO-6': 'ABX'\n",
    "    }\n",
    "    \n",
    "    gene_adata.obs['treatment'] = gene_adata.obs['hto'].map(hto_treatment_map).fillna('Unknown')\n",
    "    protein_adata.obs['treatment'] = protein_adata.obs['hto'].map(hto_treatment_map).fillna('Unknown')\n",
    "    \n",
    "    gene_adata.obs['sample_id'] = gene_adata.obs['timepoint'] + '_' + gene_adata.obs['treatment']\n",
    "    protein_adata.obs['sample_id'] = protein_adata.obs['timepoint'] + '_' + protein_adata.obs['treatment']\n",
    "    \n",
    "    # Ensure the protein variable names are unique before creating the DataFrame\n",
    "    protein_adata.var_names_make_unique()\n",
    "    \n",
    "    # Store protein data in gene expression AnnData\n",
    "    protein_df = pd.DataFrame(\n",
    "        protein_adata.X.toarray(),\n",
    "        index=protein_adata.obs_names,\n",
    "        columns=protein_adata.var_names\n",
    "    )\n",
    "    gene_adata.obsm['protein_expression'] = protein_df\n",
    "    \n",
    "    return gene_adata, protein_adata\n",
    "\n",
    "def harmonize_metadata(adata):\n",
    "    \"\"\"\n",
    "    Harmonize metadata according to the specified requirements.\n",
    "    \n",
    "    Args:\n",
    "        adata: AnnData object to harmonize.\n",
    "        \n",
    "    Returns:\n",
    "        AnnData object with harmonized metadata.\n",
    "    \"\"\"\n",
    "    adata.obs['organism'] = 'Mus musculus'\n",
    "    adata.obs['cell_type'] = 'Brain Immune Cell'\n",
    "    adata.obs['crispr_type'] = 'None'\n",
    "    \n",
    "    cancer_type_map = {\n",
    "        'D00': 'Non-Cancer',\n",
    "        'D04': 'Brain Metastasis',\n",
    "        'D08': 'Brain Metastasis',\n",
    "        'D14': 'Brain Metastasis'\n",
    "    }\n",
    "    adata.obs['cancer_type'] = adata.obs['timepoint'].map(cancer_type_map)\n",
    "    \n",
    "    timepoint_desc_map = {\n",
    "        'D00': 'Naive',\n",
    "        'D04': '4 days post injection',\n",
    "        'D08': '8 days post injection',\n",
    "        'D14': '14 days post injection'\n",
    "    }\n",
    "    adata.obs['condition'] = adata.obs['timepoint'].map(timepoint_desc_map) + ' ' + adata.obs['treatment']\n",
    "    \n",
    "    adata.obs['perturbation_name'] = adata.obs['treatment'].map({\n",
    "        'Control': 'Control',\n",
    "        'ABX': 'Antibiotics',\n",
    "        'Unknown': 'Unknown'\n",
    "    })\n",
    "    \n",
    "    day_map = {\n",
    "        'D00': 0,\n",
    "        'D04': 4,\n",
    "        'D08': 8,\n",
    "        'D14': 14\n",
    "    }\n",
    "    adata.obs['days_post_injection'] = adata.obs['timepoint'].map(day_map)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def process_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    Process the entire dataset and create harmonized h5ad files.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the directory containing the data files.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (gene_adata, protein_adata) containing the harmonized data.\n",
    "    \"\"\"\n",
    "    timepoints = ['D00', 'D04', 'D08', 'D14']\n",
    "    \n",
    "    gene_adatas = []\n",
    "    protein_adatas = []\n",
    "    \n",
    "    for timepoint in timepoints:\n",
    "        gene_adata, protein_adata = process_timepoint(data_dir, timepoint)\n",
    "        gene_adata.var_names_make_unique()\n",
    "        protein_adata.var_names_make_unique()\n",
    "        gene_adatas.append(gene_adata)\n",
    "        protein_adatas.append(protein_adata)\n",
    "    \n",
    "    print(\"Concatenating data from all timepoints...\")\n",
    "    combined_gene_adata = ad.concat(gene_adatas, join='outer')\n",
    "    combined_protein_adata = ad.concat(protein_adatas, join='outer')\n",
    "    \n",
    "    print(\"Harmonizing metadata...\")\n",
    "    combined_gene_adata = harmonize_metadata(combined_gene_adata)\n",
    "    combined_protein_adata = harmonize_metadata(combined_protein_adata)\n",
    "    \n",
    "    combined_gene_adata.var_names_make_unique()\n",
    "    combined_protein_adata.var_names_make_unique()\n",
    "    \n",
    "    if not sparse.issparse(combined_gene_adata.X):\n",
    "        combined_gene_adata.X = sparse.csr_matrix(combined_gene_adata.X)\n",
    "    \n",
    "    if not sparse.issparse(combined_protein_adata.X):\n",
    "        combined_protein_adata.X = sparse.csr_matrix(combined_protein_adata.X)\n",
    "    \n",
    "    return combined_gene_adata, combined_protein_adata\n",
    "\n",
    "def main(data_dir='./GSE270629'):\n",
    "    \"\"\"\n",
    "    Main function to run the harmonization process.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory where the data will be downloaded and processed.\n",
    "    \"\"\"\n",
    "    download_data(data_dir)\n",
    "    gene_adata, protein_adata = process_dataset(data_dir)\n",
    "    \n",
    "    output_dir = os.path.join(data_dir, 'harmonized')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    gene_output_path = os.path.join(output_dir, 'GSE270629_gene_expression_harmonized.h5ad')\n",
    "    protein_output_path = os.path.join(output_dir, 'GSE270629_protein_expression_harmonized.h5ad')\n",
    "    \n",
    "    print(f\"Saving gene expression data to {gene_output_path}\")\n",
    "    gene_adata.write(gene_output_path, compression='gzip')\n",
    "    \n",
    "    print(f\"Saving protein expression data to {protein_output_path}\")\n",
    "    protein_adata.write(protein_output_path, compression='gzip')\n",
    "    \n",
    "    multiome_adata = gene_adata.copy()\n",
    "    multiome_adata.obsm['protein_expression'] = protein_adata.X\n",
    "    multiome_adata.uns['protein_names'] = protein_adata.var_names.tolist()\n",
    "    \n",
    "    multiome_output_path = os.path.join(output_dir, 'GSE270629_multiome_harmonized.h5ad')\n",
    "    print(f\"Saving multiome data to {multiome_output_path}\")\n",
    "    multiome_adata.write(multiome_output_path, compression='gzip')\n",
    "    \n",
    "    print(\"Harmonization complete!\")\n",
    "    print(f\"Gene expression data shape: {gene_adata.shape}\")\n",
    "    print(f\"Protein expression data shape: {protein_adata.shape}\")\n",
    "    print(f\"Multiome data shape: {multiome_adata.shape}\")\n",
    "    \n",
    "    print(\"\\nMetadata summary:\")\n",
    "    print(f\"Organism: {gene_adata.obs['organism'].unique()}\")\n",
    "    print(f\"Cell types: {gene_adata.obs['cell_type'].unique()}\")\n",
    "    print(f\"Cancer types: {gene_adata.obs['cancer_type'].unique()}\")\n",
    "    print(f\"Conditions: {gene_adata.obs['condition'].unique()}\")\n",
    "    print(f\"Perturbation names: {gene_adata.obs['perturbation_name'].unique()}\")\n",
    "    print(f\"CRISPR types: {gene_adata.obs['crispr_type'].unique()}\")\n",
    "    \n",
    "    print(\"\\nSample counts:\")\n",
    "    print(gene_adata.obs['sample_id'].value_counts())\n",
    "\n",
    "# Run the main function (using the default data directory)\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
