{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "from scipy import sparse, io\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Constants and file lists\n",
    "# ---------------------------\n",
    "GEO_ACCESSION = \"GSE267070\"\n",
    "FILES = [\n",
    "    f\"{GEO_ACCESSION}_barcodes.tsv.gz\",\n",
    "    f\"{GEO_ACCESSION}_features.tsv.gz\",\n",
    "    f\"{GEO_ACCESSION}_matrix.mtx.gz\",\n",
    "    f\"{GEO_ACCESSION}_feature_reference.csv.gz\"\n",
    "]\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Helper functions\n",
    "# ---------------------------\n",
    "\n",
    "def download_files(data_dir):\n",
    "    \"\"\"Download the required files if they don't exist.\"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    # Simple HTTP request headers\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    base_url = f\"https://www.ncbi.nlm.nih.gov/geo/download/?acc={GEO_ACCESSION}&format=file\"\n",
    "    \n",
    "    for file in FILES:\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Downloading {file}...\")\n",
    "            req = urllib.request.Request(url=f\"{base_url}&file={file}\", headers=headers)\n",
    "            try:\n",
    "                with urllib.request.urlopen(req) as response, open(file_path, 'wb') as out_file:\n",
    "                    shutil.copyfileobj(response, out_file)\n",
    "                print(f\"Downloaded {file}\")\n",
    "            except urllib.error.HTTPError as e:\n",
    "                print(f\"Error downloading {file}: {e}\")\n",
    "                print(\"Consider using GEOquery in R or manual download from the GEO website.\")\n",
    "        else:\n",
    "            print(f\"File {file} already exists, skipping download.\")\n",
    "\n",
    "\n",
    "def rename_protein(raw_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Simplify a protein marker name. \n",
    "    Examples:\n",
    "      - 'CD279-(PD-1)-RMP1-30'  -> 'CD279'\n",
    "      - 'CD200-(OX2)-OX-90'     -> 'CD200'\n",
    "      - 'CD8a-53-6.7'           -> 'CD8a'\n",
    "      - 'CD45.2-104'            -> 'CD45.2'\n",
    "    If it starts with 'HTO', keep it intact.\n",
    "    If it doesn't match the pattern, returns the original full name.\n",
    "    \"\"\"\n",
    "    # Keep HTO names as-is\n",
    "    if raw_name.startswith(\"HTO\"):\n",
    "        return raw_name\n",
    "    \n",
    "    # Regex to capture strings starting with \"CD\", followed by numbers/letters/dots\n",
    "    # capturing only up until the first dash or parenthesis (if any).\n",
    "    # Example: \"CD279-(PD-1)-RMP1-30\" -> match group is \"CD279\"\n",
    "    match = re.match(r'^(CD[0-9a-zA-Z\\.]+)(?=[\\(-]|$)', raw_name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    # Otherwise, return the whole raw_name, or customize further if needed\n",
    "    return raw_name\n",
    "\n",
    "\n",
    "def rename_proteins(adata_protein):\n",
    "    \"\"\"\n",
    "    Modify .var_names of the protein AnnData in-place using 'rename_protein'.\n",
    "    \"\"\"\n",
    "    cleaned_names = [rename_protein(n) for n in adata_protein.var_names]\n",
    "    adata_protein.var_names = cleaned_names\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\"Load the 10X data into separate AnnData objects for gene expression and protein.\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "\n",
    "    # --- Load feature info ---\n",
    "    features_path = os.path.join(data_dir, f\"{GEO_ACCESSION}_features.tsv.gz\")\n",
    "    features = pd.read_csv(features_path, sep='\\t', header=None)\n",
    "    features.columns = ['id', 'name', 'feature_type']\n",
    "    \n",
    "    gene_features = features[features['feature_type'] == 'Gene Expression']\n",
    "    protein_features = features[features['feature_type'] == 'Antibody Capture']\n",
    "    \n",
    "    print(f\"Number of gene features: {len(gene_features)}\")\n",
    "    print(f\"Number of protein features: {len(protein_features)}\")\n",
    "    \n",
    "    # --- Load barcodes ---\n",
    "    barcodes_path = os.path.join(data_dir, f\"{GEO_ACCESSION}_barcodes.tsv.gz\")\n",
    "    barcodes = pd.read_csv(barcodes_path, header=None, sep='\\t')[0].values\n",
    "    \n",
    "    # --- Load the matrix ---\n",
    "    matrix_path = os.path.join(data_dir, f\"{GEO_ACCESSION}_matrix.mtx.gz\")\n",
    "    matrix = io.mmread(matrix_path).tocsr()\n",
    "    print(f\"Matrix shape (features x cells): {matrix.shape}\")\n",
    "    \n",
    "    # Transpose to get cells x features\n",
    "    matrix = matrix.transpose()\n",
    "    print(f\"Transposed matrix shape (cells x features): {matrix.shape}\")\n",
    "    \n",
    "    # --- Subset matrix into gene vs. protein ---\n",
    "    gene_indices = gene_features.index.tolist()\n",
    "    protein_indices = protein_features.index.tolist()\n",
    "    \n",
    "    adata_gene = ad.AnnData(\n",
    "        X=matrix[:, gene_indices],\n",
    "        obs=pd.DataFrame(index=barcodes),\n",
    "        var=pd.DataFrame(index=gene_features['name'].values)\n",
    "    )\n",
    "    adata_protein = ad.AnnData(\n",
    "        X=matrix[:, protein_indices],\n",
    "        obs=pd.DataFrame(index=barcodes),\n",
    "        var=pd.DataFrame(index=protein_features['name'].values)\n",
    "    )\n",
    "    \n",
    "    # --- Rename the protein var_names ---\n",
    "    rename_proteins(adata_protein)\n",
    "    \n",
    "    print(f\"Gene expression data shape: {adata_gene.shape}\")\n",
    "    print(f\"Protein data shape: {adata_protein.shape}\")\n",
    "    \n",
    "    return adata_gene, adata_protein, features\n",
    "\n",
    "\n",
    "def harmonize_metadata(adata_gene, adata_protein, features, data_dir):\n",
    "    \"\"\"Example: Add some meta-fields and parse HTO to get condition.\"\"\"\n",
    "    print(\"Harmonizing metadata...\")\n",
    "    \n",
    "    # (Optional) load the feature reference file if needed\n",
    "    feature_ref_path = os.path.join(data_dir, f\"{GEO_ACCESSION}_feature_reference.csv.gz\")\n",
    "    if os.path.exists(feature_ref_path):\n",
    "        feature_ref = pd.read_csv(feature_ref_path)\n",
    "    else:\n",
    "        feature_ref = pd.DataFrame()\n",
    "    \n",
    "    # Create a metadata DataFrame\n",
    "    metadata = pd.DataFrame(index=adata_gene.obs.index)\n",
    "    metadata['organism'] = 'Mus musculus'\n",
    "    metadata['cell_type'] = 'CD45+ Immune Cells'\n",
    "    metadata['crispr_type'] = 'None'\n",
    "    metadata['cancer_type'] = 'Melanoma'\n",
    "    metadata['condition'] = 'Unknown'       # We might overwrite this below\n",
    "    metadata['perturbation_name'] = 'None'\n",
    "    \n",
    "    # Attach to obs\n",
    "    for col in metadata.columns:\n",
    "        adata_gene.obs[col] = metadata[col].values\n",
    "        adata_protein.obs[col] = metadata[col].values\n",
    "    \n",
    "    # --- Attempt to derive condition from HTO data (if present) ---\n",
    "    try:\n",
    "        # The rename_proteins step preserves 'HTO1', 'HTO2', etc.\n",
    "        hto_names = [f for f in adata_protein.var_names if f.startswith('HTO')]\n",
    "        if hto_names:\n",
    "            # Extract HTO counts\n",
    "            hto_counts = pd.DataFrame(adata_protein[:, hto_names].X.toarray(),\n",
    "                                      index=adata_protein.obs.index,\n",
    "                                      columns=hto_names)\n",
    "            # Assign each cell to the \"max\" HTO\n",
    "            hto_counts['max_hto'] = hto_counts.idxmax(axis=1)\n",
    "            \n",
    "            # For example, if 'HTO1'..'HTO4' = 'Dietary Restriction',\n",
    "            # and 'HTO5'..'HTO8' = 'Ad Libitum'.\n",
    "            condition_map = {\n",
    "                'HTO1': 'Dietary Restriction', 'HTO2': 'Dietary Restriction',\n",
    "                'HTO3': 'Dietary Restriction', 'HTO4': 'Dietary Restriction',\n",
    "                'HTO5': 'Ad Libitum', 'HTO6': 'Ad Libitum',\n",
    "                'HTO7': 'Ad Libitum', 'HTO8': 'Ad Libitum'\n",
    "            }\n",
    "            hto_counts['condition'] = hto_counts['max_hto'].map(condition_map)\n",
    "            \n",
    "            adata_gene.obs['condition'] = hto_counts['condition']\n",
    "            adata_protein.obs['condition'] = hto_counts['condition']\n",
    "            \n",
    "            print(\"Successfully derived condition from HTO data.\")\n",
    "        else:\n",
    "            print(\"No HTO features found in protein data; condition remains 'Unknown'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not parse HTO condition: {e}\")\n",
    "    \n",
    "    return adata_gene, adata_protein\n",
    "\n",
    "\n",
    "def filter_paired_data(adata_gene, adata_protein):\n",
    "    \"\"\"Keep only cells that appear in both gene and protein data.\"\"\"\n",
    "    print(\"Filtering to keep only paired data (common barcodes)...\")\n",
    "    common_barcodes = sorted(set(adata_gene.obs_names) & set(adata_protein.obs_names))\n",
    "    print(f\"Common cells: {len(common_barcodes)}\")\n",
    "    \n",
    "    adata_gene_paired = adata_gene[common_barcodes].copy()\n",
    "    adata_protein_paired = adata_protein[common_barcodes].copy()\n",
    "    \n",
    "    return adata_gene_paired, adata_protein_paired\n",
    "\n",
    "\n",
    "def check_gene_symbols(adata):\n",
    "    \"\"\"Check for duplicate gene symbols and make them unique if needed.\"\"\"\n",
    "    print(\"Checking for duplicate gene symbols...\")\n",
    "    if adata.var_names.duplicated().any():\n",
    "        dup_count = adata.var_names.duplicated().sum()\n",
    "        print(f\"Found {dup_count} duplicated gene name(s). Making unique...\")\n",
    "        \n",
    "        var_df = adata.var.copy()\n",
    "        var_df[\"original_name\"] = adata.var_names\n",
    "        var_df[\"dup_num\"] = var_df.groupby(\"original_name\").cumcount().astype(str)\n",
    "        var_df[\"unique_name\"] = var_df.apply(\n",
    "            lambda x: x[\"original_name\"] if x[\"dup_num\"] == \"0\"\n",
    "            else f\"{x['original_name']}_{x['dup_num']}\", axis=1\n",
    "        )\n",
    "        adata.var_names = var_df[\"unique_name\"].values\n",
    "        print(\"Duplicate gene symbols have been made unique.\")\n",
    "    else:\n",
    "        print(\"No duplicate gene symbols found.\")\n",
    "    return adata\n",
    "\n",
    "\n",
    "def save_data(adata_gene, adata_protein, data_dir):\n",
    "    \"\"\"Save the two AnnData objects.\"\"\"\n",
    "    print(\"Saving final AnnData objects...\")\n",
    "    \n",
    "    gene_output_path = os.path.join(data_dir, f\"{GEO_ACCESSION}_gene_expression_harmonized.h5ad\")\n",
    "    protein_output_path = os.path.join(data_dir, f\"{GEO_ACCESSION}_protein_expression_harmonized.h5ad\")\n",
    "    \n",
    "    adata_gene.write(gene_output_path, compression='gzip')\n",
    "    adata_protein.write(protein_output_path, compression='gzip')\n",
    "    \n",
    "    print(f\"  -> {gene_output_path}\")\n",
    "    print(f\"  -> {protein_output_path}\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Master pipeline function\n",
    "# ---------------------------\n",
    "def run_pipeline(data_dir=None):\n",
    "    \"\"\"Run the end-to-end data processing and harmonization pipeline.\"\"\"\n",
    "    if data_dir is None:\n",
    "        data_dir = os.getcwd()\n",
    "    print(f\"Using data directory: {data_dir}\")\n",
    "    \n",
    "    # 1. Download data if needed\n",
    "    download_files(data_dir)\n",
    "    \n",
    "    # 2. Load data\n",
    "    adata_gene, adata_protein, features = load_data(data_dir)\n",
    "    \n",
    "    # 3. Harmonize metadata\n",
    "    adata_gene, adata_protein = harmonize_metadata(adata_gene, adata_protein, features, data_dir)\n",
    "    \n",
    "    # 4. Filter to keep only cells with both gene/protein data\n",
    "    adata_gene, adata_protein = filter_paired_data(adata_gene, adata_protein)\n",
    "    \n",
    "    # 5. Fix duplicate gene symbols (if any)\n",
    "    adata_gene = check_gene_symbols(adata_gene)\n",
    "    \n",
    "    # 6. Save\n",
    "    save_data(adata_gene, adata_protein, data_dir)\n",
    "    \n",
    "    print(\"Data harmonization complete!\")\n",
    "    return adata_gene, adata_protein\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Example of actually running\n",
    "# ---------------------------\n",
    "processed_adata_gene, processed_adata_protein = run_pipeline(\"/home/ubuntu/GSE267070\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494526e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# Load the gene expression AnnData object from the saved h5ad file.\n",
    "adata_gene = sc.read_h5ad(\"/content/GSE267070/GSE267070_gene_expression_harmonized.h5ad\")\n",
    "\n",
    "# Print the number of cells before QC filtering.\n",
    "print(\"Number of cells before QC filtering:\", adata_gene.n_obs)\n",
    "\n",
    "# Compute QC metrics for each cell, which adds metrics like 'n_genes_by_counts' to adata_gene.obs.\n",
    "sc.pp.calculate_qc_metrics(adata_gene, inplace=True)\n",
    "\n",
    "# Define a QC threshold: keep cells with at least 200 genes detected.\n",
    "qc_threshold = 200\n",
    "adata_gene_qc = adata_gene[adata_gene.obs['n_genes_by_counts'] >= qc_threshold].copy()\n",
    "\n",
    "# Print the number of cells after QC filtering.\n",
    "print(\"Number of cells after QC filtering:\", adata_gene_qc.n_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
