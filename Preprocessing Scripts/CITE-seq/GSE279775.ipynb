{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61713b-4c06-4222-8853-da54ecde594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "import requests\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "def download_data(data_dir, url=\"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE279775&format=file\"):\n",
    "    \"\"\"\n",
    "    Download the GSE279775 dataset if not already present.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory to save the data\n",
    "        url: URL to download the data from\n",
    "    \"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    tar_file = os.path.join(data_dir, \"GSE279775_RAW.tar\")\n",
    "    \n",
    "    if not os.path.exists(tar_file):\n",
    "        print(f\"Downloading GSE279775 dataset to {tar_file}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        with open(tar_file, 'wb') as f:\n",
    "            with tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Downloading\") as pbar:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        pbar.update(len(chunk))\n",
    "        \n",
    "        print(\"Download complete. Extracting files...\")\n",
    "        with tarfile.open(tar_file) as tar:\n",
    "            tar.extractall(path=data_dir)\n",
    "        print(\"Extraction complete.\")\n",
    "    else:\n",
    "        print(f\"Found existing data at {tar_file}\")\n",
    "        # Check if files are already extracted\n",
    "        if not glob.glob(os.path.join(data_dir, \"GSM*.csv.gz\")):\n",
    "            print(\"Extracting files...\")\n",
    "            with tarfile.open(tar_file) as tar:\n",
    "                tar.extractall(path=data_dir)\n",
    "            print(\"Extraction complete.\")\n",
    "        else:\n",
    "            print(\"Files already extracted.\")\n",
    "\n",
    "def read_feature_reference(file_path):\n",
    "    \"\"\"\n",
    "    Read the feature reference file to get protein information.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the feature reference file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with protein information\n",
    "    \"\"\"\n",
    "    print(f\"Reading feature reference from {os.path.basename(file_path)}...\")\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        feature_ref = pd.read_csv(f)\n",
    "    print(f\"Found {len(feature_ref)} features\")\n",
    "    return feature_ref\n",
    "\n",
    "def read_sample_tags(file_path):\n",
    "    \"\"\"\n",
    "    Read the sample tag file to get cell metadata.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the sample tag file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with cell metadata\n",
    "    \"\"\"\n",
    "    print(f\"Reading sample tags from {os.path.basename(file_path)}...\")\n",
    "    \n",
    "    # Count header lines to skip\n",
    "    header_lines = 0\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        for line in f:\n",
    "            header_lines += 1\n",
    "            if line.startswith(\"Cell_Index\"):\n",
    "                break\n",
    "    \n",
    "    print(f\"Found header at line {header_lines}\")\n",
    "    \n",
    "    # Read the data with the correct header\n",
    "    sample_tags = pd.read_csv(file_path, skiprows=header_lines-1)\n",
    "    \n",
    "    print(f\"Found {len(sample_tags)} sample tags\")\n",
    "    return sample_tags\n",
    "\n",
    "def read_expression_data(file_path):\n",
    "    \"\"\"\n",
    "    Read the expression data file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the expression data file\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (gene_expression_matrix, protein_expression_matrix, gene_names, protein_names, cell_indices)\n",
    "    \"\"\"\n",
    "    print(f\"Reading expression data from {os.path.basename(file_path)}...\")\n",
    "    \n",
    "    # Count header lines to skip\n",
    "    header_lines = 0\n",
    "    header_line = \"\"\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        for line in f:\n",
    "            header_lines += 1\n",
    "            if line.startswith(\"Cell_Index\"):\n",
    "                header_line = line\n",
    "                break\n",
    "    \n",
    "    print(f\"Found header at line {header_lines}\")\n",
    "    \n",
    "    # Read the header to get gene and protein names\n",
    "    header_parts = header_line.strip().split(',')\n",
    "    \n",
    "    # Identify protein columns (they have a specific format with | characters)\n",
    "    protein_pattern = re.compile(r'.*\\|.*\\|.*\\|.*')\n",
    "    protein_indices = [i for i, col in enumerate(header_parts) if protein_pattern.match(col)]\n",
    "    \n",
    "    # The rest are gene columns (excluding the first Cell_Index column)\n",
    "    gene_indices = [i for i in range(1, len(header_parts)) if i not in protein_indices]\n",
    "    \n",
    "    # Get protein and gene names:\n",
    "    # First, split on \"|\" to get the primary protein name,\n",
    "    # then split on \":\" to remove any trailing parts.\n",
    "    protein_names = [header_parts[i].split('|')[0].split(':')[0] for i in protein_indices]\n",
    "    gene_names = [header_parts[i] for i in gene_indices]\n",
    "    \n",
    "    print(f\"Found {len(protein_names)} proteins and {len(gene_names)} genes\")\n",
    "    \n",
    "    # Read the data in chunks to handle large files\n",
    "    print(\"Reading data in chunks...\")\n",
    "    chunks = pd.read_csv(file_path, skiprows=header_lines, chunksize=1000)\n",
    "    \n",
    "    # Initialize empty lists to store data\n",
    "    cell_indices = []\n",
    "    gene_data = []\n",
    "    protein_data = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing chunk {i}...\")\n",
    "        \n",
    "        cell_indices.extend(chunk.iloc[:, 0].values)\n",
    "        \n",
    "        # Extract gene expression data\n",
    "        gene_chunk = chunk.iloc[:, gene_indices].values\n",
    "        gene_data.append(gene_chunk)\n",
    "        \n",
    "        # Extract protein expression data\n",
    "        protein_chunk = chunk.iloc[:, protein_indices].values\n",
    "        protein_data.append(protein_chunk)\n",
    "    \n",
    "    # Combine chunks\n",
    "    print(\"Combining chunks...\")\n",
    "    gene_expression = np.vstack(gene_data)\n",
    "    protein_expression = np.vstack(protein_data)\n",
    "    \n",
    "    print(f\"Processed {len(cell_indices)} cells\")\n",
    "    \n",
    "    return gene_expression, protein_expression, gene_names, protein_names, cell_indices\n",
    "\n",
    "def process_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    Process the GSE279775 dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the data\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (gene_anndata, protein_anndata)\n",
    "    \"\"\"\n",
    "    # Find all RSEC_mols files (gene expression)\n",
    "    rsec_files = glob.glob(os.path.join(data_dir, \"*RSEC_mols.csv.gz\"))\n",
    "    \n",
    "    # Find all SampleTagCalls files (metadata)\n",
    "    tag_files = glob.glob(os.path.join(data_dir, \"*SampleTagCalls.csv.gz\"))\n",
    "    \n",
    "    # Find all feature_reference files (protein info)\n",
    "    feature_files = glob.glob(os.path.join(data_dir, \"*feature_reference.csv.gz\"))\n",
    "    \n",
    "    # Create dictionary to store data by sample\n",
    "    samples = {}\n",
    "    \n",
    "    # Process each sample\n",
    "    for rsec_file in rsec_files:\n",
    "        sample_id = os.path.basename(rsec_file).split('_RSEC')[0]\n",
    "        print(f\"\\nProcessing sample: {sample_id}\")\n",
    "        \n",
    "        # Find corresponding tag and feature files\n",
    "        tag_file = next((f for f in tag_files if sample_id in f), None)\n",
    "        feature_file = next((f for f in feature_files if sample_id in f), None)\n",
    "        \n",
    "        if not tag_file or not feature_file:\n",
    "            print(f\"Warning: Missing metadata files for {sample_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Read data\n",
    "        gene_expr, protein_expr, gene_names, protein_names, cell_indices = read_expression_data(rsec_file)\n",
    "        sample_tags = read_sample_tags(tag_file)\n",
    "        feature_ref = read_feature_reference(feature_file)\n",
    "        \n",
    "        # Create cell metadata with unique observation names by combining sample ID and cell index\n",
    "        unique_cell_ids = [f\"{sample_id}_{str(idx)}\" for idx in cell_indices]\n",
    "        cell_metadata = pd.DataFrame(index=unique_cell_ids)\n",
    "        \n",
    "        # Add sample tags to metadata\n",
    "        sample_tags_dict = dict(zip(sample_tags['Cell_Index'], sample_tags['Sample_Name']))\n",
    "        cell_metadata['sample'] = [sample_tags_dict.get(idx, 'Unknown') for idx in cell_indices]\n",
    "        \n",
    "        # Extract condition and tissue information from sample name and tags\n",
    "        donor_id = sample_id.split('_')[0]\n",
    "        condition = 'Control' if 'Control' in sample_id else 'HIV'\n",
    "        cell_metadata['donor_id'] = donor_id\n",
    "        cell_metadata['condition'] = condition\n",
    "        \n",
    "        # Extract tissue information from sample tags if available\n",
    "        tissues = []\n",
    "        for idx in cell_indices:\n",
    "            tag = sample_tags_dict.get(idx, '')\n",
    "            if 'ECX' in tag:\n",
    "                tissues.append('Ectocervix')\n",
    "            elif 'END' in tag:\n",
    "                tissues.append('Endocervix')\n",
    "            elif 'EM' in tag:\n",
    "                tissues.append('Endometrium')\n",
    "            else:\n",
    "                tissues.append('Unknown')\n",
    "        cell_metadata['tissue'] = tissues\n",
    "        \n",
    "        # Create AnnData objects using the unique cell IDs\n",
    "        gene_adata = ad.AnnData(\n",
    "            X=sparse.csr_matrix(gene_expr),\n",
    "            obs=cell_metadata.copy(),\n",
    "            var=pd.DataFrame(index=gene_names)\n",
    "        )\n",
    "        \n",
    "        protein_adata = ad.AnnData(\n",
    "            X=sparse.csr_matrix(protein_expr),\n",
    "            obs=cell_metadata.copy(),\n",
    "            var=pd.DataFrame(index=protein_names)\n",
    "        )\n",
    "        \n",
    "        # Add protein metadata from feature reference\n",
    "        protein_var = pd.DataFrame(index=protein_names)\n",
    "        for protein in protein_names:\n",
    "            if protein in feature_ref['Name'].values:\n",
    "                row = feature_ref[feature_ref['Name'] == protein].iloc[0]\n",
    "                protein_var.loc[protein, 'Sequence'] = row['Sequence']\n",
    "                protein_var.loc[protein, 'Feature_Type'] = row['Feature_Type']\n",
    "        protein_adata.var = protein_var\n",
    "        \n",
    "        # Store in samples dictionary\n",
    "        samples[sample_id] = {\n",
    "            'gene': gene_adata,\n",
    "            'protein': protein_adata\n",
    "        }\n",
    "    \n",
    "    # Combine all samples\n",
    "    all_gene_adatas = [sample_data['gene'] for sample_data in samples.values()]\n",
    "    all_protein_adatas = [sample_data['protein'] for sample_data in samples.values()]\n",
    "    \n",
    "    combined_gene_adata = ad.concat(all_gene_adatas, join='outer', merge='same')\n",
    "    combined_protein_adata = ad.concat(all_protein_adatas, join='outer', merge='same')\n",
    "    \n",
    "    return combined_gene_adata, combined_protein_adata\n",
    "\n",
    "def harmonize_data(gene_adata, protein_adata):\n",
    "    \"\"\"\n",
    "    Harmonize the data according to specified standards.\n",
    "    \n",
    "    Args:\n",
    "        gene_adata: AnnData object with gene expression data\n",
    "        protein_adata: AnnData object with protein expression data\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (harmonized_gene_adata, harmonized_protein_adata)\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    gene_adata = gene_adata.copy()\n",
    "    protein_adata = protein_adata.copy()\n",
    "    \n",
    "    # Add standardized metadata fields\n",
    "    gene_adata.obs['organism'] = 'Homo sapiens'\n",
    "    protein_adata.obs['organism'] = 'Homo sapiens'\n",
    "    \n",
    "    gene_adata.obs['cell_type'] = 'Dendritic cells'\n",
    "    protein_adata.obs['cell_type'] = 'Dendritic cells'\n",
    "    \n",
    "    gene_adata.obs['crispr_type'] = 'None'\n",
    "    protein_adata.obs['crispr_type'] = 'None'\n",
    "    \n",
    "    gene_adata.obs['cancer_type'] = 'Non-Cancer'\n",
    "    protein_adata.obs['cancer_type'] = 'Non-Cancer'\n",
    "    \n",
    "    # Ensure 'condition' is a string\n",
    "    gene_adata.obs['condition'] = gene_adata.obs['condition'].astype(str)\n",
    "    protein_adata.obs['condition'] = protein_adata.obs['condition'].astype(str)\n",
    "    \n",
    "    # Add perturbation name based on condition\n",
    "    gene_adata.obs['perturbation_name'] = gene_adata.obs['condition'].apply(\n",
    "        lambda x: 'HIV-1' if x == 'HIV' else 'None'\n",
    "    )\n",
    "    protein_adata.obs['perturbation_name'] = protein_adata.obs['condition'].apply(\n",
    "        lambda x: 'HIV-1' if x == 'HIV' else 'None'\n",
    "    )\n",
    "    \n",
    "    # Filter for cells that are in both gene and protein data\n",
    "    common_cells = gene_adata.obs_names.intersection(protein_adata.obs_names)\n",
    "    gene_adata = gene_adata[common_cells]\n",
    "    protein_adata = protein_adata[common_cells]\n",
    "    \n",
    "    # Make variable names unique if needed\n",
    "    if gene_adata.var_names.duplicated().any():\n",
    "        print(\"Found duplicate gene names. Making them unique...\")\n",
    "        gene_adata.var_names_make_unique()\n",
    "    if protein_adata.var_names.duplicated().any():\n",
    "        print(\"Found duplicate protein names. Making them unique...\")\n",
    "        protein_adata.var_names_make_unique()\n",
    "    \n",
    "    return gene_adata, protein_adata\n",
    "\n",
    "def main(data_dir=\"GSE279775\"):\n",
    "    \"\"\"\n",
    "    Run the full pipeline: download, process, and harmonize the dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory to store or locate the dataset\n",
    "    \"\"\"\n",
    "    # Download data if needed\n",
    "    download_data(data_dir)\n",
    "    \n",
    "    # Process the dataset\n",
    "    gene_adata, protein_adata = process_dataset(data_dir)\n",
    "    \n",
    "    # Harmonize the data\n",
    "    gene_adata, protein_adata = harmonize_data(gene_adata, protein_adata)\n",
    "    \n",
    "    # Save the harmonized data\n",
    "    gene_output = os.path.join(data_dir, \"GSE279775_gene_expression.h5ad\")\n",
    "    protein_output = os.path.join(data_dir, \"GSE279775_protein_expression.h5ad\")\n",
    "    gene_adata.write_h5ad(gene_output)\n",
    "    protein_adata.write_h5ad(protein_output)\n",
    "    \n",
    "    print(f\"\\nGene expression data shape: {gene_adata.shape}\")\n",
    "    print(f\"Protein expression data shape: {protein_adata.shape}\")\n",
    "    print(f\"Harmonized data saved to {data_dir}\")\n",
    "    \n",
    "    # Print summary of the data\n",
    "    print(\"\\nGene expression data summary:\")\n",
    "    print(f\"Number of cells: {gene_adata.n_obs}\")\n",
    "    print(f\"Number of genes: {gene_adata.n_vars}\")\n",
    "    print(f\"Conditions: {gene_adata.obs['condition'].unique()}\")\n",
    "    print(f\"Tissues: {gene_adata.obs['tissue'].unique()}\")\n",
    "    \n",
    "    print(\"\\nProtein expression data summary:\")\n",
    "    print(f\"Number of cells: {protein_adata.n_obs}\")\n",
    "    print(f\"Number of proteins: {protein_adata.n_vars}\")\n",
    "    \n",
    "    return gene_adata, protein_adata\n",
    "\n",
    "# Run the pipeline in the notebook\n",
    "gene_adata, protein_adata = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a838de-845c-4b24-ad68-772ecf4637f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
