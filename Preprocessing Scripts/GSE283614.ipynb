{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0eb760-fe4d-4641-903f-0da344a7d72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "import anndata\n",
    "import gzip\n",
    "import urllib.request\n",
    "import warnings\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants\n",
    "GEO_URL = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE283nnn/GSE283614/suppl\"\n",
    "FILE_PREFIXES = [\"GSE283614_ESC_perturb-seq\", \"GSE283614_DE_perturb-seq\"]\n",
    "FILE_SUFFIXES = [\"_barcodes.tsv.gz\", \"_features.tsv.gz\", \"_matrix.mtx.gz\"]\n",
    "\n",
    "def download_files(data_dir):\n",
    "    \"\"\"\n",
    "    Download the necessary files from GEO if they don't exist.\n",
    "    \"\"\"\n",
    "    print(f\"Checking for required files in {data_dir}...\")\n",
    "    for prefix in FILE_PREFIXES:\n",
    "        for suffix in FILE_SUFFIXES:\n",
    "            filename = f\"{prefix}{suffix}\"\n",
    "            filepath = os.path.join(data_dir, filename)\n",
    "            if not os.path.exists(filepath):\n",
    "                print(f\"Downloading {filename}...\")\n",
    "                url = f\"{GEO_URL}/{filename}\"\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(url, filepath)\n",
    "                    print(f\"Downloaded {filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error downloading {filename}: {e}\")\n",
    "            else:\n",
    "                print(f\"File {filename} already exists\")\n",
    "\n",
    "def read_mtx_files(data_dir, prefix):\n",
    "    \"\"\"\n",
    "    Read 10X-style mtx files and create an AnnData object.\n",
    "    \"\"\"\n",
    "    print(f\"Reading {prefix} files...\")\n",
    "    matrix_file = os.path.join(data_dir, f\"{prefix}_matrix.mtx.gz\")\n",
    "    features_file = os.path.join(data_dir, f\"{prefix}_features.tsv.gz\")\n",
    "    barcodes_file = os.path.join(data_dir, f\"{prefix}_barcodes.tsv.gz\")\n",
    "    \n",
    "    print(f\"Reading features from {features_file}...\")\n",
    "    with gzip.open(features_file, 'rt') as f:\n",
    "        feature_df = pd.read_csv(f, sep='\\t', header=None)\n",
    "    \n",
    "    print(f\"Reading barcodes from {barcodes_file}...\")\n",
    "    with gzip.open(barcodes_file, 'rt') as f:\n",
    "        barcodes = pd.read_csv(f, sep='\\t', header=None)[0].values\n",
    "    \n",
    "    var = pd.DataFrame({\n",
    "        'gene_id': feature_df[0].values,\n",
    "        'gene_name': feature_df[1].values,\n",
    "        'feature_type': feature_df[2].values if feature_df.shape[1] > 2 else 'Gene Expression'\n",
    "    })\n",
    "    var.index = var['gene_name'].values\n",
    "    \n",
    "    print(f\"Reading matrix from {matrix_file}...\")\n",
    "    matrix = scipy.io.mmread(matrix_file).T.tocsr()\n",
    "    \n",
    "    print(f\"Creating AnnData object with shape {matrix.shape}...\")\n",
    "    adata = anndata.AnnData(X=matrix, var=var)\n",
    "    adata.obs_names = barcodes\n",
    "    \n",
    "    gc.collect()\n",
    "    return adata\n",
    "\n",
    "def infer_perturbation_groups(adata, target_genes=['POU5F1', 'NANOG']):\n",
    "    \"\"\"\n",
    "    Infer perturbation groups based on expression patterns of target genes.\n",
    "    \"\"\"\n",
    "    print(\"Inferring perturbation groups based on expression patterns...\")\n",
    "    \n",
    "    # Save raw counts\n",
    "    if scipy.sparse.issparse(adata.X):\n",
    "        adata.layers['counts'] = adata.X.copy()\n",
    "    else:\n",
    "        adata.layers['counts'] = scipy.sparse.csr_matrix(adata.X.copy())\n",
    "    \n",
    "    # Normalize and log-transform\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    \n",
    "    available_targets = [gene for gene in target_genes if gene in adata.var_names]\n",
    "    if not available_targets:\n",
    "        print(f\"Warning: None of the target genes {target_genes} found in dataset\")\n",
    "        adata.obs['inferred_perturbation'] = 'Unknown'\n",
    "        adata.obs['condition'] = 'Unknown'\n",
    "        return adata\n",
    "    \n",
    "    print(f\"Found target genes: {available_targets}\")\n",
    "    perturbation_status = pd.DataFrame(index=adata.obs_names)\n",
    "    \n",
    "    for gene in available_targets:\n",
    "        if gene in adata.var_names:\n",
    "            print(f\"Processing gene {gene}...\")\n",
    "            gene_expr = adata[:, gene].X.toarray().flatten()\n",
    "            low_threshold = np.quantile(gene_expr, 0.33)\n",
    "            high_threshold = np.quantile(gene_expr, 0.67)\n",
    "            perturbation_status[f\"{gene}_status\"] = pd.cut(\n",
    "                gene_expr,\n",
    "                bins=[float('-inf'), low_threshold, high_threshold, float('inf')],\n",
    "                labels=['low', 'mid', 'high']\n",
    "            )\n",
    "            print(f\"Gene {gene} expression quantiles: low < {low_threshold:.2f}, high > {high_threshold:.2f}\")\n",
    "            del gene_expr\n",
    "            gc.collect()\n",
    "    \n",
    "    print(\"Creating perturbation labels...\")\n",
    "    def combine_perturbations(row):\n",
    "        return '+'.join([f\"{gene}_{row[f'{gene}_status']}\" for gene in available_targets])\n",
    "    \n",
    "    adata.obs['inferred_perturbation'] = perturbation_status.apply(combine_perturbations, axis=1)\n",
    "    \n",
    "    print(\"Assigning condition labels...\")\n",
    "    def assign_condition(pert):\n",
    "        if any('_low' in p for p in pert.split('+')):\n",
    "            return 'Perturbed'\n",
    "        else:\n",
    "            return 'Control'\n",
    "    \n",
    "    adata.obs['condition'] = adata.obs['inferred_perturbation'].apply(assign_condition)\n",
    "    \n",
    "    pert_counts = adata.obs['inferred_perturbation'].value_counts()\n",
    "    print(\"\\nInferred perturbation groups:\")\n",
    "    for pert, count in pert_counts.items():\n",
    "        print(f\"  {pert}: {count} cells\")\n",
    "    \n",
    "    adata.uns['perturbation_note'] = (\n",
    "        \"Perturbation assignments are inferred from gene expression patterns \"\n",
    "        \"and should be considered preliminary. For accurate perturbation information, \"\n",
    "        \"the guide RNA readout data should be integrated when available.\"\n",
    "    )\n",
    "    \n",
    "    del perturbation_status\n",
    "    gc.collect()\n",
    "    return adata\n",
    "\n",
    "def extract_perturbation_info(adata, cell_type):\n",
    "    \"\"\"\n",
    "    Add metadata and infer perturbation information for the dataset.\n",
    "    \"\"\"\n",
    "    print(f\"Adding metadata for {cell_type} dataset...\")\n",
    "    adata.obs['organism'] = 'Homo sapiens'\n",
    "    adata.obs['cell_type'] = 'Embryonic Stem Cells' if cell_type == 'ESC' else 'Definitive Endoderm'\n",
    "    adata.obs['crispr_type'] = 'CRISPR KO'\n",
    "    adata.obs['cancer_type'] = 'Non-Cancer'\n",
    "    \n",
    "    adata = infer_perturbation_groups(adata, target_genes=['POU5F1', 'NANOG'])\n",
    "    \n",
    "    print(\"Creating perturbation_name field...\")\n",
    "    adata.obs['perturbation_name'] = adata.obs['inferred_perturbation'].apply(\n",
    "        lambda x: x.replace('_low', ' KO').replace('_mid', '').replace('_high', ' OE').replace('+', ' + ')\n",
    "    )\n",
    "    \n",
    "    # ---- Ad hoc modifications start here ----\n",
    "    # Convert 'condition' to string type\n",
    "    adata.obs[\"condition\"] = adata.obs[\"condition\"].astype(str)\n",
    "    # Update values where 'condition' is 'Perturbed' to 'Test'\n",
    "    adata.obs.loc[adata.obs[\"condition\"] == \"Perturbed\", \"condition\"] = \"Test\"\n",
    "    # Convert back to categorical (if needed)\n",
    "    adata.obs[\"condition\"] = adata.obs[\"condition\"].astype(\"category\")\n",
    "    \n",
    "    # Remove \"KO\" and \"OE\" as whole words from the 'perturbation_name' column\n",
    "    adata.obs['perturbation_name'] = adata.obs['perturbation_name'].str.replace(r'\\b(KO|OE)\\b', '', regex=True)\n",
    "    # Clean up extra spaces that may result from the removal\n",
    "    adata.obs['perturbation_name'] = adata.obs['perturbation_name'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "    \n",
    "    # Set perturbation_name to \"Non-Targeting\" where condition is \"Control\"\n",
    "    adata.obs.loc[adata.obs['condition'] == 'Control', 'perturbation_name'] = 'Non-Targeting'\n",
    "    # ---- Ad hoc modifications end here ----\n",
    "    \n",
    "    adata.uns['dataset_id'] = 'GSE283614'\n",
    "    adata.uns['dataset_name'] = 'Enhancer perturbations of OCT4 and NANOG in human ESCs'\n",
    "    adata.uns['dataset_description'] = (\n",
    "        \"Single cell perturb-seq of OCT4 and NANOG enhancer perturbation library on \"\n",
    "        \"embryonic stem cell and definitive endoderm\"\n",
    "    )\n",
    "    return adata\n",
    "\n",
    "def process_dataset(data_dir, dataset_type):\n",
    "    \"\"\"\n",
    "    Process a single dataset (ESC or DE) and save it as an h5ad file.\n",
    "    \"\"\"\n",
    "    print(f\"Processing {dataset_type} data...\")\n",
    "    output_dir = os.path.join(data_dir, \"harmonized\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(output_dir, f\"GSE283614_{dataset_type}_harmonized.h5ad\")\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Harmonized {dataset_type} dataset already exists at {output_file}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        adata = read_mtx_files(data_dir, f\"GSE283614_{dataset_type}_perturb-seq\")\n",
    "        adata = extract_perturbation_info(adata, dataset_type)\n",
    "        adata.obs['dataset_origin'] = dataset_type\n",
    "        \n",
    "        print(f\"Saving {dataset_type} dataset to {output_file}...\")\n",
    "        adata.write(output_file)\n",
    "        print(f\"{dataset_type} dataset: {adata.shape[0]} cells, {adata.shape[1]} genes\")\n",
    "        del adata\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {dataset_type} dataset: {e}\")\n",
    "        print(f\"Skipping {dataset_type} dataset\")\n",
    "\n",
    "def create_combined_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    Combine the processed ESC and DE datasets and save the result.\n",
    "    \"\"\"\n",
    "    print(\"Creating combined dataset...\")\n",
    "    output_dir = os.path.join(data_dir, \"harmonized\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(output_dir, \"GSE283614_combined_harmonized.h5ad\")\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Combined dataset already exists at {output_file}\")\n",
    "        return\n",
    "    \n",
    "    esc_file = os.path.join(output_dir, \"GSE283614_ESC_harmonized.h5ad\")\n",
    "    de_file = os.path.join(output_dir, \"GSE283614_DE_harmonized.h5ad\")\n",
    "    \n",
    "    has_esc = os.path.exists(esc_file)\n",
    "    has_de = os.path.exists(de_file)\n",
    "    \n",
    "    if not has_esc and not has_de:\n",
    "        print(\"No processed datasets found. Cannot create combined dataset.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        if has_esc and has_de:\n",
    "            print(f\"Loading ESC dataset from {esc_file}...\")\n",
    "            esc_adata = anndata.read_h5ad(esc_file)\n",
    "            print(f\"Loading DE dataset from {de_file}...\")\n",
    "            de_adata = anndata.read_h5ad(de_file)\n",
    "            print(\"Combining ESC and DE datasets...\")\n",
    "            combined_adata = anndata.AnnData.concatenate(\n",
    "                esc_adata, de_adata,\n",
    "                join='outer',\n",
    "                batch_key='batch',\n",
    "                batch_categories=['ESC', 'DE']\n",
    "            )\n",
    "            del esc_adata, de_adata\n",
    "            gc.collect()\n",
    "        elif has_esc:\n",
    "            print(f\"Loading ESC dataset from {esc_file}...\")\n",
    "            combined_adata = anndata.read_h5ad(esc_file)\n",
    "            combined_adata.uns['de_dataset_note'] = (\n",
    "                \"The DE dataset could not be processed. \"\n",
    "                \"This combined dataset contains only the ESC data.\"\n",
    "            )\n",
    "        elif has_de:\n",
    "            print(f\"Loading DE dataset from {de_file}...\")\n",
    "            combined_adata = anndata.read_h5ad(de_file)\n",
    "            combined_adata.uns['esc_dataset_note'] = (\n",
    "                \"The ESC dataset could not be processed. \"\n",
    "                \"This combined dataset contains only the DE data.\"\n",
    "            )\n",
    "        \n",
    "        print(f\"Saving combined dataset to {output_file}...\")\n",
    "        combined_adata.write(output_file)\n",
    "        print(f\"Combined dataset: {combined_adata.shape[0]} cells, {combined_adata.shape[1]} genes\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating combined dataset: {e}\")\n",
    "\n",
    "def harmonize_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    Harmonize the GSE283614 dataset into h5ad format.\n",
    "    \"\"\"\n",
    "    print(f\"Processing data in {data_dir}\")\n",
    "    download_files(data_dir)\n",
    "    process_dataset(data_dir, \"ESC\")\n",
    "    process_dataset(data_dir, \"DE\")\n",
    "    create_combined_dataset(data_dir)\n",
    "    print(\"\\nHarmonization complete!\")\n",
    "    print(f\"Harmonized data saved to {os.path.join(data_dir, 'harmonized')}\")\n",
    "\n",
    "# Set the data directory (change this to your desired path)\n",
    "data_dir = \"/content\"  # e.g., \"./data\" or an absolute path\n",
    "\n",
    "# Run the harmonization\n",
    "harmonize_dataset(data_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
