{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef4da77-4a20-402d-86ec-0b21b75d8d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonization script for GSE274751 dataset (adapted for Jupyter Notebook)\n",
    "#\n",
    "# This notebook cell processes the GSE274751 dataset (CRISPR-Cas9 perturb-seq data of CD4+ T cells)\n",
    "# and harmonizes it into a standardized h5ad format with specific metadata.\n",
    "#\n",
    "# It now also downloads the required dataset files if they are not present, and forces the \"condition\"\n",
    "# column in .obs to be \"Test\" for all cells.\n",
    "#\n",
    "# Instructions:\n",
    "# 1. Update the `data_path` variable with the path to your dataset folder.\n",
    "# 2. Run the cell.\n",
    "#\n",
    "# The script will:\n",
    "#   - Download dataset files (if needed)\n",
    "#   - Load the dataset files\n",
    "#   - Extract and standardize metadata (with condition always set to \"Test\")\n",
    "#   - Create a harmonized h5ad file with standardized .obs attributes\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import anndata\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def download_dataset(data_path):\n",
    "    \"\"\"Download the GSE274751 dataset files.\"\"\"\n",
    "    # Define the files to download\n",
    "    files = [\n",
    "        \"GSE274751_tfko.sng.guides.full.ct.h5ad\",\n",
    "        \"GSE274751_feature_reference.csv.gz\",\n",
    "        \"GSE274751_HTEC_counts.h5ad\"\n",
    "    ]\n",
    "\n",
    "    # Base URL for the GEO dataset\n",
    "    base_url = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE274nnn/GSE274751/suppl/\"\n",
    "\n",
    "    # Create the data directory if it doesn't exist\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "    # Download each file\n",
    "    for file in files:\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        if os.path.exists(file_path):\n",
    "            file_size = os.path.getsize(file_path) / (1024 * 1024)  # Size in MB\n",
    "            print(f\"File {file} already exists ({file_size:.1f} MB). Skipping download.\")\n",
    "            continue\n",
    "\n",
    "        url = f\"{base_url}{file}\"\n",
    "        print(f\"Downloading {file} from {url}...\")\n",
    "\n",
    "        try:\n",
    "            import urllib.request\n",
    "            urllib.request.urlretrieve(url, file_path)\n",
    "            file_size = os.path.getsize(file_path) / (1024 * 1024)  # Size in MB\n",
    "            print(f\"Downloaded {file} ({file_size:.1f} MB)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {file}: {e}\")\n",
    "            if os.path.exists(file_path):\n",
    "                os.remove(file_path)  # Remove partial download\n",
    "\n",
    "    # Check if the main file exists\n",
    "    main_file = os.path.join(data_path, \"GSE274751_tfko.sng.guides.full.ct.h5ad\")\n",
    "    if not os.path.exists(main_file):\n",
    "        print(f\"Error: Main dataset file {main_file} not found. Cannot proceed with harmonization.\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def extract_categories(file_path, category_name):\n",
    "    \"\"\"Extract category values from h5ad file.\"\"\"\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        if f'uns/{category_name}_categories' in f:\n",
    "            categories = f[f'uns/{category_name}_categories'][:]\n",
    "            return [c.decode('utf-8') if isinstance(c, bytes) else c for c in categories]\n",
    "        return None\n",
    "\n",
    "def extract_guide_info(file_path):\n",
    "    \"\"\"Extract guide information from h5ad file.\"\"\"\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        guide_categories = {}\n",
    "        for i in range(1, 5):  # Guide 1-4\n",
    "            key = f'guide{i}_cov_categories'\n",
    "            if f'uns/{key}' in f:\n",
    "                categories = f[f'uns/{key}'][:]\n",
    "                guide_categories[f'guide{i}'] = [c.decode('utf-8') if isinstance(c, bytes) else c for c in categories]\n",
    "        return guide_categories\n",
    "\n",
    "def parse_guide_name(guide_name):\n",
    "    \"\"\"Parse guide name to extract gene and guide information.\"\"\"\n",
    "    if not guide_name or guide_name == '280':  # Handle special case\n",
    "        return None, None\n",
    "    \n",
    "    # The guide names are in format: GENE.POSITION.SEQUENCE\n",
    "    # Example: ARID5A.96550280.CCCCGCCGTACCTCTCGTAG\n",
    "    parts = guide_name.split('.')\n",
    "    if len(parts) >= 1:\n",
    "        gene = parts[0]\n",
    "        return gene, guide_name\n",
    "    return None, guide_name\n",
    "\n",
    "def create_harmonized_dataset(data_path):\n",
    "    \"\"\"\n",
    "    Create a harmonized h5ad file from the GSE274751 dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_path : str\n",
    "        Path to the folder containing the dataset files\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    anndata.AnnData\n",
    "        Harmonized dataset\n",
    "    \"\"\"\n",
    "    # Define file paths\n",
    "    tfko_file = os.path.join(data_path, \"GSE274751_tfko.sng.guides.full.ct.h5ad\")\n",
    "    \n",
    "    # Load the dataset using h5py for metadata extraction\n",
    "    print(f\"Loading dataset from {tfko_file}...\")\n",
    "    \n",
    "    # Extract metadata\n",
    "    ct_categories = extract_categories(tfko_file, 'ct')\n",
    "    donor_categories = extract_categories(tfko_file, 'donor')\n",
    "    guide_info = extract_guide_info(tfko_file)\n",
    "    \n",
    "    # Load the dataset using anndata\n",
    "    try:\n",
    "        adata = anndata.read_h5ad(tfko_file)\n",
    "        print(f\"Successfully loaded dataset with shape {adata.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset with anndata: {e}\")\n",
    "        print(\"Attempting to create anndata object manually...\")\n",
    "        \n",
    "        # Create anndata object manually\n",
    "        with h5py.File(tfko_file, 'r') as f:\n",
    "            if 'X' in f and 'data' in f['X'] and 'indices' in f['X'] and 'indptr' in f['X']:\n",
    "                from scipy import sparse\n",
    "                data = f['X/data'][:]\n",
    "                indices = f['X/indices'][:]\n",
    "                indptr = f['X/indptr'][:]\n",
    "                shape = f['X'].attrs['h5sparse_shape']\n",
    "                X = sparse.csr_matrix((data, indices, indptr), shape=shape)\n",
    "                \n",
    "                # Load obs and var data\n",
    "                obs_data = f['obs'][:]\n",
    "                var_data = f['var'][:]\n",
    "                \n",
    "                # Convert to pandas DataFrames\n",
    "                obs_df = pd.DataFrame(obs_data)\n",
    "                var_df = pd.DataFrame(var_data)\n",
    "                \n",
    "                adata = anndata.AnnData(X=X, obs=obs_df, var=var_df)\n",
    "                print(f\"Successfully created anndata object with shape {adata.shape}\")\n",
    "            else:\n",
    "                raise ValueError(\"Could not find required data in the h5ad file\")\n",
    "    \n",
    "    # Process and harmonize metadata\n",
    "    print(\"Harmonizing metadata...\")\n",
    "    \n",
    "    # Create new standardized metadata DataFrame\n",
    "    harmonized_obs = pd.DataFrame(index=adata.obs.index)\n",
    "    \n",
    "    # 1. Organism\n",
    "    harmonized_obs['organism'] = 'Homo sapiens'\n",
    "    \n",
    "    # 2. Cell Type\n",
    "    if 'ct' in adata.obs.columns and ct_categories:\n",
    "        harmonized_obs['cell_type'] = adata.obs['ct'].astype('category').cat.rename_categories(ct_categories)\n",
    "    else:\n",
    "        harmonized_obs['cell_type'] = 'CD4+ T cell'  # Default based on dataset description\n",
    "    \n",
    "    # 3. CRISPR Type\n",
    "    harmonized_obs['crispr_type'] = 'CRISPR KO'\n",
    "    \n",
    "    # 4. Cancer Type\n",
    "    harmonized_obs['cancer_type'] = 'Non-Cancer'\n",
    "    \n",
    "    # 5. Condition: Force condition to \"Test\" for all cells\n",
    "    harmonized_obs['condition'] = 'Test'\n",
    "    \n",
    "    # 6. Perturbation Name: Extract perturbation information from guide columns\n",
    "    perturbation_genes = []\n",
    "    for i, cell_idx in enumerate(adata.obs.index):\n",
    "        cell_guides = []\n",
    "        # Even if there's a WT column, we force \"Test\", so we still extract guide data\n",
    "        for guide_num in range(1, 5):  # Check guides 1-4\n",
    "            guide_col = f'guide{guide_num}_cov'\n",
    "            if guide_col in adata.obs.columns:\n",
    "                guide_value = adata.obs[guide_col].iloc[i]\n",
    "                if isinstance(guide_value, str) and guide_value != 'nan' and '.' in guide_value:\n",
    "                    gene, _ = parse_guide_name(guide_value)\n",
    "                    if gene and gene not in cell_guides:\n",
    "                        cell_guides.append(gene)\n",
    "        if not cell_guides:\n",
    "            perturbation_genes.append('Non-targeting')\n",
    "        else:\n",
    "            perturbation_genes.append(' + '.join(sorted(cell_guides)))\n",
    "    \n",
    "    unique_perturbations = set(perturbation_genes)\n",
    "    print(f\"Found {len(unique_perturbations)} unique perturbations\")\n",
    "    if len(unique_perturbations) > 1:\n",
    "        print(f\"Sample of perturbations: {list(unique_perturbations)[:10]}\")\n",
    "    else:\n",
    "        print(\"Warning: Only found 'Non-targeting' perturbations. Check the guide data.\")\n",
    "    \n",
    "    harmonized_obs['perturbation_name'] = perturbation_genes\n",
    "    \n",
    "    # Add donor information if available\n",
    "    if 'donor' in adata.obs.columns and donor_categories:\n",
    "        harmonized_obs['donor'] = adata.obs['donor'].astype('category').cat.rename_categories(donor_categories)\n",
    "    \n",
    "    # Add additional metrics if available\n",
    "    for col in ['numi', 'n_genes', 'percent_mito', 'percent_ribo', 'percent_hist']:\n",
    "        if col in adata.obs.columns:\n",
    "            harmonized_obs[col] = adata.obs[col]\n",
    "    \n",
    "    # Create the final harmonized AnnData object\n",
    "    harmonized_adata = anndata.AnnData(\n",
    "        X=adata.X,\n",
    "        obs=harmonized_obs,\n",
    "        var=adata.var,\n",
    "        uns=adata.uns\n",
    "    )\n",
    "    \n",
    "    # Optionally, store original obs metadata\n",
    "    harmonized_adata.uns['original_obs'] = adata.obs\n",
    "    \n",
    "    # Convert string columns to categorical for compatibility\n",
    "    for col in harmonized_obs.select_dtypes(include=['object']).columns:\n",
    "        if col != 'index':  # Skip index column\n",
    "            harmonized_obs[col] = harmonized_obs[col].astype('category')\n",
    "    \n",
    "    harmonized_adata.obs = harmonized_obs\n",
    "    \n",
    "    # Add categories to uns for categorical fields\n",
    "    for col in harmonized_obs.select_dtypes(include=['category']).columns:\n",
    "        harmonized_adata.uns[f'{col}_categories'] = np.array(harmonized_obs[col].cat.categories)\n",
    "    \n",
    "    print(f\"Harmonization complete. Final dataset shape: {harmonized_adata.shape}\")\n",
    "    return harmonized_adata\n",
    "\n",
    "# =========================\n",
    "# Set your data folder path here:\n",
    "data_path = \"/content/GSE274751\"  # <-- UPDATE this path accordingly\n",
    "\n",
    "# Download the dataset files if necessary\n",
    "print(f\"Checking for dataset files in {data_path}...\")\n",
    "if not download_dataset(data_path):\n",
    "    raise ValueError(\"Failed to download or locate the required dataset files.\")\n",
    "\n",
    "# Create harmonized dataset\n",
    "harmonized_adata = create_harmonized_dataset(data_path)\n",
    "\n",
    "# Save harmonized dataset to file in the same directory\n",
    "output_file = os.path.join(data_path, \"GSE274751_harmonized.h5ad\")\n",
    "print(f\"Saving harmonized dataset to {output_file}...\")\n",
    "harmonized_adata.write_h5ad(output_file)\n",
    "print(\"Harmonized dataset saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
