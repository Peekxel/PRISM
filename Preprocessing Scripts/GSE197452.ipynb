{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30c09d-2469-48af-96d5-7c0cae4d0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import shutil\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Constants\n",
    "GEO_ACCESSION = \"GSE197452\"\n",
    "DOWNLOAD_URL = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE197nnn/GSE197452/suppl/GSE197452_RAW.tar\"\n",
    "DATASETS = [\n",
    "    {\n",
    "        \"name\": \"3prime_PBMC_Illumina\",\n",
    "        \"files\": {\n",
    "            \"expression\": \"GSM6297378_expression_counts_Three_Ill.txt.gz\",\n",
    "            \"genes\": \"GSM6297378_genes_counts_Three_Ill.txt.gz\",\n",
    "            \"cells\": \"GSM6297378_cells_counts_Three_Ill.txt.gz\"\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"organism\": \"Homo sapiens\",\n",
    "            \"cell_type\": \"PBMC\",\n",
    "            \"crispr_type\": \"None\",\n",
    "            \"cancer_type\": \"Non-Cancer\",\n",
    "            \"condition\": \"control\",\n",
    "            \"perturbation_name\": \"None\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"5prime_PBMC_Illumina\",\n",
    "        \"files\": {\n",
    "            \"expression\": \"GSM6297380_expression_counts_Five_Ill.txt.gz\",\n",
    "            \"genes\": \"GSM6297380_genes_counts_Five_Ill.txt.gz\",\n",
    "            \"cells\": \"GSM6297380_cells_counts_Five_Ill.txt.gz\"\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"organism\": \"Homo sapiens\",\n",
    "            \"cell_type\": \"PBMC\",\n",
    "            \"crispr_type\": \"None\",\n",
    "            \"cancer_type\": \"Non-Cancer\",\n",
    "            \"condition\": \"control\",\n",
    "            \"perturbation_name\": \"None\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"5prime_PBMC_mixture_Illumina\",\n",
    "        \"files\": {\n",
    "            \"expression\": \"GSM6297382_expression_counts_FiveMix_Ill.txt.gz\",\n",
    "            \"genes\": \"GSM6297382_genes_counts_FiveMix_Ill.txt.gz\",\n",
    "            \"cells\": \"GSM6297382_cells_counts_FiveMix_Ill.txt.gz\"\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"organism\": \"Homo sapiens\",\n",
    "            \"cell_type\": \"PBMC\",\n",
    "            \"crispr_type\": \"None\",\n",
    "            \"cancer_type\": \"Non-Cancer\",\n",
    "            \"condition\": \"control\",\n",
    "            \"perturbation_name\": \"None\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Perturb-seq_Illumina\",\n",
    "        \"files\": {\n",
    "            \"h5\": \"GSM6297388_filtered_feature_bc_matrix.pert.ill.h5\"\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"organism\": \"Homo sapiens\",\n",
    "            \"cell_type\": \"K562\",\n",
    "            \"cancer_type\": \"Leukemia\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def download_data(data_dir):\n",
    "    \"\"\"Download the dataset if not already present.\"\"\"\n",
    "    download_dir = os.path.join(data_dir, \"download\")\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    \n",
    "    tar_file = os.path.join(download_dir, f\"{GEO_ACCESSION}_RAW.tar\")\n",
    "    \n",
    "    if not os.path.exists(tar_file):\n",
    "        print(f\"Downloading {GEO_ACCESSION} dataset...\")\n",
    "        urllib.request.urlretrieve(DOWNLOAD_URL, tar_file)\n",
    "        print(\"Download complete!\")\n",
    "    else:\n",
    "        print(f\"Dataset already downloaded at {tar_file}\")\n",
    "    \n",
    "    return tar_file\n",
    "\n",
    "def extract_data(tar_file, data_dir):\n",
    "    \"\"\"Extract the dataset files.\"\"\"\n",
    "    extract_dir = os.path.join(data_dir, \"extracted\")\n",
    "    \n",
    "    if os.path.exists(extract_dir) and len(os.listdir(extract_dir)) > 0:\n",
    "        print(f\"Data already extracted in {extract_dir}\")\n",
    "        return extract_dir\n",
    "    \n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Extracting files to {extract_dir}...\")\n",
    "    with tarfile.open(tar_file, 'r') as tar:\n",
    "        tar.extractall(path=extract_dir)\n",
    "    \n",
    "    print(\"Extraction complete!\")\n",
    "    return extract_dir\n",
    "\n",
    "def read_mtx_file(expression_file, genes_file, cells_file):\n",
    "    \"\"\"Read expression data from MTX format files.\"\"\"\n",
    "    print(f\"Reading expression data from {expression_file}\")\n",
    "    \n",
    "    with gzip.open(expression_file, 'rt') as f:\n",
    "        # Skip header lines until we get dimensions\n",
    "        for line in f:\n",
    "            if not line.startswith('%'):\n",
    "                dimensions = line.strip().split()\n",
    "                n_genes, n_cells, n_entries = map(int, dimensions)\n",
    "                break\n",
    "        \n",
    "        data = []\n",
    "        row_indices = []\n",
    "        col_indices = []\n",
    "        \n",
    "        with tqdm(total=n_entries, desc=\"Reading expression data\") as pbar:\n",
    "            for line in f:\n",
    "                gene_idx, cell_idx, value = line.strip().split()\n",
    "                row_indices.append(int(gene_idx) - 1)  # 0-based indexing\n",
    "                col_indices.append(int(cell_idx) - 1)    # 0-based indexing\n",
    "                data.append(float(value))\n",
    "                pbar.update(1)\n",
    "    \n",
    "    matrix = sparse.csr_matrix((data, (row_indices, col_indices)), shape=(n_genes, n_cells))\n",
    "    \n",
    "    print(f\"Reading genes metadata from {genes_file}\")\n",
    "    genes_df = pd.read_csv(genes_file, sep='\\t', header=None, names=['gene_id', 'gene_name', 'feature_type'])\n",
    "    \n",
    "    print(f\"Reading cells metadata from {cells_file}\")\n",
    "    cell_barcodes = pd.read_csv(cells_file, sep='\\t', header=None)[0].values\n",
    "    \n",
    "    if genes_df.shape[0] != n_genes:\n",
    "        print(f\"Warning: Number of genes in metadata ({genes_df.shape[0]}) doesn't match matrix dimensions ({n_genes})\")\n",
    "        if genes_df.shape[0] < n_genes:\n",
    "            print(f\"Adding {n_genes - genes_df.shape[0]} missing genes to metadata\")\n",
    "            missing_genes = pd.DataFrame({\n",
    "                'gene_id': [f'Unknown_{i}' for i in range(genes_df.shape[0], n_genes)],\n",
    "                'gene_name': [f'Unknown_{i}' for i in range(genes_df.shape[0], n_genes)],\n",
    "                'feature_type': ['Gene Expression'] * (n_genes - genes_df.shape[0])\n",
    "            })\n",
    "            genes_df = pd.concat([genes_df, missing_genes], ignore_index=True)\n",
    "        else:\n",
    "            print(\"Truncating gene metadata to match matrix dimensions\")\n",
    "            genes_df = genes_df.iloc[:n_genes]\n",
    "    \n",
    "    var_df = genes_df.copy()\n",
    "    var_df.index = var_df['gene_name']  # Use gene_name as index\n",
    "    \n",
    "    adata = ad.AnnData(X=matrix.T,  # cells x genes\n",
    "                       obs=pd.DataFrame(index=cell_barcodes),\n",
    "                       var=var_df)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def read_h5_file(h5_file):\n",
    "    \"\"\"Read expression data from 10x Genomics H5 file.\"\"\"\n",
    "    print(f\"Reading data from {h5_file}\")\n",
    "    \n",
    "    with h5py.File(h5_file, 'r') as f:\n",
    "        shape = f['matrix/shape'][:]\n",
    "        n_features, n_barcodes = shape\n",
    "        \n",
    "        data = f['matrix/data'][:]\n",
    "        indices = f['matrix/indices'][:]\n",
    "        indptr = f['matrix/indptr'][:]\n",
    "        \n",
    "        matrix = sparse.csc_matrix((data, indices, indptr), shape=shape).tocsr()\n",
    "        \n",
    "        feature_ids = f['matrix/features/id'][:]\n",
    "        feature_names = f['matrix/features/name'][:]\n",
    "        feature_types = f['matrix/features/feature_type'][:]\n",
    "        \n",
    "        # Convert byte strings to regular strings\n",
    "        feature_ids = [x.decode('utf-8') for x in feature_ids]\n",
    "        feature_names = [x.decode('utf-8') for x in feature_names]\n",
    "        feature_types = [x.decode('utf-8') for x in feature_types]\n",
    "        \n",
    "        barcodes = f['matrix/barcodes'][:]\n",
    "        barcodes = [x.decode('utf-8') for x in barcodes]\n",
    "    \n",
    "    gene_indices = np.where(np.array(feature_types) == 'Gene Expression')[0]\n",
    "    gene_matrix = matrix[gene_indices, :]\n",
    "    \n",
    "    gene_var = pd.DataFrame({\n",
    "        'feature_type': np.array(feature_types)[gene_indices],\n",
    "        'gene_id': np.array(feature_ids)[gene_indices],\n",
    "    }, index=np.array(feature_names)[gene_indices])\n",
    "    \n",
    "    if not gene_var.index.is_unique:\n",
    "        print(f\"Warning: Found {gene_var.index.duplicated().sum()} duplicate gene symbols\")\n",
    "        new_index = []\n",
    "        seen = set()\n",
    "        for idx, name in enumerate(gene_var.index):\n",
    "            if name in seen:\n",
    "                new_index.append(f\"{name}_{gene_var.iloc[idx]['gene_id']}\")\n",
    "            else:\n",
    "                new_index.append(name)\n",
    "                seen.add(name)\n",
    "        gene_var.index = new_index\n",
    "        print(f\"After making unique: {gene_var.index.duplicated().sum()} duplicates\")\n",
    "    \n",
    "    adata = ad.AnnData(X=gene_matrix.T,  # cells x genes\n",
    "                       obs=pd.DataFrame(index=barcodes),\n",
    "                       var=gene_var)\n",
    "    \n",
    "    # Extract CRISPR guide information\n",
    "    guide_indices = np.where(np.array(feature_types) == 'CRISPR Guide Capture')[0]\n",
    "    \n",
    "    if len(guide_indices) > 0:\n",
    "        guide_matrix = matrix[guide_indices, :]\n",
    "        guide_names = np.array(feature_names)[guide_indices]\n",
    "        \n",
    "        # For each cell, find the guide with the highest count\n",
    "        guide_assignments = {}\n",
    "        for i in range(guide_matrix.shape[1]):\n",
    "            cell_barcode = barcodes[i]\n",
    "            cell_guides = guide_matrix[:, i].toarray().flatten()\n",
    "            if np.sum(cell_guides) > 0:\n",
    "                max_guide_idx = np.argmax(cell_guides)\n",
    "                guide_name = guide_names[max_guide_idx]\n",
    "                guide_assignments[cell_barcode] = guide_name\n",
    "        \n",
    "        # Add guide information to obs\n",
    "        adata.obs['guide'] = pd.Series(guide_assignments)\n",
    "        \n",
    "        # Process guide names to extract perturbation targets\n",
    "        perturbation_map = {}\n",
    "        for barcode, guide in guide_assignments.items():\n",
    "            # If the guide indicates a non-targeting control, label as \"Non-targeting\"\n",
    "            if ('NON-GENE_SITE' in guide) or guide.startswith('NO_SITE') or (guide == 'Background'):\n",
    "                perturbation_map[barcode] = 'Non-targeting'\n",
    "            else:\n",
    "                parts = guide.split('_')\n",
    "                if len(parts) > 1 and parts[0]:\n",
    "                    perturbation_map[barcode] = parts[0]\n",
    "                else:\n",
    "                    perturbation_map[barcode] = guide\n",
    "        \n",
    "        # Add perturbation information to obs\n",
    "        adata.obs['perturbation_name'] = pd.Series(perturbation_map)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def harmonize_dataset(dataset, extract_dir, output_dir, accession):\n",
    "    \"\"\"Harmonize a single dataset.\"\"\"\n",
    "    print(f\"\\nProcessing {dataset['name']}...\")\n",
    "    \n",
    "    if 'h5' in dataset['files']:\n",
    "        h5_file = os.path.join(extract_dir, dataset['files']['h5'])\n",
    "        adata = read_h5_file(h5_file)\n",
    "    else:\n",
    "        expression_file = os.path.join(extract_dir, dataset['files']['expression'])\n",
    "        genes_file = os.path.join(extract_dir, dataset['files']['genes'])\n",
    "        cells_file = os.path.join(extract_dir, dataset['files']['cells'])\n",
    "        adata = read_mtx_file(expression_file, genes_file, cells_file)\n",
    "    \n",
    "    # Add standard metadata to each cell\n",
    "    for key, value in dataset['metadata'].items():\n",
    "        adata.obs[key] = value\n",
    "    \n",
    "    # Process perturbation information for Perturb-seq data\n",
    "    if 'guide' in adata.obs.columns:\n",
    "        adata.obs['crispr_type'] = 'CRISPR KO'\n",
    "        adata.obs['condition'] = 'unknown'\n",
    "        for cell in adata.obs_names:\n",
    "            if cell in adata.obs.index:\n",
    "                if pd.isna(adata.obs.loc[cell, 'guide']):\n",
    "                    adata.obs.loc[cell, 'perturbation_name'] = 'None'\n",
    "                    adata.obs.loc[cell, 'crispr_type'] = 'None'\n",
    "                    adata.obs.loc[cell, 'condition'] = 'unknown'\n",
    "                elif adata.obs.loc[cell, 'perturbation_name'] == 'Non-targeting':\n",
    "                    adata.obs.loc[cell, 'condition'] = 'control'\n",
    "                else:\n",
    "                    adata.obs.loc[cell, 'condition'] = 'test'\n",
    "    else:\n",
    "        adata.obs['perturbation_name'] = 'None'\n",
    "        adata.obs['crispr_type'] = 'None'\n",
    "        adata.obs['condition'] = 'control'\n",
    "    \n",
    "    print(f\"  Checking var_names: {adata.var_names[:5]}\")\n",
    "    \n",
    "    if 'gene_id' in adata.var.columns and not adata.var.index.equals(adata.var['gene_id']):\n",
    "        print(\"  var_names are already gene symbols\")\n",
    "    else:\n",
    "        print(\"  Warning: var_names might not be gene symbols, please check\")\n",
    "    \n",
    "    # Exclude cells with a perturbation name of \"None\" (case-insensitive)\n",
    "    initial_n = adata.n_obs\n",
    "    adata = adata[~adata.obs['perturbation_name'].str.lower().eq(\"none\")].copy()\n",
    "    print(f\"Excluded {initial_n - adata.n_obs} cells with perturbation name 'None'\")\n",
    "    \n",
    "    # Print summary only if there are remaining cells\n",
    "    print(\"Dataset summary:\")\n",
    "    print(f\"  Cells: {adata.n_obs}\")\n",
    "    print(f\"  Genes: {adata.n_vars}\")\n",
    "    if adata.n_obs > 0:\n",
    "        print(f\"  Organism: {adata.obs['organism'].iloc[0]}\")\n",
    "        print(f\"  Cell type: {adata.obs['cell_type'].iloc[0]}\")\n",
    "        if 'perturbation_name' in adata.obs.columns:\n",
    "            perturbed_cells = adata.obs[adata.obs['perturbation_name'] != 'None'].shape[0]\n",
    "            print(f\"  Perturbed cells: {perturbed_cells}\")\n",
    "            if perturbed_cells > 0:\n",
    "                top_perturbations = adata.obs['perturbation_name'].value_counts().head(5).to_dict()\n",
    "                print(f\"  Top perturbations: {top_perturbations}\")\n",
    "    else:\n",
    "        print(\"  No cells remain after filtering.\")\n",
    "    \n",
    "    output_file = os.path.join(output_dir, f\"{accession}_{dataset['name']}.h5ad\")\n",
    "    print(f\"Saving harmonized data to {output_file}\")\n",
    "    adata.write(output_file)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def main(data_dir):\n",
    "    \"\"\"Main function to process the dataset.\"\"\"\n",
    "    output_dir = os.path.join(data_dir, \"processed\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    tar_file = download_data(data_dir)\n",
    "    extract_dir = extract_data(tar_file, data_dir)\n",
    "    \n",
    "    for dataset in DATASETS:\n",
    "        harmonize_dataset(dataset, extract_dir, output_dir, GEO_ACCESSION)\n",
    "    \n",
    "    print(\"\\nHarmonization complete!\")\n",
    "\n",
    "# Set your data directory here (e.g., a local path where you want to store the data)\n",
    "data_dir = \"./data_directory\"  # Change this to your desired directory path\n",
    "\n",
    "# Run the main function\n",
    "main(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ca59a-be42-409e-b477-a3a0fbea9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
